

## 5.3 Application: Shorter Keys in One-Time-Secret Encryption

We revisit the motivating example from the beginning of this chapter. Alice & Bob share only a $\lambda$-bit key but want to encrypt a message of length $\lambda + \ell$. The main idea is to expand the key $k$ into a longer string using a PRG $G$, and use the result as a one-time pad on the (longer) plaintext. More precisely, let $G : \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be a PRG, and define the following encryption scheme:

**Construction 5.2 (Pseudo-OTP)**
$$
\def\arraystretch{1.5}
\begin{array}{|llll|}\hline
\ \ \mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \underline{\text{KeyGen:}} & \underline{\text{Enc}(k,m):} & \underline{\text{Dec}(k,c):}\\
\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell} &\quad  k\leftarrow \mathcal{K} & \quad \text{return}G(k)\oplus m & \quad\text{return}G(k)\oplus c\\
\ \ \mathcal{C}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}  & \quad \text{return}\ k\\\hline
\end{array}
$$
The resulting scheme will not have (perfect) one-time secrecy. That is, encryptions of $m_L$ and $m_R$ will not be identically distributed in general. However, the distributions will be *indistinguishable* if $G$ is a secure PRG. The precise flavor of security obtained by this construction is the following.

**Definition 5.3**
Let $\Sigma$ be an encryption scheme, and let $\mathcal{L}_{\text{ots-L}}^{\Sigma}$ and $\mathcal{L}_{\text{ots-R}}^{\Sigma}$ be defined as in Definition 2.6 (and repeated below for convenience). Then $\Sigma$ has **(computational) one-time secrecy if** $\mathcal{L}_{\text{ots-L}}^{\Sigma}\approx \mathcal{L}_{\text{ots-R}}^{\Sigma}$.  That is, if for all polynomial-time distinguishers $\mathcal{A}$, we have $\text{Pr}[\mathcal{A}\diamond \mathcal{L}_{\text{ots-L}}^\Sigma\Rightarrow 1]\approx[\mathcal{A}\diamond \mathcal{L}_{\text{ots-R}}^\Sigma\Rightarrow 1]$.
**Construction 5.2 (Pseudo-OTP)**
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad \mathcal{L}_{\text{ots-L}}^\Sigma\\\hline
\underline{\text{EAVESDROP}(m_L,m_R\in\Sigma.\mathcal{M}}\\
\quad  k\leftarrow \Sigma.\text{KeyGen}\\
\quad c\leftarrow \Sigma.\text{Enc}(k,m_L)\\
\quad \text{return}\ c\\\hline
\end{array}\quad\begin{array}{|l|}\hline
\qquad \qquad \quad \mathcal{L}_{\text{ots-R}}^\Sigma\\\hline
\underline{\text{EAVESDROP}(m_L,m_R\in\Sigma.\mathcal{M}}\\
\quad  k\leftarrow \Sigma.\text{KeyGen}\\
\quad c\leftarrow \Sigma.\text{Enc}(k,m_R)\\
\quad \text{return}\ c\\\hline
\end{array}
$$
This is essentially the same as Definition 2.6, except we are using $\approx$ (in distinguishability) instead of $\equiv$ (interchangeability).

**Claim 5.4**
Let pOTP denote Construction 5.2. If pOTP is instantiated using a secure PRG G then pOTP has computational one-time secrecy.

**Proof**
We must show that $\mathcal{L}_{\text{ots-L}}^{\text{pOTP}}\approx\mathcal{L}_{\text{ots-R}}^{\text{pOTP}}$. As usual, we will proceed using a sequence of hybrids that begins at $\mathcal{L}_{\text{ots-L}}^{\text{pOTP}}$ and ends at $\mathcal{L}_{\text{ots-R}}^{\text{pOTP}}$. For each hybrid library, we will demonstrate that it is indistinguishable from the previous one. Note that we are allowed to use the fact that G is a secure PRG. In practical terms, this means that if we can express some hybrid library in terms of $\mathcal{L}_{\text{prg-real}}^{G}$ (one of the libraries in the PRG security definition), we can replace it with its counterpart $\mathcal{L}_{\text{prg-rand}}^{G}$(or vice-versa). The PRG security of G says that such a change will be indistinguishable.

$$
\mathcal{L}_{\text{ots-L}}^{\text{pOTP}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad \mathcal{L}_{\text{ots-L}}^{\text{pOTP}}\\\hline
\underline{\text{EAVESDROP}(m_L,m_R\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}):}\\
\quad  \colorbox{yellow}{k}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \colorbox{yellow}{c}:=G(k)\oplus m_L\\
\quad \text{return}\ c\\\hline
\end{array}\quad\begin{array}{l}
\text{The starting point is}\ \mathcal{L}_{\text{otss-L}}^{pOTP}, \text{shown here with}\\
\text{the details of pOTP filled in.}
\end{array}
$$
$$
\mathcal{L}_{\text{hyb-1}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  \colorbox{yellow}{z}\leftarrow \text{QUERRY()}\\
\quad c:=\colorbox{yellow}{z}\oplus m_L\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ G(s)\\\hline
\end{array}
\quad\begin{array}{l}
\text{The first hybrid step is to factor out the}, \text{shown here with}\\
\text{computations involving G, in terms of the} \mathcal{L}_{\text{prg-real}}^G \text{library.}
\end{array}
$$
$$
\mathcal{L}_{\text{hyb-2}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  z\leftarrow \text{QUERRY()}\\
\quad c:=z\oplus m_L\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad \colorbox{yellow}{r}\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}\\
\quad \text{return}\ \colorbox{yellow}{r}\\\hline
\end{array}
\quad\begin{array}{l}
\text{From the PRG security of G, we may replace}\\
\text{the instance of}\ \mathcal{L}_{\text{prg-real}}^G \text{with}\ \mathcal{L}_{\text{prg-rand}}^G,\\
\text{The resulting hybrid library}\  \mathcal{L}_{\text{hyb-2}}\ \text{is indistinguishable}\\
\text{from the previous one.}
\end{array}
$$

$$
\mathcal{L}_{\text{hyb-3}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{ots-L}^{\text{OTP}}\\\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  \colorbox{yellow}{z}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}\\
\quad c:=z\oplus m_L\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{l}
\text{A subroutine has been inlined. Note that the}\\
\text{resulting library is precisely}\ \mathcal{L}_{\text{ots-L}}^{\text{OTP}} \text{involving standard one-time pad on plaintexts}\\
\text{of size}\  \lambda + \ell. \text{We have essentially proven}\\
\text{that pOTP is indistinguishable from standard}\\
\text{OTP, and thereforewe can apply the security of OTP.}
\end{array}
$$
$$
\mathcal{L}_{\text{hyb-4}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{ots-R}^{\text{OTP}}\\\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  z\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}\\
\quad c:=z\oplus \colorbox{yellow}{m}_R\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{l}
\text{The (perfect) one-time secrecy of rOTP allows}\\
\text{us to replace}\ \mathcal{L}_{\text{ots-L}}^{\text{OTP}} \text{with} \ \mathcal{L}_{\text{ots-R}}^{\text{OTP};}\\
\text{they are interchangeable.}
\end{array}
$$
The rest of the proof is essentially a “mirror image” of the previous steps, in which we perform the same steps but in reverse (and with $m_R$ being used instead of $m_L$).

$$
\mathcal{L}_{\text{hyb-5}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  z\leftarrow \text{\colorbox{yellow}{QUERRY()}}\\
\quad c:=z\oplus m_L\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad \ \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}\\
\quad \text{return}\ r\\\hline
\end{array}
\quad\begin{array}{l}
\text{A statement has been factored out into a}\\
\text{subroutine, which happens to exactly match}\\
\mathcal{L}_{\text{prg-rand}}^G.
\end{array}
$$

$$
\mathcal{L}_{\text{hyb-6}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad  z\leftarrow \text{QUERRY()}\\
\quad c:=z\oplus m_R\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad \colorbox{yellow}{s}\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ \colorbox{yellow}{Gs}\\\hline
\end{array}
\quad\begin{array}{l}
\text{From the PRG security of G, we can replace}\\
\mathcal{L}_{\text{prg-rand}}^G\text{with}\ \mathcal{L}_{\text{prg-real}}^G.\ \text{The resulting library}\\
\text{is indistinguishable from the previous one.}
\end{array}
$$

$$
\mathcal{L}_{\text{hyb-6}}:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{ots-R}}^{\text{pOTP}}\\\hline
\quad  \colorbox{yellow}{k}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c:=G(k)\oplus m_R\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{l}
\text{A subroutine has been inlined. The result is}\ \mathcal{L}_{\text{ots-R}}^{\text{pOTP}}
\end{array}
$$

Summarizing, we showed a sequence of hybrid libraries satisfying the following:

$\mathcal{L}_{\text {ots-L }}^{\text {pOTP }} \equiv \mathcal{L}_{\text {hyb }-1} \approx \mathcal{L}_{\text {hyb- } 2} \equiv \mathcal{L}_{\text {hyb- } 3} \equiv \mathcal{L}_{\text {hyb- } 4} \equiv \mathcal{L}_{\text {hyb- } 5} \approx \mathcal{L}_{\text {hyb- } 6} \equiv \mathcal{L}_{\text {ots-R }}^{\text {pOTP }}.$


Hence, $\mathcal{L}_{\text {ots-L }}^{\text {pOTP }} \approx \mathcal{L}_{\text {ots-R }}^{\text {pOTP }},$ and pOTP has (computational) one-time secrecy.

## 5.4 Extending the Stretch of a PRG
The *stretch* of a PRG measures how much longer its output is than its input. Can we use a PRG with small stretch to construct a PRG with larger stretch? The answer is yes, but only if you do it the right way!

### Two Approaches to Increase Stretch
Suppose $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}$ is a length-doubling PRG (i.e., a PRG with stretch $\lambda$). Below are two ideas for constructing a PRG with longer stretch:

 $$
\textcolor{red}{\text{Image screenshot here}}
$$
Although the constructions are similar, only one of them is secure. Before reading any further, can you guess which of $H_1, H_2$ is a secure PRG and which is insecure? By carefully comparing these two approaches, I hope you develop a better understanding of the PRG security definition.

### A Security Proof
I think it’s helpful to illustrate the “strategey” of security proofs by starting from the desired conclusion and working backwards. What better way to do this than as a Socratic dialogue in the style of Galileo?

**SALVIATI:** 	I’m sure that $H_1$ is the secure PRG. 

**SIMPLICIO:** If I understand the security denition for PRGs correctly, you mean that the output of $H_1$ looks indistinguishable from uniform, when the input to $H_1$ is uniform. Why do you say that? 

**SALVIATI:**  Simple! $H_1$’s output consists of segments called $x, u,$ and $v$. Each of these are outputs of $G$, and since $G$ itself is a PRG its outputs look uniform.

**SIMPLICIO:** I wish I had your boldness, Salviati. I myself am more cautious. If $G$ is a secure PRG, then its outputs are indeed indistinguishable from uniform, but surely *only when its input is uniform!* Are you so sure that’s the case here?

**SALVIATI:** You raise a good point, Simplicio. In these endeavors it is always preferable to err on the side of caution. When we want to claim that $H_1$ is a secure PRG, we consider the nature of its outputs when its seed s is uniform. Since $H_1$ sends that seed s directly into G, your concern is addressed.

**SIMPLICIO:** Yes, I can see how in the expression $x || y := G(s)$ the input to $G$ is uniform, and so its outputs $x$ and $y$ are indistinguishable from random. Since $x$ is part of $H_1$’s output, we are making progress towards showing that the entire output of $H_1$ is indistinguishable from random! However, the output of $H_1$ also contains terms $u$ and $v$. When I examine how they are generated, as $u||v := G(y)$, I become concerned again. Surely $y$ is not uniform, so I see no way to apply the security if $G$!

**SALVIATI:**  
Oh, bless your heart. The answer could not be any more obvious! It is true that $y$ is not uniformly distributed. But did you not just convince yourself that $y$ is indistinguishable from uniform? Should that suffice?

**SIMPLICIO:** 
Incredible! I believe I understand now. Let me try to summarize: We suppose
the input s to $H_1$ is chosen uniformly, and examine what happens to $H_1$’s outputs. In the expression $x || y := G(s)$, the input to $G$ is uniform, and thus $x$ and $y$ are indistinguishable from uniform. Now, considering the expression $u||v := G(y)$, the result is indistinguishable from a scenario in which $y$ is truly uniform. But if $y$ were truly uniform, those outputs $u$ and $v$ would be indistinguishable from uniform! Altogether, $x, u,$ and $v$ (the outputs of $H_1$) are each indistinguishable from uniform!

I hope that was as fun for you as it was for me. The formal security proof and its sequence of hybrids will follow the outline given in Simplicio’s summary. We start by applying the PRG security definition to the first call to $G$, and replace its outputs with truly uniform values. After this change, the input to the second call to $G$ becomes uniform, allowing us to apply the PRG security definition again. 

**Claim 5.5**
If $G$ is a secure length-doubling PRG, then $H_1$ (defined above) is a secure (length-tripling) PRG.

**Proof**
One of the trickier aspects of this proof is that we are using a secure PRG $G$ to prove the security of another PRG $H_1$. That means both $\mathcal{L}_{\text{prg}-\star}^{H_1}$ and $\mathcal{L}_{\text{prg}-\star}^{G}$ will appear in this proof. Both libraries/interfaces have a subroutine named “QUERRY”, and we will rename these subroutines QUERRY$_{H1}$ and QUERRY$_G$ to disambiguate.

We want to show that $\mathcal{L}_{\text{prg}-\star}^{H_1}\approx\mathcal{L}_{\text{prg-rand}}^{H_1}$.  As usual, we do so with a hybrid sequence. Since we assume that G is a secure PRG, we are allowed to use the fact that $\mathcal{L}_{\text{prg-real}}^{G}\approx\mathcal{L}_{\text{prg-rand}}^{G}$.

$$
\mathcal{L}_{\text{prg-real}}^H:\ \def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prg-real}}^{H_1}\\\hline
\quad  s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\def\arraystretch{1.5}
\left.\begin{array}{c}
x||y:=G(s)\\
u||v:=G(y)\\
\text{return}\ x||u||v\\
\end{array}\right\}H_1(s)\\\hline
\end{array}\quad
\begin{array}{l}
\text{The starting point is}\ \mathcal{L}_{\text{prg-real}}^{H_1},\ \text{shown here with}\\
\text{the details of}\ H_1\ \text{filled in.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad \colorbox{yellow}{x||y:=G(s)}\\
\quad u||v:=G(y)\\
\quad \text{return}\ x||u||v\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ G(s)\\\hline
\end{array}
\quad\begin{array}{l}
\text{The first invocation of G has been factored out}\\
\text{into a subroutine. The resulting hybrid library}\\
\text{includes an instance of}\ \mathcal{L}_{\text{prg-real}}^G.
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad x||y:=\text{QUERRY}_G()\\
\quad u||v:=G(y)\\
\quad \text{return}\ x||u||v\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
\quad\begin{array}{l}
\text{From the PRG security of G, we can replace the}\\
\text{instance of}\ \mathcal{L}_{\text{prg-real}}\ \text{with}\ \mathcal{L}_{\text{prg-rand}}.\ \text{The resulting}\\
\text{hybrid library is indistinguishable.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad \colorbox{yellow}{x||y}:=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad u||v:=G(y)\\
\quad \text{return}\ x||u||v\\\hline
\end{array}
\quad\begin{array}{l}
\text{A subroutine has been inlined.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad \colorbox{yellow}{x}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \colorbox{yellow}{y}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad u||v:=G(y)\\
\quad \text{return}\ x||u||v\\\hline
\end{array}
\quad\begin{array}{l}
\text{Choosing}\ 2\lambda\ \text{uniformly random bits and then}\\
\text{splitting them into two halves has exactly the}\\
\text{same effect as choosing}\ \lambda\ \text{uniformly random}\\
\text{bits and independently choosing} \lambda\ \text{more.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad u||v:=\text{QUERRY}_G()\\
\quad \text{return}\ x||u||v\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ G(s)\\\hline
\end{array}
\quad\begin{array}{l}
\text{The remaining appearance of G has been }\\
\text{factored out into a subroutine. Now}\ \mathcal{L}_{\text{prg-real}}^G\\
\text{makes its second appearance.}
\end{array}
$$
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad u||v:=\text{QUERRY}_G()\\
\quad \text{return}\ x||u||v\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
\quad\begin{array}{l}
\text{Again, the PRG security of G lets us replace}\\
\mathcal{L}_{\text{prg-real}}^G\ \text{with}\ \mathcal{L}_{\text{prg-rand}}^G.\ \text{The resulting hybrid}\ \\
\text{library is indistinguishable.}
\end{array}
$$
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \colorbox{yellow}{u||v}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ x||u||v\\\hline
\end{array}
\quad\begin{array}{l}
\text{A subroutine has been inlined.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\mathcal{L}_{\text{prg-rand}}^{H_1}:\ 
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{prg-rand}}^{H_1}\\\hline
\underline{\text{QUERRY}_{H_1}():}\\
\quad \colorbox{yellow}{r}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{3\lambda}\\
\quad \text{\colorbox{yellow}{return}\ r}\\\hline
\end{array}
\quad\begin{array}{l}
\text{Similar to above, concatenating}\ \lambda\ \text{uniform bits}\\
\text{with}\ 2\lambda\ \text{independently uniform bits has the}\\
\text{same effect as sampling}\ 3\lambda\ \text{uniform bits. The}\\
\text{result of this change is}\  \mathcal{L}_{\text{prg-rand}}^{H_1}.
\end{array}
$$

Through this sequence of hybrid libraries, we showed that:
$$
\mathcal{L}_{\text {prg-real }}^{H_{1}} \equiv \mathcal{L}_{\text {hyb }-1} \approx \mathcal{L}_{\text {hyb- } 2} \equiv \mathcal{L}_{\text {hyb- } 3} \equiv \mathcal{L}_{\text {hyb- } 4} \equiv \mathcal{L}_{\text {hyb- } 5} \approx \mathcal{L}_{\text {hyb- } 6} \equiv \mathcal{L}_{\text {hyb- } 7} \equiv \mathcal{L}_{\text {prg-rand }}^{H_{1}}.
$$
Hence, $H_1$ is a secure PRG.

### Where the Proof Breaks Down for $H_2$

The only difference between $H_1$ and $H_2$ is that the variable $y$ is included in the output. How does that minor change affect the reasoning that we applied to $H_1$?

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H_2(s):}\\
\quad x||y:=G(s)\\
\quad u||v:=G(y)\\
\quad \text{return}\ x||\colorbox{yellow}{y}||u||v\\\hline
\end{array}
$$

We argued that outputs $u$ and $v$ are indistinguishable from uniform since its input $y$ is also indistinguishable from random. But it’s not quite so simple: A PRG’s output is indistinguishable from random if (1) its seed is uniform, and (2) the seed is not used for anything *else!* This construction $H_2$ violates condition (2) because it includes the “seed” $y$ in the output.

We can see this idea reflected in the formal PRG definition. In $\mathcal{L}_{\text {prg-real }}$,  the seed $s$ is chosen uniformly, given as input to G, and then goes out of scope! If we try to reproduce the security proof for $H_1$ with $H_2$ instead, we’ll get stuck when we are trying to factor out the second call to G in terms of $\mathcal{L}_{\text {prg-real }}$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{QUERY}_{H_2}():}\\
\quad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{y}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{u||v:=G(y)}\\
\quad \text{return}\ x||y||u||v\\\hline
\end{array} \rightsquigarrow
\underbrace{\begin{array}{|l|}\hline
\underline{\text{QUERY}_{H_1}():}\\
\quad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{u||v:=\text{QUERY}}_G()\\
\quad \text{return}\ x||\colorbox{pink}{y}||u||v\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERY}_{G}():}\\
\quad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ G(s)\\\hline
\end{array}}_{\text{scope error! y undefined}}$$

We are trying to factor out the two highlighted lines into a separate library, renaming $y$
into $s$ in the process. But $s$ can only exist inside the private scope of the new library, while
there still exists a “dangling reference” $y$ in the original library.

Speaking more generally about PRGs, suppose we have a call to G somewhere and
want to argue that its outputs are pseudorandom. We can only express this call to G in
terms of $\mathcal{L}_{\text{prg-real}}^G$ if the input to G is uniform and is used nowhere else. That’s not true here – we can’t express one of the calls to G in terms of $\mathcal{L}_{\text{prg-real}}^G$, so we can’t be sure that the outputs of that call to G look random.

These subtle issues are not limited to PRGs. Every hybrid security proof in this course
includes steps where we factor out some statements in terms of some pre-existing library.
Don’t take these steps for granted! They will fail (often because of scoping issues) if the
construction isn’t using the building block correctly. You should always treat such “factoring
out” steps as “sanity checks” for your proof.

### A Concrete Attack on $H_2$
So far, we’ve only demonstrated that we get stuck when trying to prove the security of
$H_2$. But that doesn’t necessarily mean that $H_2$ is insecure – it could mean that we’re just
not clever enough to see a different security proof. To show that $H_2$ is actually insecure,
we must demonstrate a successful distinguishing attack.

Attacking a PRG amounts to nding “patterns” in their outputs. Does $H_2$ have a pattern
in its outputs? Yes, in this case the pattern is that if you write the output in the form $x\|y\|u\|v\|$, then $u\|v$ is always equal to $G(y)$. The calling program can check for this condition, which is unlikely to happen for truly uniform values.

You may wonder, is it legal for the calling program to compute $G(y)$? Well, G is a
publicly known algorithm (Kerckhoffs’ principle!), and y is right there as part of the input.
Nothing prevents the calling program from running G “in its head.”

**Claim 5.6**
Construction $H_2$ is not a secure PRG, even if G is.

**Proof**
Consider the following distinguisher $\mathcal{A}$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
x\|y\|u\|v:=\text{QUERY()}\\
\text{return}\ G(y)\stackrel{!}{=} u\|v\\\hline
\end{array}
$$
When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{prg-real}}^{H_2}$, the outputs indeed satisfy the condition $G(y)=u\|v$, so $\mathcal{A}$ outputs true with probability 1.

When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{prg-rand}}^{H_2}$, the outputs are truly uniform. It is helpful to imagine $x$ and $y$ being chosen before $u$ and $v$. As soon as $y$ is chosen, the value $G(y)$ is uniquely determined, since G is a deterministic algorithm. Then $\mathcal{A}$ will output true if $u\|v$ is chosen exactly to equal this $G(y)$. Since $u$ and $v$ are chosen uniformly, and are a total of $2k$ bits long, this event happens with probability $1/2^{2k}$.

$\mathcal{A}$'s advantage is the dierence in these probabilities: $1-1/2^{2k}$, which is nonnegligible.

### Discussion
In the attack on $H_2$, we never tried to distinguish the output of G from uniform. $H_2$ is
insecure even if G is the best PRG in the world! It’s insecure because of the incorrect way
it *uses* G.

From now on in this book, we’ll be studying higher-level constructions that are assembled
from various building blocks — in this chapter, fancy PRGs constructed from simpler
PRGs. “Security” means: if the building blocks are secure then the construction is secure.
“Insecurity” means: *even if the building blocks are secure*, the construction can be insecure.
So when you’re showing insecurity, you shouldn’t directly attack the building blocks! You
should assume the building blocks are secure and attack the way that the building blocks
are being used.

## $\star$ 5.5 Applications: Stream Cipher & Symmetric Ratchet

The PRG-feedback construction can be generalized in a natural way, by continuing to
feed part of G’s output into G again. The proof works in the same way as for the previous
construction — the security of G is applied one at a time to each application of G.

**Claim 5.7**
If G is a secure length-doubling PRG, then for any $n$ (polynomial function of $\lambda$) the following construction $H_n$ is a secure PRG with stretch $n\lambda$:

 $$
\textcolor{red}{\text{Image screenshot here}}
$$

The fact that this chain of PRGs can be extended indefinitely gives another useful
functionality:

**Definition 5.8 (Stream cipher)**
A **stream cipher** is an algorithm G that takes a seed s and length ` as input, and outputs a
string. It should satisfy the following requirements:

 1. $G(s,\ell)$ is a string of length $\ell$.
 2. If $i < j$, then $G(s,i)$ is a prefix of $G(s,j)$.
 3. For each $n$, the function $G(\cdot,n)$ is a secure PRG.

Because of the 2nd rule, you might want to think about a single innitely long string that is
the *limit* of $G(s,n)$ as $n$ goes to infinity. The finite-length strings $G(s,n)$ are all the prefixes
of this infinitely long string.

The PRG-feedback construction can be used to construct a secure stream cipher in the
natural way: given seed $s$ and length $\ell$, keep iterating the PRG-feedback main loop until
$\ell$ bits have been generated.

 $$
\textcolor{red}{\text{Image screenshot here}}
$$

### Symmetric Ratchet
Suppose Alice & Bob share a symmetric key k and are using a secure messaging app to
exchange messages over a long period of time. Later in the course we will see techniques
that Alice & Bob could use to securely encrypt many messages using a single key. However,
suppose Bob’s device is compromised and an attacker learns $k$. Then the attacker
can decrypt all past, present, and future ciphertexts that it saw!

Alice & Bob can protect against such a key compromise by using the PRG-feedback
stream cipher to constantly “update” their shared key. Suppose they do the following,
starting with their shared key $k$:

 - They use $k$ to seed a chain of length-doubling PRGs, and both obtain the same stream
of pseudorandom keys $t1, t2,\ldots$
 - They use $t_i$ as a key to send/receive the ith message. The details of the encryption
are not relevant to this example.
 - After making a call to the PRG, they erase the PRG input from memory, and only
remember the PRG’s output. After using $t_i$ to send/receive a message, they also
erase it from memory.

This way of using and forgetting a sequence of keys is called a **symmetric ratchet**.

**Construction 5.9 (Symm Ratchet)**

$$
\textcolor{red}{\text{Image screenshot here}}
$$
Suppose that an attacker compromises Bob’s device after $n$ ciphertexts have been sent. The
only value residing in memory is $s_n$, which the attacker learns. Since G is deterministic, the
attacker can nowcompute $t_{n+1}, t_{n+2},\ldots$ in the usual way and decrypt all future ciphertexts that are sent.

However, we can show that the attacker learns no information about $t_1,\ldots, t_n$ from
$s_n$, which implies that the previous ciphertexts remain safe. By compromising the key $s_n$,
the adversary only compromises the security of *future* messages, but not past messages.
Sometimes this property is called **forward secrecy**, meaning that messages in the present
are protected against a key-compromise that happens in the future.

This construction is called a **ratchet**, since it is easy to advance the key sequence in the
forward direction (from $s_n$ to $s_{n+1}$) but hard to reverse it (from $s_{n+1}$ to $s_n$). The exercises explore the problem of explicitly reversing the ratchet, but the more relevant property
for us is whether the attacker learns anything about the ciphertexts that were generated
before the compromise.

**Claim 5.10**
If the symmetric ratchet (Construction 5.9) is used with a secure PRG G and an encryption
scheme $\Sigma$ that has uniform ciphertexts $(\text{and}\ \Sigma.\mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda)$, then the first $n$ ciphertexts are
pseudorandom, even to an eavesdropper who compromises the key $s_n$.

**Proof**
We are considering an attack scenario in which $n$ plaintexts are encrypted, and the adversary
sees their ciphertexts as well as the ratchet-key $s_n$. This situation is captured by the following library:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad s_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad s_i\|t_i:=G(s_{i-1})\\
\qquad c_i\leftarrow \Sigma.\text{Enc}(t_i,m_i)\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}\quad \textcolor{red}{\text{Image screenshot here}}
$$

As we have seen, the shaded box (the process that computes $t_1,\ldots, t_n$ from $s_0$) is actually a PRG. Let us rewrite the library in terms of this PRG $H_n$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad \colorbox{yellow}{s}_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{t}_1\|\cdots\|t_n\|s_n:=H_n(s_0)\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad c_i\leftarrow \Sigma.\text{Enc}(t_i,m_i)\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}\quad \textcolor{red}{\text{Image screenshot here}}
$$

Now, we can apply the PRG security of $H_n$ and instead choose $t_1,\ldots, t_n$ and $s_n$ uniformly. This change is indistinguishable, by the security of the PRG. Note that we have not written out the standard explicit steps (factor out the first two lines of attack in terms of $\mathcal{L}_{\text{prg-real}}$, replace with $\mathcal{L}_{\text{prg-rand}}$, and inline).

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad \text{\colorbox{yellow}{for}}\ i=1\ \text{to}\ n:\\
\qquad \colorbox{yellow}{t}_i\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{s}_n\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad c_i\leftarrow \Sigma.\text{Enc}(t_i,m_i)\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}\equiv
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad \colorbox{yellow}{t}_i\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad c_i\leftarrow \Sigma.\text{Enc}(t_i,m_i)\\
\quad \colorbox{yellow}{s}_n\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}
$$

At this point, the encryption scheme is being used “as intended,” meaning thatwe generate
its keys $t_i$ uniformly/indepenendtly, and use each key only for one encryption and nothing
else. Formally speaking, this means we can factor out the body of the for-loop in terms of $\mathcal{L}_{\text{ots-real}}$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad \colorbox{yellow}{c}_i\leftarrow \text{CTXT}(m_i)\\
\quad \colorbox{yellow}{s}_n\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}\diamond
\begin{array}{|l|}\hline
\quad \quad\ \ \mathcal{L}_{\text{ots}\$-\text{real}}\\\hline
\underline{\text{CTXT}(m\in \Sigma.\mathcal{M}):}\\
\quad k\leftarrow \Sigma.\text{KeyGen}\\
\quad c\leftarrow \Sigma.\text{Enc}(k,m)\\
\quad \text{return}\ c\\\hline
\end{array}
$$

We can now replace $\mathcal{L}_{\text{ots}-\text{real}}$ with $\mathcal{L}_{\text{ots}-\text{rand}}$ and inline the subroutine (without showing the intermediate library). The result is:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ATTACK}(m_1,\ldots,m_n):}\\
\quad \text{for}\ i=1\ \text{to}\ n:\\
\qquad \colorbox{yellow}{c}_i\leftarrow \Sigma.\mathcal{C}\\
\quad s_n\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ (c_i,\ldots,c_n,s_n)\\\hline
\end{array}
$$

This final library is indistinguishable from the first one. As promised, we showed that the
attacker cannot distinguish the first $n$ ciphertexts from random values, even when seeing
$s_n$.

This proof used the uniform-ciphertexts property, but the same logic applies to basically
any encryption property you care about — just imagine factoring out the encryption
steps in terms of a different library than $\mathcal{L}_{\text{ots-real}}$.

### Exercises

5.1. Let $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be an injective (i.e., 1-to-1) PRG. Consider the following distinguisher:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{A}\\\hline
x:=\text{QUERY()}\\
\text{for all}\ s'\in :\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda:\\
\quad \text{if}\ G(s')=x\ \text{then return 1}\\
\text{return}\ 0\\\hline
\end{array}
$$

(a)   What is the advantage of $\mathcal{A}$ in distinguishing $\mathcal{L}_{\text{prg-real}}^G$ and $\mathcal{L}_{\text{prg-rand}}^G$?  Is it negligible?
(b)  Does this contradict the fact that G is a PRG? Why or why not?
(c ) What happens to the advantage if G is not injective?

5.2. Let $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be an injective PRG, and consider the following distinguisher:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad  \quad\mathcal{A}\\\hline
x:=\text{QUERY()}\\
s'\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda:\\
\text{return}\ G(s')\stackrel{!}{=}x\\\hline
\end{array}
$$
What is the advantage of $\mathcal{A}$ in distinguishing $\mathcal{L}_{\text{prg-real}}^G$ and $\mathcal{L}_{\text{prg-rand}}^G$?
>Hint: When computing $\text{Pr}[\mathcal{A} \diamond \mathcal{L}_{\text{prg-rand }}^G \text{outputs} ]1$, separate the probabilities based on whether $x$ is a possible output of G or not.

5.3. For any PRG $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ there will be many strings in $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda$ that are impossible to get as output of G. Let S be any such set of impossible G-outputs, and consider the following adversary that has S hard-coded:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad  \quad\mathcal{A}\\\hline
x:=\text{QUERY()}\\
\text{return}\ x\stackrel{?}{=}S\\\hline
\end{array}
$$

What is the advantage of $\mathcal{A}$ in distinguishing $\mathcal{L}_{\text{prg-real}}^G$ and $\mathcal{L}_{\text{prg-rand}}^G$?  Why does an adversary like this one not automatically break every PRG?

5.4. Show that the scheme from Section 5.3 does not have perfect one-time secrecy, by showing
that there must exist two messages $m_1$ and $m_2$ whose ciphertext distributions differ.
>Hint: There must exist strings $s_1, s_2 \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ where $s_1$ im(G) and $s_2 \notin$ im(G). Use these two strings to nd two messages $m_1$ and $m_2$ whose ciphertext distributions assign different probabilities to $s_1$ and $s_2$. Note that it is legitimate for an attacker to “know” $s_1$ and $s_2$, as these are properties of G alone, and do not depend on the random choices made “at runtime” — when the library executes the encryption algorithms.

5.5. The proof of Claim 5.5 applies the PRG security rule to both of the calls to G, starting with
the first one. Describe what happens when you try to apply the PRG security of G to these
two calls in the opposite order. Does the proof still work, or does it work only in the order
that was presented?

5.6. Let $\ell'>\ell>0$. Extend the “PRG feedback” construction to transform any PRG of stretch
$\ell$ into a PRG of stretch $\ell'$ 0. Formally define the new PRG and prove its security using the security of the underlying PRG.

5.7.  Prove that if G is a secure PRG, then so is the function $H(s)=G(\bar{s})$.

5.8.  Let $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be a secure length-tripling PRG. For each function below, state whether it is also a secure PRG. If the function is a secure PRG, give a proof. If not, then describe a successful distinguisher and explicitly compute its advantage. When we write $a\|b\|c:=G(s)$, each of $a,b, c$ have length $\lambda$.

$$
\text{(a)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H(s):}\\
\quad x\|y\|z:=G(s)\\
\quad \text{return}\ G(x)\|G(z)\\\hline
\end{array}
$$

$$
\text{(b)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H(s):}\\
\quad x\|y\|z:=G(s)\\
\quad \text{return}\ x\|y\\\hline
\end{array}
$$

$$
\text{(c)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H(s):}\\
\quad x:=G(s)\\
\quad y:=G(s)\\
\quad \text{return}\ x\|y\\\hline
\end{array}
$$

$$
\text{(d)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H(s):}\\
\quad x:=G(s)\\
\quad y:=G(\textcolor{brown}{0}^\lambda)\\
\quad \text{return}\ x\|y\\\hline
\end{array}
$$

$$
\text{(e)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{H(s):}\\
\quad x:=G(s)\\
\quad y:=G(\textcolor{brown}{0}^\lambda)\\
\quad \text{return}\ x\oplus y\\\hline
\end{array}
$$

$$
\text{(f)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\backslash\backslash H:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{3\lambda}\\
\underline{H(s_L\|s_R):}\\
\quad x:=G(s_L)\\
\quad y:=G(s_R)\\
\quad \text{return}\ x\oplus y\\\hline
\end{array}
$$

$$
\text{(g)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\backslash\backslash H:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{6\lambda}\\
\underline{H(s_L\|s_R):}\\
\quad x:=G(s_L)\\
\quad y:=G(s_R)\\
\quad \text{return}\ x\| y\\\hline
\end{array}
$$

 Let $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be a secure length-**tripling** PRG. Prove that each of the following functions is also a secure PRG:
$$
\text{(a)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\backslash\backslash H:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{4\lambda}\\
\underline{H(s_L\|s_R):}\\
\quad y:=G(s_R)\\
\quad \text{return}\ s_L\| y\\\hline
\end{array}
$$

Note that $H$ includes half of its input directly in the output. How do you reconcile this
fact with the conclusion of Exercise 5.14(b)?

$$
\text{(b)}\quad\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\backslash\backslash H:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{3\lambda}\\
\underline{H(s_L\|s_R):}\\
\quad \text{return}\ G(s_L)\\\hline
\end{array}
$$
$\star$ 5.10. Let $G$ be a secure length-doubling PRG. One of the following constructions is a secure PRG and one is not. Which is which? Give a security proof for one and an attack for the other.

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
> Hint: Usually when something is insecure, it’s insecure for *any* choice of building block. In this case, the attack only works for certain $G$. Basically, you will need to construct a particular $G$, prove that it’s a secure PRG, and then prove that $H_1/H_2$ is not secure when using this $G$.

5.11. A frequently asked question in cryptography forums is whether it’s possible to determine
which PRG implementation was used by looking at output samples.
Let $G_1$ and $G_2$ be two PRGs with matching input/output lengths. Define two libraries $\mathcal{L}_{\text{which-prg}}^{G_1}$ and $\mathcal{L}_{\text{which-prg}}^{G_2}$ as follows:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{which-prg}}^{G_1}\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ \colorbox{yellow}{G}_1(s)\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\quad \ \mathcal{L}_{\text{which-prg}}^{G_2}\\\hline
\underline{\text{QUERRY():}}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ \colorbox{yellow}{G}_2(s)\\\hline
\end{array}
$$

Prove that if $G_1$ and $G_2$ are both secure PRGs, then $\mathcal{L}_{\text{which-prg}}^{G_1}\approx\mathcal{L}_{\text{which-prg}}^{G_2}-$ that is, it is infeasible to distinguish which PRG was used simply by receiving output samples.

5.12.  Let $G_1$ and $G_2$ be deterministic functions, each accepting inputs of length $\lambda$ and producing outputs of length 3$\lambda$.
(a) Define the function $H(s_1\|s_2)=G_1(s_1)\oplus G_2(s_2)$. Prove that if **either** of $G_1$ or $G_2$ (or both) is a secure PRG, then so is $H$.
(b) What can you say about the simpler construction $H(s)=G_1(s_1)\oplus G_2(s_2)$, when one of $G_1,G_2$ is a secure PRG?

$\star$ 5.13. Prove that if PRGs exist, then P$\neq$NP.
>Hint: $\{y| \exists_s:G(s)=y\}\in$ NP. Prove the contrapositive! Use the powerful assumption that P = NP to construct an ecient adversary to attack any candidate PRG.

5.14. (a)  Let $f$ be any function. Show that the following function $G$ is not a secure PRG, no
matter what $f$ is. Describe a successful distinguisher and explicitly compute its advantage:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{G(s):}\\
\quad \text{return}\ s\|f(s)\\\hline
\end{array}
$$
(b)  Let $G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda+\ell}$ be a candidate PRG. Suppose there is a polynomial-time algorithm $V$ with the property that it inverts $G$ with non-negligible probability. That is,
$$
\underset{s \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda}{\operatorname{Pr}}[V(G(s))=s] \text { is non-negligible. }
$$
Show that if an algorithm $V$ exists with this property, then $G$ is not a secure PRG. In other words, construct a distinguisher contradicting the PRG-security of $G$ and show that it achieves non-negligible distinguishing advantage.

 *Note*: Don't assume anything about the output of $V$ other than the property shown above. In particular, $V$ might very frequently output the "wrong" thing.
 
5.15. Let $s_{0}, s_{1}, \ldots$ and $t_{1}, t_{2}, \ldots$ be defined as in the symmetric ratchet (Construction 5.9).
(a) Prove that if $G$ is a secure PRG then the following two libraries are indistinguishable, for any polynomial-time algorithm $\mathcal{A}$ :

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \quad\mathcal{L}_{\text{left}}\\\hline
\underline{\text{TEST()}:}\\
\quad s_{n-1}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad s_n\|t_n:=G(s_{n-1})\\
\quad \tilde{t}=\mathcal{A}(s_n)\\
\quad \text{return}\ \tilde{t}\stackrel{?}{=}t_n\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{right}}\\\hline
\underline{\text{TEST()}:}\\
\quad s_{n}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \tilde{t}=\mathcal{A}(s_n)\\
\quad t_n\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ \tilde{t}\stackrel{?}{=}t_n\\\hline
\end{array}
$$

(b) What is Pr[test outputs true] in $\mathcal{L}_{\text{right}}$?
(c ) Prove that for any polynomial-time algorithm $\mathcal{A},\text{Pr}[\mathcal{A}(s_n)=t_n]$ is negligible, where $s_n, t_n$ are generated as in the symmetric ratchet construction.
(d) Prove that for any polynomial-time algorithm $\mathcal{A},\text{Pr}[\mathcal{A}(s_n)=\colorbox{yellow}{s}_{n-1}]$ negligible. In other words, “turning the ratchet backwards” is a hard problem.
>Hint: the proof should be a few lines, a direct corollary of part (c).
# 6 Pseudorandom Functions & Block Ciphers

Imagine if Alice \& Bob had an *infinite* amount of shared randomness - not just a short key. They could split it up into $\lambda$ -bit chunks and use each one as a one-time pad whenever they want to send an encrypted message of length $\lambda$.

Alice could encrypt by saying, "hey Bob, this message is encrypted with one-time pad using chunk $\# 674696273$ as key. Bob could decrypt by looking up location $\# 674696273$ in his copy of the shared randomness. As long as Alice doesn't repeat a key/chunk, an eavesdropper (who doesn't have the shared randomness) would learn nothing about the encrypted messages. Although Alice announces (publicly) *which* location/chunk was used as each one-time pad key, that information doesn't help the attacker know the value at that location.

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

It is silly to imagine an infinite amount of shared randomness. However, an exponential amount of something is often just as good as an infinite amount. A shared table containing "only" $2^{\lambda}$ one-time pad keys would be quite useful for encrypting as many messages as you could ever need.

A **pseudorandom function (PRF)** is a tool that allows Alice \& Bob to achieve the effect of such an exponentially large table of shared randomness in practice. In this chapter we will explore PRFs and their properties. In a later chapter, after introducing new security definitions for encryption, we will see that PRFs can be used to securely encrypt *many* messages under the same key, following the main idea illustrated above.

## 6.1 Definition

Continuing our example, imagine a huge table of shared data stored as an array $T,$ so the ith item is referenced as $T[i]$. Instead of thinking of $i$ as an integer, we can also think of $i$ as a binary string. If the array has $2^{\text {in }}$ items, then $i$ will be an $i n$ -bit string. If the array contains strings of length "out", then the notation $T[i]$ is like a function that takes an input from $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}$ and gives an output from $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}$

A pseudorandom function emulates the functionality of a huge array. It is a function $F$ that takes an input from $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}$ and gives an output from $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}$. However, $F$ also takes an additional argument called the seed, which acts as a kind of secret key.

The goal of a pseudorandom function is to "look like" a uniformly chosen array lookup table. Such an array can be accessed through the Lookup subroutine of the following library:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\text{for}\ x\in \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}:\\
\quad T[x]\leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}\\
\underline{\text{LOOKUP}\ (x\in  \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad \text{return} T[x]\\\hline
\end{array}
$$

As you can see, this library initially fills up the array $T$ with uniformly random data, and then allows the calling program to access any position in the array.

A pseudorandom function should produce indistinguishable behavior, when it is used with a uniformly chosen seed. More formally, the following library should be indistinguishable from the one above:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k \leftarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda}\\
\underline{\text {LOOKUP}(x \in\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad {\text { return } F(k, x)}\\\hline
\end{array}
$$

Note that the first library samples out $\cdot 2^{\text {in }}$ bits uniformly at random (out bits for each of $2^{\text {in }}$ entries in the table), while the second library samples only $\lambda$ bits (the same $k$ is used for all invocations of $F$ ). Still, we are asking for the two libraries to be indistinguishable.

 This is basically the definition of a PRF, with one technical caveat. We want to allow situations like in $\geqslant \lambda,$ but in those cases the first library runs in exponential time. It is generally convenient to build our security definitions with libraries that run in polynomial time. We fix this by taking advantage of the fact that, no matter how big the table $T$ is meant to be, a polynomial-time calling program will only access a polynomial amount of it. In some sense it is "overkill" to actually populate the entire table $T$ upfront. Instead, we can populate $T$ in a lazy $/$ on-demand way. $T$ initially starts uninitialized, and its values are only assigned as the calling program requests them. This changes when each $T[x]$ is sampled (if at all), but does not change how it is sampled (i.e, uniformly \& independently). This also changes $T$ from being a typical array to being an *associative* array ("hash table" or "dictionary" data structure), since it only maps a subset of $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}$ to values in $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}$.

**Definition 6.1 (PRF security)** Let $F:\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda}\times\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text{in}}\rightarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text{out}}$ be a deterministic function. We say that $F$ is a secure **pseudorandom function (PRF)** if $\mathcal{L}_{\text{prf-real}}^F\approx\mathcal{L}_{\text{prf-rand}}^F$ where:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
k \leftarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda}\\
\underline{\text {LOOKUP}(x \in\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad {\text { return } F(k, x)}\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text {LOOKUP}(x \in\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad\text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}\\
\quad {\text { return } T[x]}\\\hline
\end{array}
$$

### Discussion, Pitfalls

The name "pseudorandom *function*" comes from the perspective of viewing $T$ not as an (associative) array, but as a function $T:\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }} \rightarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}$. There are $2^{\text {out }-2^{\text {is }}}$ possible functions for $T$ (an incredibly large number), and $\mathcal{L}_{\text {prf-rand }}$ chooses a "random function" by uniformly sampling its truth table as needed.

For each possible seed $k$, the residual function $F(k, \cdot)$ is also a function from $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }} \rightarrow$ $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}$. There are "only" $2^{\lambda}$ possible functions of this kind (one for each choice of $k$ ), and $\mathcal{L}_{\text {prf-real }}$ chooses one of these functions randomly. In both cases, the libraries give the calling program input/output access to the function that was chosen. You can think of this in terms of the picture from Section 5.1 , but instead of strings, the objects are functions. 

Note that even in the case of a "random function" $\left(\mathcal{L}_{\text {prf-rand }}\right),$ the function $T$ itself is still deterministic! To be precise, this library chooses a deterministic function, uniformly, from the set of all possible **deterministic** functions. But once it makes this choice, the input/output behavior of $T$ is fixed. If the calling program calls Lookur twice with the same $x,$ it receives the same result. The same is true in $\mathcal{L}_{\text {prf-real }}$, since $F$ is a deterministic function and $k$ is fixed throughout the entire execution. To avoid this very natural confusion, it is perhaps better to think in terms of "randomly initialized lookup tables" rather than "random functions.

### How NOT to Build a PRF
We can appreciate the challenges involved in building a PRF by looking at a natural approach that doesn't quite work.

**Example**
Suppose we have a length-doubling $\operatorname{PRGG}:\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{2 \lambda}$ and try to use it to construct a PRFF as follows:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{F(k, x):}\\
\quad\text { return } G(k) \oplus x\\\hline
\end{array}
$$


You might notice that all we have done is rename the encryption algorithm of "pseudo-OTP" (Construction 5.2). We have previously argued that this algorithm is a secure method for onetime encryption, and that the resulting ciphertexts are pseudorandom. Is this enough for a secure PRF? No, we can attack the security of this PRF.

Atfacking F means designing distinguisher that behaves as differently as possible in the presence of the two $\mathcal{L}_{\text{prf-}\star}^F$ libraries. We want to show that $F$ is insecure even if $G$ is an excellent PRG. We should not try to base aur atack on distingulding oufputs of $G$ frow random. Indend, we must try to **break the inappropriate way that** $G$ **is used** to construct a PRF

The distinguisher must use the interface of the $\mathcal{L}_{\text {prf}-\star }$ libraries - i.e., make some calls to the LOOKUP subroutine and output 0 or 1 based on the answers it gets. The LOOKUP subroutine takes an argument, so the distinguisher has to choose which arguments to use.

One observation we can make is that if a calling program sees only one value of the form $G(k) \oplus x,$ it will look pseudorandom. This is essentially what we showed in Section 5.3. So we should be looking for a calling program that makes more than one call to LOOKUP.

If we make two calls to LOOKUP $-$ say, on inputs $x_{1}$ and $x_{2}-$ the responses from $\mathcal{L}_{\text {prf-real }}$ will be $G(k) \oplus x_{1}$ and $G(k) \oplus x_{2} .$ To be a secure PRF, these responses must look independent and uniform. Do they? They actually have a pattern that the calling program can notice: their XOR is always $x_{1} \oplus x_{2},$ a value that is already known to the calling program. We can condense all of our observations into the following distinguisher:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \qquad\mathcal{A}\\\hline
\text{pick}\ x_1,x_2\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\ \text{arbitrarily so that}\ x_1\neq x_2\\
z_1:=\text{LOOKUP}(x_1)\\
z_2:=\text{LOOKUP}(x_2)\\
\text { return }z_1 \oplus z_2 \stackrel{?}{=}x_1\oplus x_2\\\hline
\end{array}
$$

Let’s compute its advantage in distinguishing $\mathcal{L}_{\text{prf-real}}^F$ from $\mathcal{L}_{\text{prf-rand}}^F$  considering $\mathcal{A}’s$ behavior when linked to these two libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad \mathcal{A}\\\hline
\text{pick}\ x_1\neq x_2\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
z_1:=\text{LOOKUP}(x_1)\\
z_2:=\text{LOOKUP}(x_2)\\
\text { return }z_1 \oplus z_2 \stackrel{?}{=}x_1\oplus x_2\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad \qquad \ \mathcal{L}_{\text{prf-real}}^F\\\hline
k\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\\\
\text{LOOKUP}(x):\\
\quad\text { return }G(k) \oplus x// F(k,x)\\\hline
\end{array}
$$

When $\mathcal{A}$ is linked to $\mathcal{L}_{\text {prf-real }}^{F}$, the library will choose a key $k$. Then $z_{1}$ is set to $G(k) \oplus x_{1}$ and $z_{2}$ is set to $G(k) \oplus x_{2} .$ So $z_{1} \oplus z_{2}$ is always equal to $x_{1} \oplus x_{2},$ and $\mathcal{A}$ always outputs $1 .$ That is,
$$
\operatorname{Pr}\left[\mathcal{A} \diamond \mathcal{L}_{\text {prf-real }}^{F} \Rightarrow 1\right]=1.
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad \mathcal{A}\\\hline
\text{pick}\ x_1\neq x_2\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
z_1:=\text{LOOKUP}(x_1)\\
z_2:=\text{LOOKUP}(x_2)\\
\text { return }z_1 \oplus z_2 \stackrel{?}{=}x_1\oplus x_2\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad \qquad \ \mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad\text{return}\ T[x]\\
\hline
\end{array}
$$

When $\mathcal{A}$ is linked to $\mathcal{L}_{\text {prf-rand }}^F$, the responses of the two calls to LOOKUP will be chosen uniformly and independently because LOOKUP is being called on distinct inputs. Consider the moment in time when the second call to LOOKUP is about to happen. At that point, $x_{1}, x_{2},$ and $z_{1}$ have all been determined, while $z_{2}$ is about to be chosen uniformly by the library. Using the properties of XOR, we see that $\mathcal{A}$ will output 1 if and only if $z_{2}$ is chosen to be exactly the value $x_{1} \oplus x_{2} \oplus z_{1} .$ This happens only with probability $1 / 2^{2 \lambda} .$ That is,
$$
\operatorname{Pr}\left[\mathcal{A} \circ \mathcal{L}_{\text {prf-rand }}^{F} \Rightarrow 1\right]=1 / 2^{2 \lambda}.
$$
The advantage of $\mathcal{A}$ is therefore $1-1 / 2^{2 \lambda}$ which is certainly non-negligible since it doesn't even approach $0 .$ This shows that $F$ is not a secure PRF.

At a more philosophical level, we wanted to identify exactly how $G$ is being used in an inappropriate way. The PRG security libraries guarantee security when G's seed is chosen freshly for each call to G. This construction of $F$ violates that rule and allows the same seed to be used twice in different calls to $G,$ where the results are supposed to look independent.

This example shows the challenge of building a PRF. Even though we know how to make any individual output pseudorandom, it is difficult to make all outputs collectively appear independent, when in reality they are derived from a single short seed. 

## 6.2 PRFs vs PRGs; Variable-Hybrid Proofs

In this section we show that a PRG can be used to construct a PRF, and vice-versa. The construction of a PRG from PRF is practical, and is one of the more common ways to obtain a PRG in practice. The construction of a PRF from PRG is more of theoretical interest and does not reflect how PRFs are designed in practice.

### Constructing a PRG from a PRF
As promised, a PRF can be used to construct a PRG. The construction is quite natural. For simplicity, suppose we have a PRF $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ (i.e., in $=$ out $=\lambda$ ). We can build a length-doubling PRG in the following way:

**Construction 6.2 (Counter PRG)**

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{G(s):}\\
\quad x:=F(s,\textcolor{brown}{0\cdots 00})\\
\quad y:=F(s,\textcolor{brown}{0\cdots 01})\\
\quad\text { return }x\|y\\\hline
\end{array}
$$

There is nothing particularly special about the inputs $\textcolor{brown}{0\cdots 00}$ and $\textcolor{brown}{0\cdots 01}$ to $F$ . All that matters is that they are distinct. The construction can be extended to easily give more than 2 blocks of output, by treating the input to $F$ as a simple counter (hence the name of this construction).

The guarantee of a PRF is that when its seed is chosen uniformly and it is invoked on
distinct inputs, its outputs look independently uniform. In particular, its output on inputs
$\textcolor{brown}{0\cdots 00}$ and $\textcolor{brown}{0\cdots 01}$ are indistinguishable from uniform. Hence, concatenating them gives a string which is indistinguishable from a uniform 2$\lambda$-bit string.

That really is all there is to the security of this construction, but unfortunately there is
a slight technical issue which makes the security proof more complicated than you might
guess. We will have to introduce a new technique of **variable hybrids** to cope with it.

**Claim 6.3**
If $F$ is a secure PRF, then the counter PRG construction $G$ above is a secure PRG.

**Proof**
In order to prove that $G$ is a secure PRG, we must prove that the following libraries are
indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
 \qquad\qquad\ \ \mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERY}():}\\
\quad s\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\left.\begin{array}{l}
\ x:=F(s,\textcolor{brown}{0\cdots 00})\\
\ y:=F(s,\textcolor{brown}{0\cdots 01})\\
\ \text { return }x\|y
\end{array}\right\}//G(s)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
 \quad\ \  \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERY}():}\\
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

During the proof, we are allowed to use the fact that $F$ is a secure PRF. That is, we can use
the fact that the following two libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
k \leftarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda}\\\\
\underline{\text {LOOKUP}(x \in\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad {\text { return } F(k, x)}\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text {LOOKUP}(x \in\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {in }}):}\\
\quad\text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {out }}\\
\quad {\text { return } T[x]}\\\hline
\end{array}
$$

The inconvenience in the proof stems from a mismatch of the $s$ variable in $\mathcal{L}_{\text {prg-real }}$ and the $k$ variable in $\mathcal{L}_{\text {prf-real }}$. In $\mathcal{L}_{\text {prg-real }}, s$ is local to the QUERY subroutine. Over the course of an execution, $s$ will take on many values. Since $s$ is used as the PRF seed, we must write the calls to $F$ in terms of the LOOKUP subroutine of $\mathcal{L}_{\text {prf-real }}$. But in $\mathcal{L}_{\text {prf-real }}$ the PRF seed is fixed for the entire execution. In other words, we can only use $\mathcal{L}_{\text {prf-real }}$ to deal with a single PRF seed at a time, but $\mathcal{L}_{\text {prg-real }}$ deals with many PRG seeds at a time.

To address this, we will have to apply the security of $F\left(\right.$ i.e., replace $\mathcal{L}_{\text {prf-real }}$ with $\mathcal{L}_{\text {prf-rand }}$ ) *many times* during the proof $-$ in fact, once for every call to QUERY made by the calling program. Previous security proofs had a fixed number of hybrid steps ( $e . g$., the proof of Claim 5.5 used 7 hybrid libraries to show $\mathcal{L}_{\text {prg-real }} \approx \mathcal{L}_{\text {hyb }-1} \approx \cdots \approx \mathcal{L}_{\text {hyb- } 7} \approx$ $\left.\mathcal{L}_{\text {prg-rand }}\right)$. This proof will have a **variable number of hybrids that depends on the calling program.** Specifically, we will prove
$$
\mathcal{L}_{\text {prg-real }}^{G} \approx \mathcal{L}_{\text {hyb-1 }} \approx \cdots \approx \mathcal{L}_{\text {hyb- } \colorbox{yellow}{q}} \approx \mathcal{L}_{\text {prg-rand }}^{G},
$$
where $q$ is the number of times the calling program calls QUERY.

Don’t be overwhelmed by all these hybrids. They all follow a simple pattern. In fact,
the ith hybrid looks like this: 

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{hby}-i}\\\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count \leqslant \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
$$

In other words, the hybrid libraries all differ in the value $\colorbox{silver}{i}$ that is inserted into the code above. If you're familiar with $C$ compilers, think of this as adding "$\textcolor{brown}{\#\ \texttt{define}\ i\ 427}$ " to the top of the code above, to obtain $\mathcal{L}_{\text {hyb- } 427}$. 

First note what happens for extreme choices of $\colorbox{silver}{i}$ :
- In $\mathcal{L}_{\text {hyb- } 0}$, the if-branch is never taken (count $\leqslant 0$ is never true). This library behaves exactly like $\mathcal{L}_{\text {prg-real }}^{G}$ by giving PRG outputs on every call to QUERY.
- If $q$ is the total number of times that the calling program calls QUERY, then in $\mathcal{L}_{\mathrm{hyb}-q},$ the if-branch is always taken ( count $\leqslant q$ is always true). This library behaves exactly like $\mathcal{L}_{\text {prg-rand }}^{G}$ by giving truly uniform output on every call to QUERY.

In general, $\mathcal{L}_{\text {hyb- } i}$ will respond to the first $i$ calls to QUERY by giving truly random output. It will respond to all further calls by giving outputs of our PRG construction.

We have argued that $\mathcal{L}_{\text {prg-real }}^{G} \equiv \mathcal{L}_{\text {hyb- } 0}$ and $\mathcal{L}_{\text {prg-rand }}^{G} \equiv \mathcal{L}_{\text {hyb- } q .}$ To complete the proof, we must show that $\mathcal{L}_{\text {hyb- }(i-1)} \approx \mathcal{L}_{\text {hyb- } i}$ for all $i$. The main reason for going to all this trouble of defining so many hybrid libraries is that $\mathcal{L}_{\mathrm{hyb}-(i-1)}$ and $\mathcal{L}_{\text {hyb- } i}$ are completely identical except in how they respond to the $i$ th call to QUERY. This difference involves a single call to the PRG (and hence a single PRF seed), which allows us to apply the security of the PRF.

In more detail, let $i$ be arbitrary, and consider the following sequence of steps starting with $\mathcal{L}_{\text {hyb- }(i-1)}$ :

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count \leqslant \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{elseif:}\ count < \colorbox{silver}{i}:\\
\qquad s^*\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s^*,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s^*,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have taken $\mathcal{L}_{\text{hyb-(i-1)}}$ and simply expanded the else-branch}\\
\text{($count \geqslant$ i ) into two subcases ($count = i$ and $count > i$ ).}\\
\text{However, both cases lead to the same block of code (apart from}\\
\text{ a change to a localvariable’s name), so the change}\\
\text{has no effect on the calling program.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count < \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{elseif:}\ count < \colorbox{silver}{i}:\\
\qquad x:=\text{\colorbox{yellow}{LOOKUP}}(\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=\text{\colorbox{yellow}{LOOKUP}}(\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
k\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{return}\ F(k,x)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have factored out the calls to $F$ that}\\
\text{use seed $s^*$ (corresponding to the $count = \colorbox{silver}{i}$}\\
\text{case) in terms of $\mathcal{L}_{\text{prf-real}}$}  \text{This change no}\\
\text{effect on the calling program.}\\
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count < \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{elseif:}\ count < \colorbox{silver}{i}:\\
\qquad x:=\text{LOOKUP}(\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=\text{LOOKUP}(\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ T[x]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{From the fact that $F$ is a secure PRF, we}\\
\text{can replace  $\mathcal{L}_{\text{prf-real}}^F$\ with\ $\mathcal{L}_{\text{prf-rand}}^F$ }\\
\text{and the overall change is indistinguishable.}\\
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count < \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{elseif:}\ count < \colorbox{silver}{i}:\\
\qquad x:=\text{LOOKUP}(\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=\text{LOOKUP}(\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\underline{\text{LOOKUP}(x):}\\
\quad r \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
\quad
\begin{array}{l}
\text{Since $count = i$ happens only once, only two}\\
\text{calls to LOOKUP will be made across the}\\
\text{entire lifetime of the library, and they are on}\\
\text{distinct inputs. Therefore, the if-branch in}\\
\text{LOOKUP will always be taken, and $T$ is never}\\
\text{needed (it is only needed to “remember” values and }\\
\text{give the same answer when the same $x$ is used }\\
\text{twice as argument to LOOKUP). Simplifying the}\\
\text{library therefore has no effect on the calling program:}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
count:=0\\\\
\underline{\text{QUERY():}}\\
\quad count:=count+1\\
\quad \text{if}\ count < \colorbox{silver}{i}:\\
\qquad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\qquad\text{return}\ r\\
\quad \text{elseif:}\ count < \colorbox{silver}{i}:\\
\qquad \colorbox{yellow}{x}\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad \colorbox{yellow}{y}\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad \text{return}\ x\|y\\
\quad \text{else:}\\
\qquad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\qquad x:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{00})\\
\qquad y:=F(s,\textcolor{brown}{0}\cdots\textcolor{brown}{01})\\
\qquad \text{return}\ x\|y\\\hline
\end{array}
\quad
\begin{array}{l}
\text{Inlining the subroutine has no effect on the calling program.}\\
\text{The resulting library responds with uniformly random output}\\
\text{to the first $i$ calls to QUERY, and responds with outputs of our}\\
\text{PRG G to the others. Hence, this library has identical behavior}\\
\text{to $\mathcal{L}_{\text{hyb-}i }$.}
\end{array}
$$
We showed that $\mathcal{L}_{\text {hyb- }(i-1)} \approx \mathcal{L}_{\text {hyb- } i},$ and therefore:
$$
\mathcal{L}_{\text {prg-real }}^{G} \equiv \mathcal{L}_{\text {hyb- } 0} \approx \mathcal{L}_{\text {hyb-1 }} \approx \cdots \approx \mathcal{L}_{\text {hyb- } q} \equiv \mathcal{L}_{\text {prg-rand }}^{G}
$$
This shows that $\mathcal{L}_{\text {prg-real }}^{G} \approx \mathcal{L}_{\text {prg-rand }}^{G},$ so $G$ is a secure PRG.


## $\star\quad$ A Theoretical Construction of a PRF from a PRG
We have already seen that it is possible to feed the output of a PRG back into the PRG again, to extend its stretch (Claim 5.7). This is done by making a long chain (like a linked list) of PRGs. The trick to constructing a PRF from a PRG is to chain PRGs together in a binary tree (similar to Exercise $5.8(\mathrm{a})$ ). The leaves of the tree correspond to final outputs of the PRF. If we want a PRF with an exponentially large domain (e.g., in $=\lambda$ ), the binary tree itself is exponentially large! However, it is still possible to compute any individual leaf efficiently by simply traversing the tree from root to leaf. This tree traversal itself is the PRF algorithm. This construction of a PRF is due to Goldreich, Goldwasser, and Micali, in the paper that defined the concept of a PRF.

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

Imagine a complete binary tree of height in (in will be the input length of the PRF). Every node in this tree has a *position* which can be written as a binary string. Think of a node's position as the directions to get there starting at the root, where a $\textcolor{brown}{0}$ means "go left" and $\textcolor{brown}{1}$ means "go right." For example, the root has position $\epsilon$ (the empty string), the right child of the root has position $\textcolor{brown}{1}$ , etc.

The PRF construction works by assigning a label to every node in the tree, using the a length-doubling $\operatorname{PRG} G:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2 \lambda} .$ For convenience, we will write $G_{L}(k)$ and $G_{R}(k)$ to denote the first $\lambda$ bits and last $\lambda$ bits of $G(k)$, respectively. Labels in the tree are $\lambda$ -bit strings, computed according to the following two rules:
1. The root node's label is the PRF seed.
2. If the node at position $p$ has label $v$, then its left child (at position $p \| \textcolor{brown}{0}$ ) gets label $G_{L}(v),$ and its right child (at position $p \| \textcolor{brown}{1}$ ) gets label $G_{R}(v)$

In the picture above, a node's label is the string being sent on its incoming edge. The tree has $2^{\text {in }}$ leaves, whose positions are the strings $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {in }}$. We define $F(k, x)$ to be the label of node/leaf $x$. To compute this label, we can traverse the tree from root to leaf, taking left and right turns at each node according to the bits of $x$ and computing the labels along that path according to the labeling rule. In the picture above, the highlighted path corresponds to the computation of $F(k, \textcolor{brown}{1001}\cdots)$.

It is important to remember that the binary tree is a useful conceptual tool, but it is exponentially large in general. Running the PRF on some input does not involve computing labels for the entire tree, only along a single path from root to leaf.

**Construction 6.4 (GGM PRF)**

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
& \underline{F(k,x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\textit{in}}}\\
& \quad v:=k\\
\text{\textit{in}=arbitrary} &\quad \text{for}\ i=1\ \text{to \textit{in}}:\\
out=\lambda & \qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
& \qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
& \quad \text{return}\ v\\\hline
\end{array}
$$

**Claim 6.5**
If $G$ is a secure PRG, then Construction 6.4 is a secure PRF.

**Proof**
We prove the claim using a sequence of hybrids. The number of hybrids in this case
depends on the input-length parameter in. The hybrids are defined as follows:



$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \ \ \mathcal{L}_{\text{hyb-d}}\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{QUERY}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d}\  \text{bits of}\ x\\
\quad \text{if}\  T[p]\ \text{undefined:}\\
\qquad T[p]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad v:=T[p]\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\quad \text{return}\ v\\\hline
\end{array}
$$

The hybrids differ only in their hard-coded value of $\colorbox{silver}{d}$. We will show that
$$
\mathcal{L}_{\text {prf-real }}^{F} \equiv \mathcal{L}_{\text {hyb- } 0} \approx \mathcal{L}_{\text {hyb- } 1} \approx \cdots \approx \mathcal{L}_{\text {hyb-in }} \equiv \mathcal{L}_{\text {prf-rand }}^{F}
$$
We first start by understanding the behavior of $\mathcal{L}_{\text {hyb- } d}$ for extreme choices of $\colorbox{silver}{d}$. Simplifications to the code are shown on the right.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \qquad \mathcal{L}_{\text{hyb-d}}\\\hline
\begin{array}{ll}
T:=\text{empty assoc. array} &\qquad k:=\text{undefined}\\
& \qquad//k\text{is alias for}\ T[\epsilon]\\
\end{array}\\
\begin{array}{ll}
\underline{\text{QUERY}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d}\  \text{bits of}\ x &\qquad\ \ p=\epsilon\\
\quad \text{if}\  T[p]\ \text{undefined:} &\qquad\ \  \text{if}\ k\ \text{undefined:}\\
\qquad T[p]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \qquad \qquad k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\end{array}\\
\left.\begin{array}{l}
\quad v:=T[p]\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\end{array}\right\}v:=F(k,x)\\
\quad \text{return}\ v \qquad \qquad \qquad \qquad \qquad \text{return}\ \ F(k,x)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{In $\mathcal{L}_{\text{hyb-d}}$, we always have $p=\epsilon$,}\\
\text{so the only entry of T that is accessed}\\
\text{is $T[\epsilon]$. Then renaming
$T[\epsilon]$ to $k$, we see}\\
\text{that $\mathcal{L}_{\text{hyb-0}}\equiv\mathcal{L}_{\text{hyb-real}}^F$. The only difference is}\\
\text{when the PRF seed $k(T[\epsilon])$ is sampled:}\\
\text{ eagerly at initialization time in $\mathcal{L}_{\text{hyb-real}}^F$ Vs.}\\
\text{at the last possible minute in $\mathcal{L}_{\text{hyb-0}}$.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \qquad \mathcal{L}_{\text{hyb}-in}\\\hline
\begin{array}{ll}
T:=\text{empty assoc. array} &\\
&\\
\end{array}\\
\begin{array}{ll}
\underline{\text{LOOKUP}(x):}\\
\quad p:=\text{first} \colorbox{silver}{\textit{in}}\  \text{bits of}\ x &\qquad\ \ p=x\\
\quad \text{if}\  T[p]\ \text{undefined:} &\qquad\ \  \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[p]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \qquad \qquad T[x]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad v:=T[p]\\
\end{array}\\
\left.\begin{array}{l}
\quad \text{for}\ i=\colorbox{silver}{\textit{in}+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\end{array}\right\}// \text{unreachable}\\
\quad \text{return}\ v \qquad \qquad \qquad \qquad \qquad \text{return}\ \ T[x]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{In $\mathcal{L}_{\text{hyb}-in}$, we always have $p=x$,}\\
\text{and the body of the forloop is always}\\
\text{unreachable. In that case, it is easy to}\\
\text{ see that $\mathcal{L}_{\text{hyb}-in}$ has identical behavior to}\\
\text{ $\mathcal{L}_{\text{prf-rand}}^F$.}
\end{array}
$$

The general pattern is that $\mathcal{L}_{\text {hyb- } d}$ "chops off" the top $d$ levels of the conceptual binary tree. When computing the output for some string $x$, we don't start traversing the tree from the root but rather $d$ levels down the tree, at the node whose position is the $d$ -bit prefix of $x$ (called $p$ in the library). We initialize the label of this node as a uniform value (unless it has already been defined), and then continue the traversal to the leaf $x$. 

To finish the proof, we show that $\mathcal{L}_{\mathrm{hyb}-(d-1)}$ and $\mathcal{L}_{\mathrm{hyb}-d}$ are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d-1}\  \text{bits of}\ x\\
\quad \text{if}\  T[p]\ \text{undefined:}\\
\qquad T[p]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad \colorbox{yellow}{T}[p\|\textcolor{brown}{0}]:=G_L(T[p])\\
\qquad \colorbox{yellow}{T}[p\|\textcolor{brown}{1}]:=G_R(T[p])\\
\quad \colorbox{yellow}{p':=\text{first}} \colorbox{silver}{d}\ \text{bits of}\ x\\
\quad \colorbox{yellow}{v:=T[p']}\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\quad \text{return}\ v\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The library that is shown here is different from}\\
\mathcal{L}_{\text{hyb-}(d-1)}\text{in the highlighted parts. However, these differences}\\
\text{have no effect on the calling program. The library here}\\
\text{advances $d- 1$ levels down the tree (to the node at location $p$),}\\
\text{initializes that node’s label as a uniform value, then}\\
\text{computes the labels for both its children, and finally continues computing}\\
\text{labels toward the leaf. The only significant difference from}\\
\mathcal{L}_{\text{hyb-}(d-1)}\text{is that it computes the labels of both of $p$’s children, even}\\
\text{though only one is on the path to $x$. Since it computes the label}\\
\text{correctly, though, it makes no difference when (or if) this}\\
\text{extra label is computed.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d-1}\  \text{bits of}\ x\\
\quad \text{if}\  T[p]\ \text{undefined:}\\
\qquad \colorbox{yellow}{T}[p\|\textcolor{brown}{0}]\Big|\Big|T[p\|\textcolor{brown}{1}]:=\text{QUERY()}\\
\quad p':=\text{first} \colorbox{silver}{d}+1\ \text{bits of}\ x\\
\quad v:=T[p']\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\quad \text{return}\ v\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad\mathcal{L}_{\text{prg-real}}^G\\\hline
\underline{\text{QUERY():}}\\
\quad s\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ G(s)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have factored out the body}\\
\text{of the if-statement in terms of}\\
\mathcal{L}_{\text{prg-real}}^G\text{since it involves an call}\\
\text{to $G$ on uniform input. Importantly,}\\
\text{the seed to $G$ (called $T[p]$ in the previous}\\
\text{hybrid) was not used anywhere else —}\\
\text{it was a string of length $d - 1$ while}\\
\text{the library only reads $T[p']$ for $p'$ of}\\
\text{ength d. The change has no effect}\\
\text{on the calling program.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d-1}\  \text{bits of}\ x\\
\quad \text{if}\  T[p]\ \text{undefined:}\\
\qquad T[p\|\textcolor{brown}{0}]\Big|\Big|T[p\|\textcolor{brown}{1}]:=\text{QUERY()}\\
\quad p':=\text{first} \colorbox{silver}{d}+1\ \text{bits of}\ x\\
\quad v:=T[p']\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\quad \text{return}\ v\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad\ \ \mathcal{L}_{\text{prg-rand}}^G\\\hline
\underline{\text{QUERY():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda}\\
\quad \text{return}\ G(s)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have applied the security}\\
\text{of $G$ and replaced} \mathcal{L}_{\text{prg-real}}\ \text{with}\\
\mathcal{L}_{\text{prg-rand}}. \text{The change is indistinguishable.}\\
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad p:=\text{first} \colorbox{silver}{d-1}\  \text{bits of}\ x\\
\quad \text{if}\  T[p]\ \text{undefined:}\\
\qquad \colorbox{yellow}{T}[p\|\textcolor{brown}{0}]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad \colorbox{yellow}{T}[p\|\textcolor{brown}{1}]\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad p':=\text{first} \colorbox{silver}{d}+1\ \text{bits of}\ x\\
\quad v:=T[p']\\
\quad \text{for}\ i=\colorbox{silver}{d+1}\ \text{to}\ in: \\
\qquad \text{if}\ x_i=\textcolor{brown}{0}\ \text{then}\ v:=G_L(v)\\
\qquad \text{if}\ x_i=\textcolor{brown}{1}\ \text{then}\ v:=G_R(v)\\
\quad \text{return}\ v\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have inlined $\mathcal{L}_{\text{prg-rand}}$ and split the sampling of 2$\lambda$}\\
\text{bits into two separate statements sampling  $\lambda$ bits each.}\\
\text{In this library, we advance $d$ levels down the tree, assign}\\
\text{a uniform label to a node (and its sibling), and then proceed}\\
\text{to the leaf applying $G$ as usual. The only difference}\\
\text{between this library and $\mathcal{L}_{\text{hby-d}}$ is that we sample the label}\\
\text{of a node that is not on our direct path. But since we}\\
\text{sample it uniformly, it doesn’t matter when (or if) that}\\
\text{extra value is sampled. Hence, this library has identical}\\
\text{behavior to $\mathcal{L}_{\text{hby-d}}$.}
\end{array}
$$

We showed that $\mathcal{L}_{\text{hby}-(d-1)}\approx \mathcal{L}_{\text{hby-d}}$. Putting everything together, we have:

$$\mathcal{L}_{\text{prf-real}}^F\equiv\mathcal{L}_{\text{hby-0}}\approx\mathcal{L}_{\text{hby-1}}\approx\cdots\approx \mathcal{L}_{\text{hby-in}}\equiv\mathcal{L}_{\text{prf-rand}}^F.$$

Hence, $F$ is a secure PRF.

## 6.3 Block Ciphers (Pseudorandom Permutations)

After fixing the seed of a PRF, it computes a function from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {in }}$ to $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {out }}$. Let's consider the case where *in* $=$ *out*. Some functions from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {in }}$ to $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {out }}$ are invertible, which leads to the question of whether a PRF might realize such a function and be invertible (with knowledge of the seed). In other words, what if it were possible to determine $x$ when given $k$ and $F(k, x) ?$ While this would be a convenient property, it is not guaranteed by the PRF security definition, even in the case of *in* $=$ *out*. A function from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {in }}$ to $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {out }}$ chosen at random is unlikely to have an inverse, therefore a PRF instantiated with a random key is unlikely to have an inverse.

A **pseudorandom permutation** **(PRP)** $-$ also called a **block cipher** $-$ is essentially a PRF that is guaranteed to be invertible for every choice of seed. We use both terms (PRP and block cipher) interchangeably. The term "permutation" refers to the fact that, for every $k,$ the function $F(k, \cdot)$ should be a permutation of $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{i n} .$ Instead of requiring a PRP to be indistinguishable from a randomly chosen function, we require it to be indistinguishable from a randomly chosen *invertible* function.  This means we must modify one of the libraries from the PRF definition. Instead of populating the associative array $T$ with uniformly random values, it chooses uniformly random *but distinct* values. As long as $T$ gives distinct outputs on distinct inputs, it is consistent with some invertible function. The library guarantees distinctness by only sampling values that it has not previously assigned. Thinking of an associative array $T$ as a key-value store, we use the notation $T .$ values to denote the set of values stored in $T$.


**Definition 6.6 (PRP syntax)**

Let $F:\{0,1\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$ be a deterministic function. We refer to blen as the **blocklength** of $F$ and any element of $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$ as a **block**.

We call $F$ a **secure pseudorandom permutation (PRP) (block cipher)** if the following two conditions hold:
1. (Invertible given $k$ ) There is a function $F^{-1}:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$ satisfying
$$
F^{-1}(k, F(k, x))=x
$$
for all $k \in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ and all $x \in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$
2. (Security) $\mathcal{L}_{\text {prp-real }}^{F} \approx \mathcal{L}_{\text {prp-rand }}^{F},$ where

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
k\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\\\
\underline{\text{LOOKUP}(x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{return}\ F(k,x)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash \colorbox{yellow}{T.values}\\
\quad \text{return}\ T[x]\\\hline
\end{array}
$$

"T.values" refers to the set $\{v \mid \exists x: T[x]=v\}$.

The changes from the PRF definition are highlighted in yellow. In particular, the $\mathcal{L}_{\text {prp-real }}$ and $\mathcal{L}_{\text {prf-real }}$ libraries are identical.

### Discussion, Pitfalls
In the definition, both the functions $F$ and $F^{-1}$ take the seed $k$ as input. Therefore, only someone with $k$ can invert the block cipher. Think back to the definition of a PRF without the seed $k$, it is hard to compute $F(k, x)$. A block cipher has a forward and reverse direction, and computing either of them is hard without $k !$

## 6.4 Relating PRFs and Block Ciphers
In this section we discuss how to obtain PRFs from PRPs/block ciphers, and vice-versa.


### Switching Lemma (PRPs are PRFs, Too!)

Imagine you can query a PRP on chosen inputs (as in the $\mathcal{L}_{\text {prp-real }}$ library), and suppose the blocklength of the PRP is blen $=\lambda$. You would only be able to query that PRP on a *negligible* *fraction* of its exponentially large input domain. It seems unlikely that you would even be able to tell that it was a PRP (i.e., an invertible function) rather than a PRF (an unrestricted function). 

This idea can be formalized as follows.

**Lemma 6.7 (PRP switching)**
Let $\mathcal{L}_{\text {prf-rand }}$ and $\mathcal{L}_{\text {prp-rand }}$ be defined as in Definitions $6.1 \& 6.6,$ with parameters *in* $=$ *out* $=$ blen $=\lambda$ (so that the interfaces match up). Then $\mathcal{L}_{\text {prf-rand }} \approx \mathcal{L}_{\text {prp-rand }}.$

**Proof**
Recall the replacement-sampling lemma, Lemma 4.11 , which showed that the following libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\quad\ \mathcal{L}_{\text{samp-L}}\\\hline
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad\ \mathcal{L}_{\text{samp-R}}\\\hline
R:=\emptyset\\\\
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \backslash R\\
\quad R:=R\cup\{r\}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

$\mathcal{L}_{\text{samp-L}}$ samples values with replacement, and $\mathcal{L}_{\text{samp-R}}$ samples values without replacement. Now consider the following library $\mathcal{L}^*$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad\ \ \mathcal{L}^*\\\hline
T:=\text{empty assoc. array}\\\\
\underline{\text{LOOKUP}(x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow\text{SAMP()}\\
\quad \text{return}\ T[x]\\\hline
\end{array}
$$
When we link $\mathcal{L}^{*} \diamond \mathcal{L}_{\text{samp-L}}$ we obtain $\mathcal{L}_{\text {prf-rand }}$ since the values in $T[x]$ are sampled uniformly. When we link $\mathcal{L}^{*} \diamond \mathcal{L}_{\text {samp-R }}$ we obtain $\mathcal{L}_{\text {prp-rand }}$ since the values in $T[x]$ are sampled uniformly subject to having no repeats (consider $R$ playing the role of $T .$ values in $\mathcal{L}_{\text {prp-rand }}$). Then from Lemma 4.11 , we have:
$$
\mathcal{L}_{\text {prf-rand }} \equiv \mathcal{L}^{*} \diamond \mathcal{L}_{\text {samp-L }} \approx \mathcal{L}^{*} \diamond \mathcal{L}_{\text {samp-R }} \equiv \mathcal{L}_{\text {prp-rand }},
$$
which completes the proof.

Using the switching lemma, we can conclude that every PRP (with blen $=\lambda$ ) is also a PRF:

**Corollary 6.8**
Let $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ be a secure PRP (with blen $=\lambda$ ). Then $F$ is also a secure PRF.

**Proof**
As we have observed above, $\mathcal{L}_{\text {prf-real }}^{F}$ and $\mathcal{L}_{\text {prp-real }}^{F}$ are literally the same library. Since $F$ is a secure PRP, $\mathcal{L}_{\text {prp-real }}^{F} \approx \mathcal{L}_{\text {prp-rand }}^{F} .$ Finally, by the switching lemma, $\mathcal{L}_{\text {prp-rand }}^{F} \approx \mathcal{L}_{\text {prf-rand }}^{F}$ Putting everything together:
$$
\mathcal{L}_{\text {prf-real }}^{F} \equiv \mathcal{L}_{\text {prp-real }}^{F} \approx \mathcal{L}_{\text {prp-rand }}^{F} \approx \mathcal{L}_{\text {prf-rand }}^{F}.
$$
hence $F$ is a secure PRF.

Keep in mind that the switching lemma applies only when the blocklength is sufficiently large (at least $\lambda$ bits long). This comes from the fact that $\mathcal{L}_{\text {samp-L }}$ and $\mathcal{L}_{\text {samp-R }}$ in the proof are indistinguishable only when sampling with long (length-\lambda) strings (look at the proof of Lemma 4.11 to recall why). Exercise 6.14 asks you to show that a random permutation over a small domain can be distinguished from a random (unconstrained) function; so, a PRP with a small blocklength is not a PRF.

### Constructing a PRP from a PRF: The Feistel Construction
How can you build an *invertible* block cipher out of a PRF that is not necessarily invertible?
In this section, we show a simple technique called the **Feistel construction** (named after
IBM cryptographer Horst Feistel).

The main idea in the Feistel construction is to convert a not-necessarily-invertible
function $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^n\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^n$ into an invertible function $F^*:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2n}\rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2n}$. The function $F^*$ is called the **Feistel round with round function** $F$ and is defined as follows:

**Construction 6.9 (Feistel round)**
$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
No matter what $F$ is, its Feistel round $F^*$ is invertible. Not only that, but its inverse is
a kind of “mirror image” of $F^*$:

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
Note how both the forward and inverse Feistel rounds use $F$ in the forward direction!

**Example**
Let's see what happens in the Feistel construction with a trivial round function. Consider the constant function $F(y)=\textcolor{brown}{0}^{n},$ which is the "*least invertible" function imaginable.* The Feistel construction gives:
$$
\begin{aligned}
F^{*}(x \| y) &=y \|(F(y) \oplus x) \\
&=y \|\left(\textcolor{brown}{0}^{n} \oplus x\right) \\
&=y \| x
\end{aligned}
$$
The result is a function that simply switches the order of its halves - clearly invertible.

**Example**
Let's try another simple round function, this time the identity function $F(y)=y .$ The Feistel construction gives:
$$
\begin{aligned}
F^{*}(x \| y) &=y \|(F(y) \oplus x) \\
&=y \|(y \oplus x)
\end{aligned}
$$
This function is invertible because given $y$ and $y \oplus x$ we can solve for $x$ as $y \oplus(y \oplus x) .$ You can verify that this is what happens when you plug $F$ into the inverse Feistel construction.

We can also consider using a round function $F$ that has a key/seed. The result will be an $F^{*}$ that also takes a seed. For every seed $k, F^{*}(k, \cdot)$ will have an inverse (which looks like its mirror image).

**Construction 6.10 (Keyed Feistel)**
$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
Now suppose $F$ is a secure PRF and we use it as a Feistel round function, to obtain a
keyed function $F^*$. Since $F(k,\cdot)$ is invertible for every $k$, and since $F^*$ uses a secure PRF in some way, you might be tempted to claim that $F^*$ is a secure PRP. Unfortunately, it is not! The output of $F^*$ contains half of its input, making it quite trivial to break the PRP-security of $F^*$.

We can avoid this trivial attack by performing several Feistel rounds in succession,
resulting in a construction called a **Feistel cipher**. At each round, we can even use a
different key to the round function. If we use $k_1$ in the first round, $k_2$ in the second round,
and so on, then $k_1, k_2,\ldots$ is called the **key schedule** of the Feistel cipher. The formal
denition of an r -round Feistel cipher is given below:

**Construction 6.11 (Feistel cipher)**
Because each round is invertible (given the appropriate round key), the overall Feistel cipher is also invertible. Note that the inverse of the Feistel cipher uses inverse Feistel rounds and reverses the order of the key schedule.

Surprisingly, a 3-round Feistel cipher can actually be secure, although a 2-round Feistel cipher is never secure (see the exercises). More precisely: when F is a secure PRF with *in = out* = $\lambda$, then using $F$ as the round function of a 3-round Feistel cipher results in a secure PRP. The Feistel cipher has blocklength $2\lambda$, and it has a key of length $3\lambda$(3 times longer than the key for $F$ ). Implicitly, this means that the three round keys are chosen independently.

**Theorem 6.12 (Luby-Rackoff)**
If $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ a secure PRF, then the 3-round Feistel cipher $\mathbb{F}_3$ (Construction 6.11) is a secure PRP.

Unfortunately, the proof of this theorem is beyond the scope of this book.

## 6.5 PRFs and Block Ciphers in Practice

Block ciphers are one of the cornerstones of cryptography in practice today. We have
shown how (at least in principle) block ciphers can be constructed out of simpler primitives:
PRGs and PRFs. However, in practice we use block ciphers that are designed “from
scratch,” and then use these block ciphers to construct simpler PRGs and PRFs when we
need them.

We currently have **no proof** that any secure PRP exists. Aswe discussed in Section 5.2,
such a proof would resolve the famous P vs NP problem. Without such proofs, what is our
basis for confidence in the security of block ciphers being used today? The process that led
to the Advanced Encryption Standard (AES) block cipher demonstrates the cryptographic
community’s best efforts at instilling such confidence.

The National Institute of Standards & Technology (NIST) sponsored a competition to design a block cipher to replace the DES standard from the 1970s. Many teams of cryptographers
submitted their block cipher designs, all of which were then subject to years of intense public scrutiny by the cryptographic research community. The designs were evaluated on the basis of their performance and resistance to attacks against the PRP security definition (and other attacks). Some designs did offer proofs that they resist certain *classes of attacks*, and proofs that justify certain choices in building the block cipher from simpler components.

The Rijndael cipher, designed by Vincent Rijmen and Joan Daemen, was selected as the winner and became the AES standard in 2001. There may not be another cryptographic algorithm that has been the focus of more scrutiny and attempts at attack. So far no significant weaknesses in AES are known.

The AES block cipher has a blocklength of 128 bits, and oers 3 different variants with 128-bit, 192-bit, and 256-bit keys. As a result of its standardization, AES is available in cryptographic libraries for any programming language. It is even implemented as hardware instructions in most modern processors, allowing millions of AES evaluations per second. As we have seen, once you have access to a good block cipher, it can be used directly also as a secure PRF (Corollary 6.8), and it can be used to construct a simple PRG (Construction 6.2). Even though AES itself is not a *provably secure* PRP, these constructions of PRFs and PRGs based on AES are secure. Or, more precisely, the PRF-security and PRG-security of these constructions is guaranteed to be as good as the PRP-security of AES.

## $\star\quad$ 6.6  Strong Pseudorandom Permutations
Since a block cipher $F$ has a corresponding inverse $F ^{-1}$, it is natural to think of $F$ and $F ^{-1}$ as interchangeable in some sense. However, the PRP security definition only guarantees a security property for $F$ and not its inverse. In the exercises, you will see that it is possible to construct $F$ which is a secure PRP, whose inverse $F^{-1}$ is not a secure PRP!

It would be very natural to ask for a PRP whose $F$ and $F ^{-1}$ are both secure. We will later  see applications where this property would be convenient. An even stronger requirement would allow the distinguisher to query both $F$ and $F ^{-1}$ in a single interaction (rather than one security definition where the distinguisher queries only F , and another definition where the distinguisher queries only $F ^{-1}$). If a PRP is indistinguishable from a random permutation under that setting, then we say it is a **strong PRP** (SPRP).

In the formal security definition, we provide the calling program two subroutines: one for forward queries and one for reverse queries. In $\mathcal{L}_{\text{sprp-real}}$, these subroutines are implemented by calling the PRP or its inverse accordingly. In $\mathcal{L}_{\text{sprp-real}}$ we emulate the behavior of a randomly chosen permutation that can be queried in both directions. We maintain two associative arrays $T$ and $T_{inv}$ to hold the truth tables of these permutations, and sample their values on-demand. The only restriction is that  $T$ and $T_{inv}$ maintain consistency $(T[x]=y$ if and only if $T_{inv}[y]=x)$. This also ensures that they always represent an invertible function. We use the same technique as before to ensure invertibility.

**Definition 6.13 (SPRP security)**
Let $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}$ be a deterministic function. We say that F is a **secure strong pseudorandom permutation (SPRP)** if $\mathcal{L}_{\text{sprp-real}}^F\approx \mathcal{L}_{\text{sprp-rand}}^F$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \ \ \mathcal{L}_{\text{sprp-real}}^F\\\hline
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\\\
\underline{\text{LOOKUP}(x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{return}\ F(k,x)\\\\
\underline{\text{INVLOOKUP}(y\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{return}\ F^{-1}(k,y)\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad\qquad \ \ \mathcal{L}_{\text{sprp-rand}}^F\\\hline
T,T_{inv}:=\text{empty assoc. arrays}\\\\
\underline{\text{LOOKUP}(x\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{if}\ T[x]\ \text{undefined}:\\
\qquad y\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T.\text{values}\\
\qquad T[x]:=y:\quad T_{inv}[y]:=x\\
\quad \text{return}\ T[x]\\
\underline{\text{INVLOOKUP}(y\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}):}\\
\quad \text{if}\ T_{inv}[y]\ \text{undefined}:\\
\qquad x\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T_{inv}.\text{values}\\
\qquad T_{inv}[y]:=x:\quad T[x]:=y\\
\quad \text{return}\ T_{inv}[y]\\\hline
\end{array}
$$

Earlier we showed that using a PRF as the round function in a 3-round Feistel cipher results in a secure PRP. However, that PRP is **not** a *strong* PRP. Even more surprisingly, adding an extra round to the Feistel cipher does make it a strong PRP! We present the following theorem without proof:

**Theorem 6.14 (Luby-Rackoff)**

Let $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ is a secure PRF, then the 4-round Feistel cipher $\mathbb{F}_4$ (Construction 6.11) is a secure SPRP.

### Exercises

6.1. In this problem, you will show that it is hard to determine the key of a PRF by querying the PRF.

Let $F$ be a candidate PRF, and suppose there exists a program $\mathcal{A}$ such that:

$$\text{Pr}[\mathcal{A}\diamond\mathcal{L}_{\text{prf-real}}^F\ \text{outputs}\ k]\ \text{is non-negligible:}$$

In the above expression, $k$ refers to the private variable within $\mathcal{L}_{\text{prf-real}}$.

Prove that if such an $\mathcal{A}$ exists, then $F$ is not a secure PRF. Use$\mathcal{A}$ to construct a distinguisher that violates the PRF security definition.

6.2. Let F be a secure PRF.

(a) Let $m\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}$ be a fixed (public, hard-coded, known to the adversary) string. Define: 

$$F_m(k,x)=F(k,x)\oplus m.$$

Prove that for every $m, F_m$ is a secure PRF.

(b) Define
$$
F^{\prime}(k, x)=F(k, x) \oplus x
$$
Prove that $F^{\prime}$ is a secure PRF.

6.3. Let $F$ be a secure PRF with $\lambda$ -bit outputs, and let $G$ be a PRG with stretch $\ell$. Define
$$
F^{\prime}(k, r)=G(F(k, r))
$$
So $F^{\prime}$ has outputs of length $\lambda+\ell$. Prove that $F^{\prime}$ is a secure PRF.

6.4. Let $F$ be a secure PRF with $i n=2 \lambda,$ and let $G$ be a length-doubling $\mathrm{PRG}$. Define
$$
F^{\prime}(k, x)=F(k, G(x))
$$
We will see that $F^{\prime}$ is not necessarily a PRF.

(a) Prove that if $G$ is injective then $F^{\prime}$ is a secure PRF.
> Hint: You should not even need to use the fact that G is a PRG.
> 
$\star$ (b) Exercise 5.9 (b) constructs a secure length-doubling PRG that ignores half of its input Show that $F^{\prime}$ is insecure when instantiated with such a PRG. Give a distinguisher and compute its advantage.
 Note: You are not attacking the PRF security of $F,$ nor the PRG security of $G$. You are attacking the invalid way in which they have been combined.
 
6.5. Let $F$ be a secure PRF, and let $m \in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {in }}$ be a fixed (therefore known to the adversary) string. Define the new function
$$
F_{m}(k, x)=F(k, x) \oplus F(k, m).
$$
Show that $F_{m}$ is **not** a secure PRF. Describe a distinguisher and compute its advantage.

$\star \ 6.6 .$ In the previous problem, what happens when $m$ is secret and part of the PRF seed? Let $F$ be a secure PRF, and define the new function: Define the new function
$$
F^{\prime}((k, m), x)=F(k, x) \oplus F(k, m).
$$
The seed of $F^{\prime}$ is $(k, m)$, which you can think of as a $\lambda+i n$ bit string. Show that $F^{\prime}$ is indeed a secure PRF.
>Hint: Rewrite the $F'$ algorithm to include an “if x = m” clause and argue that the calling program can rarely satisfy this clause.

6.7. Let $F$ be a secure PRF. Let $\overline{x}$ denote the bitwise complement of the string $x$. Define the new function:
$$
F^{\prime}((k, x)=F(k, x) \| F(k, \overline{x}).
$$
Show that $F'$ is **not** a secure PRF. Describe a distinguisher and compute its advantage.

6.8. Suppose $F$ is a secure PRF with input length in, but we want to use it to construct a PRF with longer input length. Below are some approaches that don’t work. For each one, describe a successful distinguishing attack and compute its advantage:

(a) $F^{\prime}\left(k, x \| x^{\prime}\right)=F(k, x) \| F\left(k, x^{\prime}\right),$ where $x$ and $x^{\prime}$ are each *in* bits long.
(b) $F^{\prime}\left(k, x \| x^{\prime}\right)=F(k, x) \oplus F\left(k, x^{\prime}\right),$ where $x$ and $x^{\prime}$ are each *in* bits long.
(c) $F^{\prime}\left(k, x \| x^{\prime}\right)=F(k, x) \oplus F\left(k, x \oplus x^{\prime}\right),$ where $x$ and $x^{\prime}$ are each *in* bits long.
(d) $F^{\prime}\left(k, x \| x^{\prime}\right)=F(k, \textcolor{brown}{0} \| x) \oplus F\left(k, \textcolor{brown}{1} \| x^{\prime}\right),$ where $x$ and $x^{\prime}$ are each *in*-$1$ bits long.

6.9. Define a PRF $F$ whose key $k$ we write as $\left(k_{1}, \ldots, k_{i n}\right),$ where each $k_{i}$ is a string of length out. Then $F$ is defined as:
$$
F(k, x)=\bigoplus_{i \times x_{i}=1} k_{i}.
$$
Show that $F$ is not a secure PRF. Describe a distinguisher and compute its advantage.

6.10. Define a PRF $F$ whose key $k$ is an *in* $\times 2$ array of out-bit strings, whose entries we refer to as $k[i, b]$. Then $F$ is defined as:
$$
F(k, x)=\bigoplus_{i=1}^{i n} k\left[i, x_{i}\right].
$$
Show that $F$ is **not** a secure PRF. Describe a distinguisher and compute its advantage.

6.11. A function $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ is chosen uniformly at random. What is the probability that the function is invertible?

6.12. Let $F$ be a secure PRP with blocklength *blen* $=128 .$ Then for each $k,$ the function $F(k,\cdot)$ is a permutation on $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{128}$. Suppose I choose a permutation on $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{128}$ uniformly at random. What is the probability that the permutation I chose agrees with a permutation of the form $F(k,\cdot) ?$ Compute the probability as an actual number $-$ is it a reasonable probability or a tiny one?

6.13. Suppose $R:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ is chosen uniformly among all such functions. What is the probability that there exists an $x \in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ such that $R(x)=x ?$
>Hint: First find the probability that $R(x)\neq x$ for all $x$. Simplify your answer using the approximation $(1-y)\approx e^{-y}$.
>
6.14. In this problem, you will show that the PRP switching lemma holds only for large domains. Let $\mathcal{L}_{\text {prf-rand }}$ and $\mathcal{L}_{\text {prp-rand }}$ be as in Lemma $6.7 .$ Choose any small value of blen $=$ in $=$ out that you like, and show that $\mathcal{L}_{\text {prf-rand }} \not\approx \mathcal{L}_{\text {prp-rand }}$ with those parameters. Describe $\mathbf{a}$ distinguisher and compute its advantage.

>Hint: Remember that the distinguisher needs to run in polynomial time in$\lambda$, but not necessarily polynomial in blen.

6.15. Let $F:\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{in} \rightarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}$ be a (not necessarily invertible) function. We showed how to
use F as a round function in the Feistel construction ony when *in = out*.

Describe a modification of the Feistel construction that works even when the round function satisfies *in* $\neq$ *out*. The result should be an invertible with input/output length *in+out*. Be sure to show that your proposed transform is invertible! You are not being asked to show any security properties of the Feistel construction.

6.16. Showthat a 1-round keyed Feistel cipher **cannot** be a secure PRP, no matter what its round functions are. That is, construct a distinguisher that successfully distinguishes $\mathcal{L}_{\text{prp-real}}^F$ and $\mathcal{L}_{\text{prp-rand}}^F$, knowing only that F is a 1-round Feistel cipher. In particular, the purpose is to attack the Feistel transform and not its round function, so your attack should work no matter what the round function is.

6.17. Showthat a 2-round keyed Feistel cipher cannot be a secure PRP, no matter what its round
functions are. Your attack should work without knowing the round keys, and it should work even with different (independent) round keys.
>Hint: A successful attack requires two queries.
>
6.18. Show that any function F that is a 3-round keyed Feistel cipher **cannot** be a secure *strong* PRP. As above, your distinguisher shouldwork without knowing what the round functions
are, and the attack should work with different (independent) round functions.

6.19. In this problem you will show that PRPs are hard to invert without the key (if the blocklength is large enough). Let $F$ be a candidate PRP with blocklength blen $\geqslant \lambda$. Suppose there is a program $\mathcal{A}$ where:
$$
\underset{y \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}}{\operatorname{Pr}}\left[\mathcal{A}(y) \diamond \mathcal{L}_{\text {prf-real }}^{F} \text { outputs } F^{-1}(k, y)\right] \text { is non-negligible. }
$$
The notation means that $\mathcal{A}$ receives a random block $y$ as an input (and is also linked to $\left.\mathcal{L}_{\text {prf-real }}\right) . k$ refers to the private variable within $\mathcal{L}_{\text {prf-real. }}$ So, when given the ability to evaluate $F$ in the forward direction only (via $\mathcal{L}_{\text {prf-real }}$ ), $\mathcal{A}$ can invert a uniformly chosen block $y$

Prove that if such an $\mathcal{A}$ exists, then $F$ is not a secure PRP. Use $\mathcal{A}$ to construct a distinguisher that violates the PRP security definition. Where do you use the fact that blen $\geqslant \lambda ?$ How do you deal with the fact that $\mathcal{A}$ may give the wrong answer with high probability?

6.20. Let $F$ be a secure PRP with blocklength blen $=\lambda$, and consider $\widehat{F}(k, x)=F(k, k) \oplus F(k, x)$.

 $\quad$(a) Show that $\widehat{F}$ is not a strong PRP (even if $F$ is).
$\ \star$ (b) Show that $\widehat{F}$ is a secure (normal) PRP.


# 7 Security Against Chosen Plaintext Attacks

Our previous security definitions for encryption capture the case where a key is used to encrypt only one plaintext. Clearly it would be more useful to have an encryption scheme that allows many plaintexts to be encrypted under the same key.

Fortunately we have arranged things so that we get the “correct” security definition when we modify the earlier definition in a natural way. We simply let the libraries choose a secret key once and for all, which is used to encrypt all plaintexts. More formally:

**Definition 7.1 (CPA security)**
Let $\Sigma$ be an encryption scheme. We say that $\Sigma$ has **security against chosen-plaintext attacks (CPA security**) if $\mathcal{L}_{\text{cpa-L}}^{\Sigma}\approx\mathcal{L}_{\text{cpa-R}}^{\Sigma}$ where:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \qquad \ \mathcal{L}_{\text{cpa-L}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{EAVESDROP}(m_L,m_R\in \Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\text{Enc}(l,\colorbox{yellow}{m}_L)\\
\quad \text{return}\ c\\\hline
\end{array}\quad
\begin{array}{|l|}\hline
\qquad\qquad \qquad \ \mathcal{L}_{\text{cpa-R}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{EAVESDROP}(m_L,m_R\in \Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\text{Enc}(l,\colorbox{yellow}{m}_R)\\
\quad \text{return}\ c\\\hline
\end{array}
$$

Notice how the key k is chosen at initialization time and is static for all calls to Enc. CPA security is often called “IND-CPA” security, meaning “indistinguishability of ciphertexts under chosen-plaintext attack.”

## 7.1 Limits of Deterministic Encryption

We have already seen block ciphers / PRPs, which seem to satisfy everything needed for a secure encryption scheme. For a block cipher, $F$ corresponds to encryption, $F ^{-1}$ corresponds to decryption, and all outputs of $F$ look pseudorandom. What more could you ask for in a good encryption scheme?

**Example**
We will see that a block cipher, when used “as-is,” is **not** a CPA-secure encryption scheme. Let
F denote the block cipher and suppose its block length is $blen$.

Consider the following adversary $\mathcal{A}$, that tries to distinguish the $\mathcal{L}_{\text{cpa}-\star}$ libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \qquad \ \mathcal{A}\\\hline
c_1:=\text{EAVESDROP}(\textcolor{brown}{0}^{blen},\textcolor{brown}{0}^{blen})\\
c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{blen},\textcolor{brown}{1}^{blen})\\
\text{return}\ c_1\stackrel{?}{=} c_2\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \qquad \ \mathcal{A}\\\hline
c_1:=\text{EAVESDROP}(\textcolor{brown}{\colorbox{yellow}{0}}^{blen},\textcolor{brown}{0}^{blen})\\
c_2:=\text{EAVESDROP}(\textcolor{brown}{\colorbox{yellow}{0}}^{blen},\textcolor{brown}{1}^{blen})\\
\text{return}\ c_1\stackrel{?}{=} c_2\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\qquad \quad \ \mathcal{L}_{\text{cpa-L}}^\Sigma\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=F(k,\colorbox{yellow}{m}_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{cpa-L}}$, the}\\
\text{EAVESDROP \textit{algorithm} will encrypt}\\
\text{its first argument. So, $c_1$ and $c_2$}\\
\text{will both be computed as $F(k,\textcolor{brown}{0}^{blen})$.}\\
\text{Since $F$ is a deterministic function, this}\\
\text{results in identical outputs from EAVESDROP.}\\
\text{In other words $c_1 = c_2$, and $\mathcal{A} \diamond \mathcal{L}_{\text{cpa-L}}$}\\ \text{\bf{always} outputs 1.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \qquad \ \mathcal{A}\\\hline
c_1:=\text{EAVESDROP}(\textcolor{brown}{\colorbox{yellow}{0}}^{blen},\textcolor{brown}{0}^{blen})\\
c_2:=\text{EAVESDROP}(\textcolor{brown}{\colorbox{yellow}{0}}^{blen},\textcolor{brown}{1}^{blen})\\
\text{return}\ c_1\stackrel{?}{=} c_2\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\qquad \ \ \mathcal{L}_{\text{cpa-R}}^\Sigma\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=F(k,\colorbox{yellow}{m}_R)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{cpa-R}}$, the}\\
\text{EAVESDROP \textit{algorithm} will encrypt}\\
\text{its second argument. So, $c_1$ and $c_2$}\\
\text{are computed as $c_1=F(k,\textcolor{brown}{0}^{blen})$.}\\
\text{and $c_2=F(k,\textcolor{brown}{1}^{blen}).$ Since F is a}\\
\text{permutation, $c_1 \neq c_2$, so $\mathcal{A} \diamond \mathcal{L}_{\text{cpa-R}}$}\\ \text{\bf{never} outputs 1.}
\end{array}
$$

This adversary has advantage 1 in distinguishing the libraries, so the bare block cipher $F$
is not a CPA-secure encryption scheme.

### Impossibility of Deterministic Encryption
The reason a bare block cipher does not provide CPA security is that it is **deterministic**. Calling Enc$(k,m)$ twice — with the same key and same plaintext — leads to the same ciphertext.
Even one-time pad is deterministic. One of the first and most important aspects of CPA security is that it is incompatible with deterministic encryption. Deterministic encryption can never be CPA-secure! In other words, we can attack the CPA-security of any scheme $\Sigma$, knowing only that it has deterministic encryption. The attack is a simple generalization of our attack against a bare PRP:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\qquad \qquad \qquad \quad \mathcal{A}\\\hline
\text{arbitrarily choose \textit{distinct} plaintexts}\ x,y\in\mathcal{M}\\
c_1:=\text{EAVESDROP}(x,x)\\
c_2:=\text{EAVESDROP}(x,y)\\
\text{return}\ c_1\stackrel{?}{=} c_2\\\hline
\end{array}
$$

A good way to think about what goes wrong with deterministic encryption is that it **leaks whether two ciphertexts encode the same plaintext**, and this is not allowed by CPA security. Think of sealed envelopes as an analogy for encryption. I shouldn’t be able to tell whether two sealed envelopes contain the same text! We are only now seeing this issue because this is the first time our security definition allows an adversary to see multiple ciphertexts encrypted under the same key.

### Avoiding Deterministic Encryption
Is CPA security even possible? How exactly can we make a non-deterministic encryption scheme? This sounds challenging! We must design an Enc algorithm such that calling it twice with the same plaintext and key results in different ciphertexts (otherwise the attack $\mathcal{A}$ above violates CPA security). What’s more, it must be possible to decrypt all of those different encryptions of the same plaintext to the correct value!

There are 3 general ways to design an encryption scheme that is not deterministic:

 - Encryption/decryption can be **stateful**, meaning that every call to Enc or Dec will actually modify the value of k. The symmetric ratchet construction described in Section 5.5 could be thought of as such a stateful construction. The key is updated via the ratchet mechanism for every encryption. A significant drawback with stateful encryption is that synchronization between sender and receiver is fragile and can be broken if a ciphertext is lost in transit.
 
 - Encryption can be **randomized**. Each time a plaintext is encrypted, the Enc algorithm chooses fresh, independent randomness specific to that encryption. The main challenge in designing a randomized encryption method is to incorporate randomness into each ciphertext in such a way that decryption is still possible. Although this sounds quite challenging, we have already seen such a method, and we will prove its CPA security in the next sections. In this book we will focus almost entirely on randomized encryption.
 - Encryption can be **nonce-based**. A “nonce” stands for “number used only once,” and it refers to an extra argument that is passed to the Enc and Dec algorithms. A nonce does not need to be chosen randomly; it does not need to be secret; it only needs to be **distinct** among all calls made to Enc. By guaranteeing that some input to Enc will be different every time (even when the key and plaintext are repeated), the Enc algorithm can be deterministic and still provide CPA security.
 Nonce-based encryption requires a change to the interface of encryption, and therefore a change to the correctness & security definitions as well. The encryption/decryption algorithms syntax is updated to $\text{Enc}(k,v,m)$ and $\text{Dec}(k,v, c)$, where v is a nonce. The correctness property is that $\text{Dec}(k,v,\text{Enc}(k,v,m))$ = $m$ for all $k,v,m$, so both encryption & decryption algorithms should use the same nonce. The security definition allows the adversary to choose the nonce, but gives an error if the adversary tries to encrypt multiple ciphertexts with the same nonce. In this way, the definition enforces that the nonces are distinct.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k\leftarrow\Sigma.\text{KeyGen}\\
\colorbox{yellow}{V:=}\emptyset\\\\
\underline{\text{EAVESDROP}(\colorbox{yellow}{v},m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{\text{if}\ V}\in V:\text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \colorbox{yellow}{V:=V}\cup\{v\}\\
\quad c:=\Sigma.\text{Enc}(k,\colorbox{yellow}{v},m_L)\\
\quad\text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
k\leftarrow\Sigma.\text{KeyGen}\\
\colorbox{yellow}{V:=}\emptyset\\\\
\underline{\text{EAVESDROP}(\colorbox{yellow}{v},m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{\text{if}\ V}\in V:\text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \colorbox{yellow}{V:=V}\cup\{v\}\\
\quad c:=\Sigma.\text{Enc}(k,\colorbox{yellow}{v},m_R)\\
\quad\text{return}\ c\\\hline
\end{array}
$$
Note that the calling program provides a single value $v$ (not a $v_L$ and $v_R$). Both libraries use the nonce $v$ that is given, and this implies that the encryption scheme does not need to *hide* $v$. If something is the same between both libraries, then it is not necessary to hide it in order to make the libraries indistinguishable.

If an encryption scheme does not fall into one of these three categories, it cannot satisfy our definition of CPA-security. You can and should use deterministic encryption as a sanity check against any proposed encryption algorithm.

## 7.2 Pseudorandom Ciphertexts

When we introduced one-time security of encryption (in Section 2.2), we had two variants
of the definition. The more general variant said, roughly, that encryptions of $m_L$ should
look like encryptions of $m_R$. The more specific variant said that encryptions of every m
should look uniform.

We can do something similar for CPA security, by defining a security definition that says “encryptions of $m$ look uniform.” Note that it is not sufficient to use the same security libraries from the one-time security definition. It is important for the library to allow multiple encryptions under the same key. Just because a single encryption is pseudorandom, it doesn’t mean that multiple encryptions appear *jointly* pseudorandom. In particular, they may not look *independent* (this was an issue we saw when discussing the difficulty of constructing a PRF from a PRG).

**Definition 7.2 (CPA$\varPhi$ security)**
Let $\Sigma$ be an encryption scheme. We say that $\Sigma$ has **pseudorandom ciphertexts in the presence of chosen-plaintext attacks (CPA$\varPhi$ security)** if $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\approx\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$ where:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\ \ \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{CTXT}(m\in\Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\text{Enc}(k,m)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad\ \ \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma\\\hline
\underline{\text{CTXT}(m\in\Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\mathcal{C}\\
\quad \text{return}\ c\\\hline
\end{array}
$$

This definition is also called “IND$-CPA”, meaning “indistinguishable from random under chosen plaintext attacks.” This definition will be useful to use since:

 - It is easier to prove CPA$\varPhi$ security than to prove CPA security. Proofs for CPA security tend to be about twice as long and twice as repetitive, since they involve getting to a “half-way hybrid” and then performing the same sequence of hybrids steps in reverse. Taking the proof only to the same half-way point is generally enough to prove CPA$\varPhi$ security

 - CPA$\varPhi$ security implies CPA security. We show this below, but the main idea is the same as in the case of one-time security. If encryptions of all plaintexts look uniform, then encryptions of $m_L$ look like encryptions of $m_R$. 
 
 - Most of the schemes we will consider achieve CPA$\varPhi$ anyway.

Still, most of our high-level discussion of security properties will be based on CPA security. It is the “minimal” (i.e., least restrictive) definition that appears to capture our security intuitions.

**Claim 7.3**
If an encryption scheme has CPA$\varPhi$ security, then it also has CPA security.

**Proof**
We want to prove that $\mathcal{L}_{\text{cpa-L}}^\Sigma\approx\mathcal{L}_{\text{cpa-R}}^\Sigma$, *using* the assumption that  $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\approx\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$. The sequence of hybrids follows:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\ \ \mathcal{L}_{\text{cpa-L}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=\Sigma.\text{Enc}(k,m_L)\\
\quad \text{return}\ c\\\hline
\end{array}\qquad \text{The starting point is}\ \mathcal{L}_{\text{cpa-L}}^\Sigma, \text{as expected.}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=\colorbox{yellow}{\text{CTXT}}(m_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\ \ \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{CTXT}(m):}\\
\quad c:=\Sigma.\text{Enc}(k,m)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{It may look strange, but we have further}\\
\text{factored out the call to Enc into a subroutine.}\\
\text{It looks like everything from $\mathcal{L}_{\text{cpa-L}}$ has been}\\
\text{factored out, but actually the original library}\\
\text{still “makes the choice” of which of $m_L,m_R$}\\
\text{to encrypt.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=\text{CTXT}(m_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\ \  \ \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma\\\hline
\underline{\text{CTXT}(m):}\\
\quad c:=\Sigma.\mathcal{C}\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have replaced $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma$\ with\ $\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$.}\\
\text{By our assumption, the change is indistinguishable.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=\text{CTXT}(\colorbox{yellow}{m}_R)\\
\quad \text{return}\ c\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\ \  \ \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma\\\hline
\underline{\text{CTXT}(m):}\\
\quad c\leftarrow\Sigma.\mathcal{C}\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have changed the argument being}\\
\text{passed to CTXT. This has no effect on the}\\
\text{library’s behavior since CTXT completely}\\
\text{ignores its argument in these hybrids.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad c:=\text{CTXT}(m_R)\\
\quad \text{return}\ c\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\ \  \ \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{CTXT}(m):}\\
\quad c\leftarrow\Sigma.\text{Enc}(k,m)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The mirror image of a previous step; we}\\
\text{replace $\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$ with $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma$.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad  \ \mathcal{L}_{\text{cpa-R}}^\Sigma\\\hline
\colorbox{yellow}{k}\leftarrow\Sigma.\text{KeyGen}\\\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \colorbox{yellow}{c:=}\Sigma.\text{Enc}(k,m_R)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}$ library has been inlined,}\\
\text{and the result is $\mathcal{L}_{\text{cpa-R}}^\Sigma$.}
\end{array}
$$

The sequence of hybrids shows that $\mathcal{L}_{\text{cpa-L}}^\Sigma\approx\mathcal{L}_{\text{cpa-R}}^\Sigma$, as desired.

## 7.3 CPA-Secure Encryption Based On PRFs

CPA security presents a significant challenge; its goals seem difficult to reconcile. On the one hand, we need an encryption method that is randomized, so that each plaintext $m$ is mapped to a large number of potential ciphertexts. On the other hand, the decryption method must be able to recognize all of these various ciphertexts as being encryptions of $m$.

However, we have already seen a way to do this! In Chapter 6 we motivated the concept of a PRF with the following encryption technique. If Alice and Bob share a huge table $T$ initialized with uniform data, then Alice can encrypt a plaintext $m$ to Bob by saying something like "this is encrypted with one-time pad, using key #674696273" and sending $T[674696273] \oplus m$. Seeing the number 674696273 doesn't help the eavesdropper know what $T[674696273]$ is. A PRF allows Alice $\&$ Bob to do the same encryption while sharing only a short key $k$. Instead of a the huge table $T$, they can instead use a PRF $F(k, \cdot)$ to derive a common pseudorandom value. Knowing a value $r$ doesn't help the adversary predict $F(k, r),$ when $k$ is secret.

So, translated into more precise PRF notation, an encryption of $m$ will look like $(r, F(k, r) \oplus m) .$ Since Bob also has $k,$ he can decrypt any ciphertext of this form by computing $F(k, r)$ and XOR'ing the second ciphertext component to recover $m .$

It remains to decide how exactly Alice will choose $r$ values. We argued, informally, that as long as these $r$ values don't repeat, security is preserved. This is indeed true, and the distinctness of the $r$ values is critical. Recall that there are 3 ways to avoid deterministic encryption, and all 3 of them would work here:
- In a **stateful** encryption, $r$ could be used as a counter. Use $r=i$ to encrypt/decrypt the $i$ th ciphertext.
- In a **randomized** encryption, choose $r$ uniformly at random for each encryption. If the $r$ values are long enough strings, then repeating an $r$ value should be negligibly likely.
- In a **nonce-based** encryption, we can simply let $r$ be the nonce. In the nonce-based setting, it is guaranteed that these values won't repeat.

In this section we will show the security proof for the case of randomized encryption, since it is the most traditional setting and also somewhat more robust than the others.

The exercises explore how the nonce-based approach is more fragile when this scheme is
extended in natural ways.

**Construction 7.4**
Let $F$ be a secure PRF with *in* = $\lambda$. Define the following encryption scheme based on $F$ :

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\begin{array}{ll}
& \underline{\text { Enc }(k, m):}\\
\mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  &\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\ \mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {out }} &\quad x:=F(k, r) \oplus m \\
 C=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \times\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {out }} &\quad \text { return }(r, x) \\\\
 \underline{\text { KeyGen: }} & \underline{\operatorname{Dec}(k,(r, x)):}\\
 \quad k \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} &\quad m:=F(k, r) \oplus x\\
 \quad\text{return}\ k &\quad \text{return}\ m
 \end{array}\\\hline
\end{array}
$$

It is easy to check that the scheme satisfies the correctness property.

**Claim 7.5**
Construction 7.4 has CPAS security (and therefore CPA security) if $F$ is a secure PRF.

The proof has more steps than other proofs we have seen before, and some steps are subtle. So let us use a Socratic dialogue to illustrate the strategy behind the proof:

**SALVIATI:** 
The ciphertexts of Construction 7.4 are indistinguishable from uniform randomness.

**SIMPLICIO:** 
Salviati, you speak with such confidence! Do tell me why you say that these ciphertexts appear pseudorandom.

**SALVIATI:** 
Simple! The ciphertexts have the form $(r, F(k, r) \oplus m) .$ By its very definition, $r$ is chosen uniformly, while $F(k, r) \oplus m$ is like a one-time pad ciphertext which is also uniformly distributed.

**SIMPLICIO:** 
 Your statement about $r$ is self-evident but $F(k, r) \oplus m$ confuses me. This does not look like the one-time pad that we have discussed. For one thing, the same $k$ is used "every time," not "one-time."

**SALVIATI:** 
 I did say it was merely "like" one-time pad. The one-time pad "key" is not k but $F(k, r)$. And since $F$ is a pseudorandom function, all its outputs will appear independently uniform (not to mention uncorrelated with their respectiver), even when the same seed is used every time. Is this not what we require from a one-time pad key?

**SIMPLICIO:** 
 I see, but surely the outputs of $F$ appear independent only when its inputs are distinct? I know that $F$ is deterministic, and this may lead to the same "onetime pad key" being used on different occasions.

**SALVIATI:** 
Your skepticism serves you well in this endeavor, Simplicio. Indeed, the heart of your concern is that Alice may choose $r$ such that it repeats. I say that this is negligibly likely, so that we can safely ignore such a bothersome event.

**SIMPLICIO:** 
 Bothersome indeed, but why do you say that $r$ is unlikely to repeat?
 
**SALVIATI:**
Oh Simplicio, now you are becoming bothersome! This value $r$ is $\lambda$ bits long and chosen uniformly at random each time. Do you not recall our agonizingly long discussion about the birthday paradox? 

**SIMPLICIO:** 
Oh yes, now I remember it well. Now I believe I understand all of your reasoning: Across all ciphertexts that are generated, $r$ is unlikely to repeat because of the birthday paradox. Now, provided that $r$ never repeats, Alice invokes the PRF on distinct inputs. A PRF invoked on distinct inputs provides outputs that are uniformly random for all intents and purposes. Hence, using these outputs as one-time pads completely hides the plaintext. Is that right, Salviati?

**SALVIATI:**
Excellent! Now we may return to discussing the motion of the Sun and Earth $\ldots$

Look for Simplicio’s final summary to be reflected in the sequence of hybrids used in the formal proof:

**Proof**
We prove that $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\approx\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$ using the hybrid technique:

$$
\def\arraystretch{1.5}
 \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma:\ \ 
\begin{array}{|l|}\hline
\qquad  \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\\\
\underline{\text{CTXT}(m):}\\
\quad \colorbox{yellow}{r}\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \colorbox{yellow}{x:=}F(k,r)\oplus m\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The starting point is $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma$. The details}\\
\text{of $\Sigma$ have been filled in and highlighted.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \colorbox{yellow}{z:=}\text{LOOKUP}(r) \\
\quad x:=\colorbox{yellow}{z}\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{prf-real}}^F\\\hline
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\\\
\underline{\text{LOOKUP}(r):}\\
\quad \text{return}\ F(k,r)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The statements pertaining to the PRF have}\\
\text{been factored out in terms of the  $\mathcal{L}_{\text{prf-real}}^F$}\\
\text{library.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad z:=\text{LOOKUP}(r) \\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(r):}\\
\quad\text{if}\ T [r ]\ \text{undefined:}\\
\qquad T[r]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ T[r]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have replaced $\mathcal{L}_{\text{prf-real}}^F$ with $\mathcal{L}_{\text{prf-rand}}^F$.}\\
\text{From the PRF security of $F$ , these two hybrids}\\
\text{are indistinguishable.}
\end{array}
$$

At this point in the proof, it is easy to imagine that we are done. Ciphertexts have the form $(r , x)$, where $r$ is chosen uniformly and $x$ is the result of encrypting the plaintext with what appears to be a one-time pad. Looking more carefully, however, the “one-time pad key" is $T[r]-$ a value that could potentially be used more than once if $r$ is ever repeated! 

As Simplicio rightly pointed out, a PRF gives independently random(-looking) outputs when called on distinct inputs. But in our current hybrid there is no guarantee that PRF inputs are distinct! Our proof must explicitly contain reasoning about why PRF inputs are unlikely to be repeated. We do so by appealing to the sampling-with-replacement lemma of Lemma 4.11 .

We first factor out the sampling of $r$ values into a subroutine. The subroutine corresponds to the $\mathcal{L}_{\text {samp-L }}$ library of Lemma 4.11 :

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow\colorbox{yellow}{SAMP()}\\
\quad z:=\text{LOOKUP}(r) \\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(r):}\\
\quad\text{if}\ T [r ]\ \text{undefined:}\\
\qquad T[r]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ T[r]\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{samp-L}}\\\hline
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Next, $\mathcal{L}_{\text{samp-L}}$ is replaced by $\mathcal{L}_{\text{samp-R}}$. By Lemma 4.11, the difference is indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow\colorbox{yellow}{SAMP()}\\
\quad z:=\text{LOOKUP}(r) \\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(r):}\\
\quad\text{if}\ T [r ]\ \text{undefined:}\\
\qquad T[r]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ T[r]\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{samp-R}}\\\hline
R:=\emptyset\\\\
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\backslash R\\
\quad R:=R\cup\{r\}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Inspecting the previous hybrid, we can reason that the arguments to lookup are guaranteed to never repeat. Therefore the $\mathcal{L}_{\text{prf-rand}}^F$ library can be greatly simplified. In particular, the if-condition in $\mathcal{L}_{\text{prf-rand}}^F$ is always true. Simplifying has no effect on the library’s output behavior:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow SAMP()\\
\quad z:=\text{LOOKUP}(r) \\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\underline{\text{LOOKUP}(r):}\\
\qquad t\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ t\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \mathcal{L}_{\text{samp-R}}\\\hline
R:=\emptyset\\\\
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\backslash R\\
\quad R:=R\cup\{r\}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Now we are indeed using unique one-time pads to mask the plaintext. We are in much better shape than before. Recall that our goal is to arrive at a hybrid in which the outputs of CTXT are chosen uniformly. These outputs include the value $r$ , but now $r$ is *no longer being chosen uniformly*! We must revert $r$ back to being sampled uniformly, and then we are nearly to the finish line.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow SAMP()\\
\quad z:=\text{LOOKUP}(r) \\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\underline{\text{LOOKUP}(r):}\\
\quad t\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ t\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad \mathcal{L}_{\text{samp-L}}\\\hline
\underline{\text{SAMP():}}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \text{return}\ r\\\hline
\end{array}
\quad
\begin{array}{l}
\text{As promised, $\mathcal{L}_{\text{samp-R}}$ has been}\\
\text{replaced by $\mathcal{L}_{\text{samp-L}}$. The}\\
\text{difference is indistinguishable}\\
\text{due to Lemma 4.11.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m):}\\
\quad \colorbox{yellow}{r}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \colorbox{yellow}{z}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad x:=z\oplus m\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{All of the subroutine calls have}\\
\text{been inlined; no effect on the}\\
\text{library’s output behavior.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma:\ 
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma\\\hline
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
\quad \colorbox{yellow}{x}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ (r,x)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have applied the one-time pad rule with respect to variables $z$}\\
\text{and $x$, but omitted the very familiar steps (factor out, replace library,}\\
\text{inline) that we have seen several times before. The resulting library is}\\
\text{precisely $\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$ since it samples uniformly from $\Sigma.\mathcal{C}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\times \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{text{out}}$.}
\end{array}
$$

The sequence of hybrids shows that $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma \approx \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma$, so $\Sigma$ has pseudorandom ciphertexts.

### Exercises

7.1. Let $\Sigma$ be an encryption scheme, and suppose there is a program $\mathcal{A}$ that recovers the key from a chosen plaintext attack. More precisely, $\text{Pr}[\mathcal{A}\diamond\mathcal{L}\ \text{outputs}\ k]$ is non-negligible, where $\mathcal{L}$ is defined as:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\ \ \mathcal{L}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
\underline{\text{CHALLENGE}(m\in\Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\text{Enc}(k,m)\\
\quad \text{return}\ c\\\hline
\end{array}
$$

Prove that if such an $\mathcal{A}$ exists, then $\Sigma$ does not have CPA security. Use $\mathcal{A}$ as a subroutine in a distinguisher that violates the CPA security definition.

In other words, CPA security implies that it should be hard to determine the key from seeing encryptions of chosen plaintexts.

7.2. Let $\Sigma$ be an encryption scheme with CPA$ security. Let $\Sigma'$ be the encryption scheme defined by:

$$\Sigma'.\text{Enc}(k,m)=\textcolor{brown}{00}\|\Sigma.\text{Enc}(k,m)$$

The decryption algorithm in $\Sigma'$ simply throws away the first two bits of the ciphertext and then calls $\Sigma$.Dec.

(a) Does $\Sigma'$ have CPA$\varPhi$ security? Prove or disprove (if disproving, show a distinguisher and calculate its advantage).
(b) Does $\Sigma'$ have CPA security? Prove or disprove (if disproving, show a distinguisher and
calculate its advantage).

7.3. Suppose a user is using Construction 7.4 and an adversary observes two ciphertexts that
have the same $r$ value.

(a) What exactly does the adversary learn about the plaintexts in this case?
(b) How do you reconcile this with the fact that in the proof of Claim 7.5 there is a hybrid where $r$ values are *never* repeated?

7.4. Construction 7.4 is a randomized encryption scheme, but we could also consider dening it as a **nonce-based** scheme, interpreting r as the nonce: $\text{Enc}(k,r,m)=(r,F(k,r)\oplus m)$. Formally prove that it is secure as a deterministic, nonce-based scheme. In other words, show that the following two libraries are indistinguishable, where $\Sigma$ refers to Construction 7.4.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k\leftarrow \Sigma.\text{KeyGen}\\
V:=\emptyset\\\\
\underline{\text{EAVESDROP}(v, m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \text{if}\ v\in V:\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad V:=V\cup\{v\}\\
\quad c:=\Sigma.\text{Enc}(k,v,m_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k\leftarrow \Sigma.\text{KeyGen}\\
V:=\emptyset\\\\
\underline{\text{EAVESDROP}(v, m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \text{if}\ v\in V:\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad V:=V\cup\{v\}\\
\quad c:=\Sigma.\text{Enc}(k,v,m_R)\\
\quad \text{return}\ c\\\hline
\end{array}
$$

7.5. Let $F$ be a secure PRP with blocklength $blen = \lambda$. Consider the following randomized encryption scheme:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\begin{array}{lll}
\mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  & \underline{\text { KeyGen: }} & \underline{\text { Enc }(k, m):}\\
\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} &\quad k \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}   &\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\ C=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^2&\quad \text{return}\ k &\quad x:=F(k, r) \oplus m \\
  & &\quad \text { return }(r, x) 
 \end{array}\\\hline
\end{array}
$$

(a) Give the decryption algorithm for this scheme.
(b) Prove that the scheme has CPA$\varPhi$ security.
(c ) Suppose that we interpret this scheme as a nonce-based scheme, where v is the nonce. Show that the scheme does not have nonce-based CPA security. The libraries for this definition are given in the previous problem.
Note: Even in the standard CPA libraries, $v$ is given to the adversary and it is unlikely to repeat. However, in the nonce-based libraries the adversary can choose $v$, and this is what leads to problems.

7.6. Let $F$ be a secure PRP with blocklength $blen =\lambda$. Show the the following scheme has pseudorandom ciphertexts:
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\begin{array}{ll}
& \underline{\text { Enc }(k, m):}\\
\mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  &\quad s \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\ \mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} &\quad z:=F(k, s \oplus m) \oplus m \\
 C=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^2 &\quad \text { return }(s\oplus m, z) \\\\
 \underline{\text { KeyGen: }} & \underline{\operatorname{Dec}(k,(r, z)):}\\
 \quad k \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} &\quad  \text{return}\ F(k, r) \oplus x\\
 \quad\text{return}\ k &
 \end{array}\\\hline
\end{array}
$$
> Hint: Rewrite Enc to include a new variable $r := s \oplus m$ and write the output in terms of $r$ instead of $s$. You might then recognize a familiar face

7.7. Let $F$ be a secure PRP with blocklength $blen$ $=\lambda$. Below are several encryption schemes, each with $\mathcal{K}=\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}$ and $C=\left(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\right)^{2} .$ For each one:
- Give the corresponding Dec algorithm.
- State whether the scheme has CPA security. (Assume KeyGen samples the key uniformly from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} .$ ) If so, then give a security proof. If not, then describe a successful adversary and compute its distinguishing bias.
$$
\def\arraystretch{1.5}
\text{(a)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad z:=F(k, m) \oplus r \\
\quad \text { return }(r, z) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(b)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad s:=r\oplus m\\
\quad x:=F(k, r)  \\
\quad \text { return }(s, x) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(c)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad x:=F(k, r)  \\
\quad y:=r\oplus m\\
\quad \text { return }(x, y) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(d)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad x:=F(k, r)  \\
\quad y:=F(k, r)\oplus m\\
\quad \text { return }(x, y) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(e)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad x:=F(k, r)  \\
\quad y:=r\oplus F(k, m)\\
\quad \text { return }(x, y) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(f)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad s_1 \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad s_2:=s_1\oplus m\\
\quad x:=F(k, s_1)  \\
\quad y:=F(k, s_2)  \\
\quad \text { return }(x, y) \\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\star\ \text{(g)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad x:=F(k,m\oplus r)\oplus r \\
\quad \text { return }(r, x) \\\hline
\end{array}
$$

>Hint: In all security proofs, you can use the PRP switching lemma (Lemma 6.7) to start with the assumption that $F$ is a PRF.

7.8. Suppose $F$ is a secure PRP with blocklength $n +\lambda$. Below is the encryption algorithm for a scheme that supports plaintext space $\mathcal{M} = \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$:

$$
\def\arraystretch{1.5}
\star\ \text{(g)}\quad
\begin{array}{|l|}\hline
\underline{\text { Enc }(k, m):}\\
\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text { return }\ F(k,m\|r) \\\hline
\end{array}
$$

(a) Describe the corresponding decryption algorithm.
(b) Prove that the scheme satisfies CPA$\varPhi$ security.

$\star$ 7.9. Suppose $F$ is a secure PRP with blocklength $\lambda$. Give the decryption algorithm for the following scheme and prove that it does not have CPA security:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\begin{array}{lll}
\mathcal{K}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  & \underline{\text { KeyGen: }} & \underline{\text { Enc }(k, m_1\|m_2):}\\
\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2\lambda} &\quad k \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}   &\quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\ C=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^3&\quad \text{return}\ k &\quad s:=F(k, r \oplus m_1) \\
& & \quad t:=F(k,r\oplus m_1\oplus F(k,m_1)\oplus m_2)\\
  & &\quad \text { return }(r,s,t) 
 \end{array}\\\hline
\end{array}
$$

$\star$ 7.10. Suppose $F$ is a secure PRP with blocklength $\lambda$. Give the decryption algorithm for the following scheme and prove that it satisfies CPA$\varPhi$ security:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\begin{array}{lll}
\mathcal{K}=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^2  & \underline{\text { KeyGen: }} & \underline{\text { Enc }(k, m_1\|m_2):}\\
\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} &\quad k \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}   &\quad s \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\ C=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^2 & \quad r \leftarrow\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}&\quad x:=F(k, s) \\
&\quad \text{return}\ (k,r)  & \quad y:=F(k,s\oplus m\oplus r)\\
  & &\quad \text { return }(x,y) 
 \end{array}\\\hline
\end{array}
$$

>Hint: You may find it useful to divide the Enc algorithm into two cases by introducing an “if $m = r$” statement.

Note: If $r = \textcolor{brown}{0}^\lambda$ then the scheme reduces to Exercise 7.7 (f). So it is important that $r$ is secret and random.

7.11. Let $\Sigma$ be an encryption scheme with plaintext space $\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ and ciphertext space $C=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n} .$ Prove that $\Sigma$ cannot have CPA security.

Conclude that direct application of a PRP to the plaintext is not a good choice for an encryption scheme.

$\star 7.12 .$ In all of the CPA-secure encryption schemes that we'll ever see, ciphertexts are at least $\lambda$ bits longer than plaintexts. This problem shows that such ciphertext expansion is essentially unavoidable for CPA security.

Let $\Sigma$ be an encryption scheme with plaintext space $\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ and ciphertext space $C=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n+\ell}$. Show that there exists a distinguisher that distinguishes the two CPA libraries with advantage $\Omega\left(1 / 2^{\ell}\right)$.

>Hint:  As a warmup, consider the case where each plaintext has exactly $2^\ell$ possible ciphertexts. However, this need not be true in general. For the general case, choose a random plaintextm and argue that with “good probability” (that you should precisely quantify)m has at most $2^{\ell+1}$ possible ciphertexts.

7.13. Show that an encryption scheme $\Sigma$ has CPA security if and only if the following two
libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{left}}^\Sigma\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\\\
\underline{\text{CHALLENGE}(m\in\Sigma.\mathcal(M):}\\
\quad \text{return}\ \Sigma.\text{Enc}(k,m)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{right}}^\Sigma\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\\\
\underline{\text{CHALLENGE}(m\in\Sigma.\mathcal(M):}\\
\quad m'\leftarrow \Sigma.\mathcal{M}\\
\quad \text{return}\ \Sigma.\text{Enc}(k,m')\\\hline
\end{array}
$$

In plain language: if these libraries are indistinguishable, then encryptions of chosen plaintexts are indistinguishable from encryptions of random plaintexts. You must prove both directions!


7.14. Let $\Sigma_{1}$ and $\Sigma_{2}$ be encryption schemes with $\Sigma_{1} \cdot \mathcal{M}=\Sigma_{2} \cdot \mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$.

Consider the following approach for encrypting plaintext $m \in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}:$ First, secret-share $m$ using any 2 -out-of- 2 secret-sharing scheme. Then encrypt one share under $\Sigma_{1}$ and the other share under $\Sigma_{2}$. Release both ciphertexts.

(a) Formally describe the algorithms of this encryption method.
(b) Prove that the scheme has CPA security if at least one of $\left\{\Sigma_{1}, \Sigma_{2}\right\}$ has CPA security. In other words, it is not necessary that *both* $\Sigma_{1}$ and $\Sigma_{2}$ are secure. This involves proving two cases (assuming $\Sigma_{1}$ is secure, and assuming $\Sigma_{2}$ is secure).

 # 8 Block Cipher Modes of Operation
One of the drawbacks of the previous CPA-secure encryption scheme is that its ciphertexts are $\lambda$ bits longer than its plaintexts. In the common case that we are using a block cipher with blocklength *$blen$* = $\lambda$, this means that ciphertexts are twice as long as plaintexts. Is there any way to encrypt data (especially lots of it) without requiring such a significant overhead?

A **block cipher mode** refers to a way to use a block cipher to efficiently encrypt a large amount of data (more than a single block). In this chapter, we will see the most common modes for CPA-secure encryption of long plaintexts.

## 8.1 A Tour of Common Modes

As usual, $blen$ will denote the blocklength of a block cipher $F$ . In our diagrams, we’ll write
Fk as shorthand for $F(k,\cdot)$. When $m$ is the plaintext, we will write $m=m_1\|m_2\|\cdots\|m_l,$ where each $m_i$ is a single block (so $\ell$ is the length of the plaintext measured in blocks). For now, we will assume that $m$ is an exact multiple of the block length.

### ECB: Electronic Codebook ($\textcolor{brown}{\texttt{NEVER\ NEVER\ USE\ THIS!\ NEVER!!}}$)

The most obvious way to use a block cipher to encrypt a long message is to just apply the block cipher independently to each block. The only reason to know about this mode is to know never to use it (and to publicly shame anyone who does). It can’t be said enough times: **never use ECB mode!** It does not provide security of encryption; can you see why?

**Construction 8.1 (ECB Mode)**

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
### CBC: Cipher Block Chaining

CBC (which stands for cipher block chaining) is the most common mode in practice. The CBC encryption of an $\ell-$block plaintext is $\ell+1$ blocks long. The first ciphertext block is called an **initialization vector (IV)**. Here we have described CBC mode as a randomized encryption, with the IV of each ciphertext being chosen uniformly. As you know, randomization is necessary (but not sufficient) for achieving CPA security, and indeed CBC mode provides CPA security.

**Construction 8.2 (CBC Mode)**
$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
### CTR: Counter
The next most common mode in practice is counter mode (usually abbreviated as CTR mode). Just like CBC mode, it involves an additional IV block $r$ that is chosen uniformly. The idea is to then use the sequence

$$F(k,r);\quad F(k,r+1);\quad F(k,r+2);\quad \ldots$$

as a long one-time pad to mask the plaintext. Since $r$ is a block of bits, the addition expressions
like $r + 1$ refer to addition modulo $2^{blen}$ (this is the typical behavior of unsigned addition in a processor).

### Construction 8.3 (CTR Mode)
$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
### OFB: Output Feedback
OFB (output feedback) mode is rarely used in practice. We’ll include it in our discussion because it has the easiest security proof. As with CBC and CTR modes, OFB starts with a random IV $r$ , and then uses the sequence:

$$F(k,r);\quad F(k,F(k,r));\quad F(k,F(k,F(k,r)));\quad \ldots$$

as a one-time pad to mask the plaintext.

**Construction 8.4 (OFB Mode)**
$$
\textcolor{red}{{\text{Image screenshot here}}}
$$
### Compare & Contrast
CBC and CTR modes are essentially the only two modes that are ever considered in practice for CPA security. Both provide the same security guarantees, and so any comparison between the two must be based on factors outside of the CPA security definition. Here are a few properties that are often considered when choosing between these modes:

 - Although we have not shown the decryption algorithm for CTR mode, it does not even use the block cipher’s inverse $F ^{-1}$. This is similar to our PRF-based encryption scheme from the previous chapter (in fact, CTR mode collapses to that construction when restricted to 1-block plaintexts). Strictly speaking, this means CTR mode can be instantiated from a PRF; it doesn’t need a PRP. However, in practice it is rare to encounter an ecient PRF that is not a PRP.
 
 - CTR mode encryption can be parallelized. Once the IV has been chosen, the $i^{\text{th}}$ block of ciphertext can be computed without first computing the previous $i - 1$ blocks. CBC mode does not have this property, as it is inherently sequential. Both modes have a parallelizable *decryption* algorithm, though.

 - If calls to the block cipher are expensive, it might be desirable to pre-compute and store them before the plaintext is known. CTR mode allows this, since only the IV affects the input given to the block cipher. In CBC mode, the plaintext influences the inputs to the block cipher, so these calls cannot be pre-computed before the plaintext is known.

 - It is relatively easy to modify CTR to support plaintexts that are not an exact multiple of the blocklength. (This is left as an exercise.) We will see a way to make CBC mode support such plaintexts as well, but it is far from trivial.

 - So far all of the comparisons have favored CTR mode, so here is one important property that favors CBC mode. It is common for implementers to misunderstand the security implications of the IV in these modes. Many careless implementations allow an IV to be reused. Technically speaking, reusing an IV (other than by accident, as the birthday bound allows) means that the scheme was not implemented correctly. But rather than dumping the blame on the developer, it is good design practice to anticipate likely misuses of a system and, when possible, try to make them non-catastrophic.
 The effects of IV-reuse in CTR mode are quite devastating to message privacy (see the exercises). In CBC mode, reusing an IV can actually be safe, if the two plaintexts have different first blocks!

## 8.2 CPA Security and Variable-Length Plaintexts
Here’s a big surprise: none of these block cipher modes achieve CPA security, or at least CPA security as we have been defining it.

**Example**
Consider a block cipher with *$blen$* = $\lambda$, used in CBC mode. As you will see, there is nothing particularly specific to CBC mode, and the same observations apply to the other modes.

In CBC mode, a plaintext consisting of $\ell$ blocks is encrypted into a ciphertext of $\ell+ 1$
blocks. In other words, the ciphertext **leaks the number of blocks in the plaintext**. We can leverage this observation into the following attack:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{A:}\\\hline
c:=\text{EAVESDROP}(\textcolor{brown}{0}^\lambda,\textcolor{brown}{0}^{2\lambda})\\
 \text{return}\ |c|\stackrel{?}{=}2\lambda\\\hline
\end{array}
$$

The distinguisher chooses a 1-block plaintext and a 2-block plaintext. If this distinguisher is linked to $\mathcal{L}_{\text{cpa-L}}$, the 1-block plaintext is encrypted and the resulting ciphertext is 2 blocks (2$\lambda$ bits) long. If the distinguisher is linked to $\mathcal{L}_{\text{cpa-R}}$, the 2-block plaintext is encrypted and the resulting ciphertext is 3 blocks (3$\lambda$ bits) long. By simply checking the length of the ciphertext, this distinguisher can tell the difference and achieve advantage 1.

So, technically speaking, these block cipher modes do not provide CPA security, since ciphertexts leak the length (measured in blocks) of the plaintext. But suppose we don't really care about hiding the length of plaintexts.  Is there a way to make a security definition that says: **ciphertexts hide everything about the plaintext, except their length?**

 It is clear from the previous example that a distinguisher can successfully distinguish the CPA libraries if it makes a query EAVESDROP $\left(m_{L}, m_{R}\right)$ with $\left|m_{L}\right| \neq\left|m_{R}\right| .$ A simple way to change the CPA security definition is to just disallow this kind of query. The libraries will give an error message if $\left|m_{L}\right| \neq\left|m_{R}\right| .$ This would allow the adversary to make the challenge plaintexts differ in any way of his/her choice, except in their length. It doesn't really matter whether $|m|$ refers to the length of the plaintext in bits or in blocks whichever makes the most sense for a particular scheme. 
 
From now on, when discussing encryption schemes that support variable-length plaintexts, CPA security will refer to the following updated libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{cpa-L}}^\Sigma\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\\\
\underline{\text{CTXT}(m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{if}|m_L|\neq |m_R|\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad c:=\Sigma.\text{Enc}(k,m_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{cpa-R}}^\Sigma\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\\\
\underline{\text{CTXT}(m_L,m_R\in\Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{if}|m_L|\neq |m_R|\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad c:=\Sigma.\text{Enc}(k,m_R)\\
\quad \text{return}\ c\\\hline
\end{array}
$$

In the definition of CPA$\varPhi$ security (pseudorandom ciphertexts), the $\mathcal{L}_{\text {cpa}\varPhi-\text{rand }}$ library responds to queries with uniform responses. Since these responses must look like ciphertexts, they must have the appropriate length. For example, for the modes discussed in this chapter, an $\ell$ -block plaintext is expected to be encrypted to an $(\ell+1)$ -block ciphertext. So, based on the length of the plaintext that is provided, the library must choose the appropriate ciphertext length. We are already using $\Sigma . C$ to denote the set of possible ciphertexts of an encryption scheme $\Sigma$. So let's extend the notation slightly and write $\Sigma . C(\ell)$ to denote the set of possible ciphertexts for plaintexts of length $\ell$. Then when discussing encryption schemes supporting variable-length plaintexts, CPA$\varPhi$ security will refer to the following libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\\\
\underline{\text{CHANLLENGE}(m\in\Sigma.\mathcal{M}):}\\
\quad c:=\Sigma.\text{Enc}(k,m_L)\\
\quad \text{return}\ c\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^\Sigma\\\hline
\underline{\text{CHANLLENGE}(m\in\Sigma.\mathcal{M}):}\\
\quad \leftarrow\Sigma.\mathcal{C}(|m|)\\
\quad \text{return}\ c\\\hline
\end{array}
$$
Note that the $\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}$ library does not use any information about $m$ other than its length. This again reflects the idea that ciphertexts leak nothing about plaintexts other than their length.

In the exercises, you are asked to prove that, with respect to these updated security definitions, CPA$\varPhi$ security implies CPA security as before.

### Don’t Take Length-Leaking for Granted!

We have just gone from requiring encryption to leak no partial *information* to casually allowing some specific information to leak. Let us not be too hasty about this!

 If we want to truly support plaintexts of *arbitrary* length, then leaking the length is in fact unavoidable. But “unavoidable” doesn’t mean “free of consequences.” By observing only the length of encrypted network trafic, many serious attacks are possible. Here are several examples:

 - When accessing Google maps, your browser receives many image tiles that comprise the map that you see. Each image tile has the same pixel dimensions. However, they are compressed to save resources, and not all images compress as significantly as others. Every region of the world has its own rather unique “fingerprint” of imagetile lengths. So even though trafic to and from Google maps is encrypted, the sizes of the image tiles are leaked. This can indeed be used to determine the region for which a user is requesting a map. The same idea applies to auto-complete suggestions in a search form.
 
 - Variable-bit-rate (VBR) encoding is a common technique in audio/video encoding. When the data stream is carrying less information (e.g., a scene with a fixed camera position, or a quiet section of audio), it is encoded at a lower bit rate, meaning that each unit of time is encoded in fewer bits. In an encrypted video stream, the changes in bit rate are reflected as changes in packet length. When a user is watching a movie on Netflix or a Youtube video (as opposed to a live event stream), the bit-rate changes are consistent and predictable. It is therefore rather straight-forward to determine which video is being watched, even on an encrypted connection, just by observing the packet lengths.
 
 - VBR is also used in many encrypted voice chat programs. Attacks on these tools have been increasing in sophistication. The first attacks on encrypted voice programs showed how to identify who was speaking (from a set of candidates), just by observing the stream of ciphertext sizes. Later attacks could determine the language being spoken. Eventually, when combined with sophisticated linguistic models, it was shown possible to even identify individual words to some extent!

It’s worth emphasizing again that none of these attacks involve any attempt to break the encryption. The attacks rely solely on the fact that encryption leaks the length of the plaintexts.

## 8.3 Security of OFB Mode

In this section we will prove that OFB mode has pseudorandom ciphertexts (when the blocklength is *$blen$* = $\lambda$ bits). OFB encryption and decryption both use the forward direction of $F$ , so OFB provides security even when $F$ is not invertible. Therefore we will prove security assuming $F$ is simply a PRF.

**Claim 8.5**
OFB mode (Construction 8.4) has CPA$\varPhi$ security, if its underlying block cipher $F$ is a secure PRF with parameters *in = out* = $\lambda$.

**Proof**
The general structure of the proof is very similar to the proof used for the PRF-based encryption scheme in the previous chapter (Construction 7.4). This is no coincidence: if OFB mode is restricted to plaintexts of a single block, we obtain exactly Construction 7.4 !

The idea is that each ciphertext block (apart from the IV) is computed as $c_{i}:=r \oplus m_{i}$. By the one-time pad rule, it suffices to show that the $r$ values are independently pseudorandom. Each $r$ value is the result of a call to the PRF. These PRF outputs will be independently pseudorandom only if all of the inputs to the PRF are *distinct*. In OFB mode, we use the output $r$ of a previous PRF call as input to the next, so it is highly unlikely that this PRF *output* $r$ matches a past PRF-input value. To argue this more precisely, the proof includes hybrids in which $r$ is chosen without replacement (before changing $r$ back to uniform sampling). 

The formal sequence of hybrid libraries is given below:

$$
\def\arraystretch{1.5}
\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma:
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\\\
\underline{\text{CTXT}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=F(k,r)\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\quad
\begin{array}{l}
\text{ The starting point is $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^\Sigma$,  shown}\\
\text{here with the details of OFB filled in.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=\colorbox{yellow}{LOOPUP(r)}\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{prf-real}}^F\\\hline
k\leftarrow\{\textcolor{brown}{0},\text{1}\}^\lambda\\\\
\underline{\text{LOOKUP}(r):}\\
\quad \text{return}\ F(k,r)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{ The statements pertaining to the PRF}\\
\text{$F$ have been factored out in terms of}\\
\mathcal{L}_{\text{prf-real}}^F
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CTXT}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=\colorbox{yellow}{LOOPUP(r)}\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{prf-rand}}^F\\\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
 \quad \text{return}\ T[x]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{$\mathcal{L}_{\text{prf-real}}^F$ has been replaced by}\\
\text{$\mathcal{L}_{\text{prf-rand}}^F$. By the PRF security of $F$ ,}\\
\text{the change is indistinguishable.}
\end{array}
$$

Next, all of the statements that involve sampling values for the variable $r$ are factored out
in terms of the $\mathcal{L}_{\text{samp-L}}$ library from Lemma 4.11:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CHALLENGE}(m_1\|\cdots \|m_{\ell)}:}\\
\quad \colorbox{yellow}{r:=\text{SAMP}()}\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=LOOPUP(r)\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad \colorbox{yellow}{T[x]:=\text{SAMP()}}\\
 \quad \text{return}\ T[x]\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad\mathcal{L}_{\text{samp-L}}\\\hline
\underline{\text{SAMP()}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ r\\\hline
\end{array}
$$

$\mathcal{L}_{\text{samp-L}}$ is then replaced by $\mathcal{L}_{\text{samp-R}}$. By Lemma 4.11, this change is indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CHALLENGE}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r:=\text{SAMP}()\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=LOOPUP(r)\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
T:=\text{empty}\\\\
\underline{\text{LOOKUP}(x):}\\
\quad \text{if}\ T[x]\ \text{undefined:}\\
\qquad T[x]:=\text{SAMP()}\\
 \quad \text{return}\ T[x]\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{samp-R}}\\\hline
R:=\emptyset\\\\
\underline{\text{SAMP()}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash R\\
\quad R:=R\cup\{r\}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Arguments to lookup are never repeated in this hybrid, so the middle library can be significantly simplified:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CHALLENGE}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r:=\text{SAMP}()\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=LOOPUP(r)\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\underline{\text{LOOKUP}(x):}\\
\quad t:=\text{SAMP()}\\
 \quad \text{return}\ t\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\qquad\mathcal{L}_{\text{samp-R}}\\\hline
R:=\emptyset\\\\
\underline{\text{SAMP()}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash R\\
\quad R:=R\cup\{r\}\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Next, $\mathcal{L}_{\text{samp-R}}$ is replaced by $\mathcal{L}_{\text{samp-L}}$. By Lemma 4.11, this change is indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CHALLENGE}(m_1\|\cdots \|m_{\ell)}:}\\
\quad r:=\text{SAMP}()\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r:=LOOPUP(r)\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\underline{\text{LOOKUP}(x):}\\
\quad t:=\text{SAMP()}\\
 \quad \text{return}\ t\\\hline
\end{array}
\diamond
\begin{array}{|l|}\hline
\quad\mathcal{L}_{\text{samp-L}}\\\hline
\underline{\text{SAMP()}:}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ r\\\hline
\end{array}
$$

Subroutine calls to lookup and samp are inlined:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CHALLENGE}(m_1\|\cdots \|m_{\ell)}:}\\
\quad \colorbox{yellow}{r}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c_0 :=r\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad \colorbox{yellow}{r}\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\qquad c_i:=r\oplus m_i\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

Finally, the one-time pad rule is applied within the for-loop (omitting some common steps). Note that in the previous hybrid, each value of $r$ is used only once as a one-time pad. The $i=0$ case has also been absorbed into the for-loop. The result is $\mathcal{L}_{\text {cpas-rand }}^{\text {OFB }},$ since OFB encrypts plaintexts of $\ell$ blocks into $\ell+1$ blocks.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad\ \mathcal{L}_{\text{cpa}\varPhi-\text{rand}}\\\hline
\underline{\text{CTXT}(m_1\|\cdots \|m_{\ell)}:}\\
\quad \colorbox{yellow}{\text{for}\ i=1\ \text{to}}\ \ell:\\
\qquad \colorbox{yellow}{c}_i\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad\text{return}\ c_0 \| c_1 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

The sequence of hybrids shows that $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^{\text{OFB}}\approx\mathcal{L}_{\text{cpa}\varPhi-\text{rand}}^{\text{OFB}}$, so OFB mode has pseudorandom ciphertexts.

We proved the claim assuming $F$ is a PRF only, since OFB mode does not require $F$ to be invertible. Since we assume a PRF with parameters *in* $=$ *out* $=\lambda$, the PRP switching lemma (Lemma 6.7) shows that OFB is secure also when $F$ is a PRP with blocklength $n=\lambda$.

## 8.4 Padding \& Ciphertext Stealing
So far we have assumed that all plaintexts are exact multiples of the blocklength. But data in the real world is not always so accommodating. How are block ciphers used in practice with data that has arbitrary length?

### Padding
**Padding** just refers to any approach to encode arbitrary-length data into data that is a multiple of the blocklength. The only requirement is that this encoding is reversible. More formally, a **padding scheme** should consist of two algorithms:

- pad: takes as input a string of any length, and outputs a string whose length is a multiple of the blocklength

- unpad: the inverse of pad. We require that unpad $(\operatorname{pad}(x))=x$ for all strings $x$.

The idea is that the sender can encrypt pad $(x)$, which is guaranteed to be a multiple of the blocklength; the receiver can decrypt and run unpad on the result to obtain $x$.

In the real world, data almost always comes in **bytes** and not bits, so that will be our assumption here. In this section we will write bytes in hex, for example $\colorbox{silver}{8f}$. Typical blocklengths are 128 bits (16 bytes) or 256 bits ( 32 bytes).

 Here are a few common approaches for padding:
 
**Null padding:** The simplest padding approach is to just fill the final block with null bytes $(\colorbox{silver}{00})$. The problem with this approach is that it is not always reversible. For example, $\operatorname{pad}(\colorbox{silver}{31|41|59})$ and pad$(\colorbox{silver}{31|41|59|00}$ ) will give the same result. It is not possible to distinguish between a null byte that was added for padding and one that was intentionally the last byte of the data.

**ANSIX.923 standard:** Data is padded with null bytes, except for the last byte of padding which indicates how many padding bytes there are. In essence, the last byte of the padded message tells the receiver how many bytes to remove to recover the original message.

 Note that in this padding scheme (and indeed in all of them), if the original unpadded data is *already* a multiple of the block length, then **an entire extra block of padding** must be added. This is necessary because it is possible for the original data to end with some bytes that look like valid padding (e.g., $\colorbox{silver}{00|00|03}$, and we do not want these bytes to be removed erroneously.

**Example**
Below are some examples of valid and invalid X.923 padding (using 16-byte blocks):
$$\begin{array}{l
ll}
\colorbox{silver}{| 01 |34 |11 | d9 | 81 | 88 | 05 | 57 | 1d | 73 | c3 | \textcolor{green}{00} | \textcolor{green}{00} | \textcolor{green}{00} | \textcolor{green}{00} | \textcolor{green}{05} |} & \Rightarrow & valid\\
\colorbox{silver}{| 95 | 51 | 05 | 4a | d6 | 5a | a3 | 44 | af | b3 | 85 | 00 | 00 | \textcolor{green}{00} | \textcolor{green}{00} | \textcolor{green}{03} |} & \Rightarrow & valid\\
\colorbox{silver}{| 71 | da | 77 | 5a | 5e | 77 | eb | a8 | 73 | c5 | 50 | b5 | 81 | d5 | 96 | \textcolor{green}{01} |} & \Rightarrow & valid\\
\colorbox{silver}{| 5b | 1c | 01 | 41 | 5d | 53 | 86 | 4e | e4 | 94 | 13 | e8 | 7a | 89 | c4 | \textcolor{brown}{71} |} & \Rightarrow & invalid\\
\colorbox{silver}{| d4 | 0d | d8 | 7b | 53 | 24 | c6 | d1 | af | 5f | d6 | f6 | \textcolor{brown}{00} | \textcolor{brown}{c0} | \textcolor{brown}{00} | \textcolor{brown}{04} |} & \Rightarrow & invalid
\end{array}
$$

**PKCS#7 standard:** If b bytes of padding are needed, then the data is padded not with null bytes but with $\colorbox{silver}{b}$ bytes. Again, the last byte of the padded message tells the receiver how many bytes to remove.

$$\begin{array}{l
ll}
\colorbox{silver}{| 01 | 34 | 11 | d9 | 81 | 88 | 05 | 57 | 1d | 73 | c3 | 05 | \textcolor{green}{05} | \textcolor{green}{05} | \textcolor{green}{05} | \textcolor{green}{05} |} & \Rightarrow & valid\\
\colorbox{silver}{| 95 | 51 | 05 | 4a | d6 | 5a | a3 | 44 | af | b3 | 85 | 03 | 03 | \textcolor{green}{03} | \textcolor{green}{03} | \textcolor{green}{03} |} & \Rightarrow & valid\\
\colorbox{silver}{| 71 | da | 77 | 5a | 5e | 77 | eb | a8 | 73 | c5 | 50 | b5 | 81 | d5 | 96 | \textcolor{green}{01} |} & \Rightarrow & valid\\
\colorbox{silver}{| 5b | 1c | 01 | 41 | 5d | 53 | 86 | 4e | e4 | 94 | 13 | e8 | 7a | 89 | c4 | \textcolor{brown}{71} |} & \Rightarrow & invalid\\
\colorbox{silver}{| d4 | 0d | d8 | 7b | 53 | 24 | c6 | d1 | af | 5f | d6 | f6 | \textcolor{brown}{04} | \textcolor{brown}{c0} | \textcolor{brown}{04} | \textcolor{brown}{04} |} & \Rightarrow & invalid
\end{array}
$$

**ISO/IEC $7816-4$ standard:** $\quad$ The data is padded with a $\colorbox{silver}{80}$ byte followed by null bytes. To remove the padding, remove all trailing null bytes and ensure that the last byte is $\colorbox{silver}{80}$ (and then remove it too).

The significance of $\colorbox{silver}{80}$ is clearer when you write it in binary as $\textcolor{brown}{10000000} .$ So another way to describe this padding scheme is: append a $\textcolor{brown}{1}$ bit, and then pad with $\textcolor{brown}{0}$ bits until reaching the block length. To remove the padding, remove all trailing $\textcolor{brown}{0}$ bits as well as the rightmost $\textcolor{brown}{1}$ bit. Hence, this approach generalizes easily to padding data that is not a multiple of a byte.

**Example**
Below are some examples of valid and invalid ISO/IEC $7816-4$ padding (using 16 -byte blocks):

$$\begin{array}{l
ll}
\colorbox{silver}{| 01 | 34 | 11 | d9 | 81 | 88 | 05 | 57 | 1d | 73 | c3 | \textcolor{green}{80} | \textcolor{green}{05} | \textcolor{green}{05} | \textcolor{green}{05} | \textcolor{green}{05} |} & \Rightarrow & valid\\
\colorbox{silver}{| 95 | 51 | 05 | 4a | d6 | 5a | a3 | 44 | af | b3 | 85 | 03 | 03 | \textcolor{green}{80} | \textcolor{green}{00} | \textcolor{green}{00} |} & \Rightarrow & valid\\
\colorbox{silver}{| 71 | da | 77 | 5a | 5e | 77 | eb | a8 | 73 | c5 | 50 | b5 | 81 | d5 | 96 | \textcolor{green}{80} |} & \Rightarrow & valid\\
\colorbox{silver}{| 5b | 1c | 01 | 41 | 5d | 53 | 86 | 4e | e4 | 94 | 13 | e8 | 7a | 89 | c4 | \textcolor{brown}{71} |} & \Rightarrow & invalid\\
\colorbox{silver}{| d4 | 0d | d8 | 7b | 53 | 24 | c6 | d1 | af | 5f | d6 | f6 | \textcolor{brown}{c4} | \textcolor{brown}{00} | \textcolor{brown}{00} | \textcolor{brown}{00} |} & \Rightarrow & invalid
\end{array}
$$

The choice of padding scheme is not terribly important, and any of these is generally fine. Just remember that **padding schemes are not a security feature!** Padding is a public method for encoding data, and it does not involve any secret keys. The only purpose of padding is to enable functionality — using block cipher modes like CBC with data that is not a multiple of the block length.

Furthermore, as we will see in the next chapter, padding is associated with certain attacks against improper use of encryption. Even though this is not really the fault of the padding (rather, it is the fault of using the wrong flavor of encryption), it is such a common pitfall that it is always worth considering in a discussion about padding.

### Ciphertext Stealing

Another approach with a provocative name is **ciphertext stealing** (CTS, if you are not yet tired of three-leter acronyms), which results in ciphertexts that are not a multiple of the blocklength. The main idea behind ciphertext stealing is to use a standard block-cipher mode that only supports full blocks (e.g., CBC mode), and then **simply throwaway some bits of the ciphertext**, in such a way that decryption is still possible. If the last plaintext blocks is $j$ bits short of being a full block, it is generally possible to throw away $j$ bits of the ciphertext. In this way, a plaintext of $n$ bits will be encrypted to a ciphertext of $blen+n$ bits, where $blen$ is the length of the extra IV block.

As an example, let's see ciphertext stealing as applied to $\mathrm{CBC}$ mode. Suppose the blocklength is $blen$ and the last plaintext block $m_{\ell}$ is $j$ bits short of being a full block. We start by extending $m_{\ell}$ with $j$ zeroes (i.e., null-padding the plaintext) and performing $\mathrm{CBC}$ encryption as usual.

Now our goal is to identify $j$ bits of the CBC ciphertext that can be thrown away while still making decryption possible. In this case, the appropriate bits to throw away are **the last** $j$ **bits** of $c_{\ell-1}$ (the next-to-last block of the CBC ciphertext). The reason is illustrated in the figure below:

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

Suppose the receiver obtains this CBC ciphertext but the last $j$ bits of $c_{\ell-1}$ have been deleted. How can he/she decrypt? The important idea is that those missing $j$ bits were redundant, because there is another way to compute them. 

In CBC encryption, the last value given as input into the block cipher is $c_{\ell-1} \oplus m_{\ell}$. Let us give thils value a name $x^{*}:=c_{\ell-1} \oplus m_{\ell} .$ Since the last $j$ bits of $m_{\ell}$ are  $\textcolor{brown}{0}$  's,  the last $j$ bits of $x^{*}$ are the last $j$ bits of $c_{\ell-1}-$ the missing bits. Even though these bits are missing from $c_{\ell-1},$ the receiver has a different way of computing them as $x^{*}:=F^{-1}\left(k, c_{\ell}\right)$

Putting it all together, the receiver does the following: First, it observes that the ciphertext is $j$ bits short of a full block. It computes $F^{-1}\left(k, c_{\ell}\right)$ and takes the last $j$ bits of this value to be the missing bits from $c_{\ell-1}$. With the missing bits recovered, the receiver does CBC decryption as usual. The result is a plaintext consisting of $\ell$ full blocks, but we know that the last $j$ bits of that plaintext are  $\textcolor{brown}{0}$  padding that the receiver can remove.

It is convenient in an implementation for the boundaries between blocks to be in predictable places. For that reason, it is slightly awkward to remove $j$ bits from the middle of the ciphertext during encryption (or add them during decryption), as we have done here. So in practice, the last two blocks of the ciphertext are often interchanged. In the example above, the resulting ciphertext (after ciphertext stealing) would be:
$c_{0}\left\|c_{1}\right\| c_{2} \cdots c_{\ell-3}\left\|c_{\ell-2}\right\| c_{\ell} \| c_{\ell-1}^{\prime},$ where $c_{\ell-1}^{\prime}$ is the first $blen$ $-j$ bits of $c_{\ell-1}$

That way, all ciphertext blocks except the last one are the full blen bits long, and the boundaries between blocks appear consistently every $blen$ bits. This “optimization” does add some significant edge cases to any implementation. One must also decide what to do when the plaintext is already an exact multiple of the blocklength — should the final two ciphertext blocks be swapped even in this case? Below we present an implementation of ciphertext stealing (CTS) that does *not* swap the final two blocks in this case. This means that it collapses to plain CBC mode when the plaintext is an exact multiple of the block length.

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\begin{array}{l}
\underline{\operatorname{Enc}\left(k, m_{1}\|\cdots\| m_{\ell}\right)}\\
// \text{each $m_{i}$ is blen bits,}\\
 // \text{except possibly $m_{\ell}$}\\\\
 \text{$j:=blen$ $-\left|m_{\ell}\right|$}\\
 \text{$m_{\ell}:=m_{\ell} \| \textcolor{brown}{0}^{j}$}\\
 \text{$c_{0} \leftarrow\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\text {$blen$ }}:$}\\
 \text{for $i=1$ to $\ell$}\\
 \quad c_i:=F(k,m_i \oplus c_{i-1}\\
 \text{if}\ j\neq0\\
 \quad\text{remove final $j$ bits of $c_{\ell-1}$}\\
 \quad\text{ $\operatorname{swap} c_{\ell-1}$ and $c_{\ell}$}\\
 \text{return $c_{0}\left\|c_{1}\right\| \cdots \| c_{\ell}$}
\end{array}
&
\begin{array}{l}
\underline{\text{$\operatorname{Dec}\left(k, c_{0}\|\cdots\| c_{\ell}\right)$}}\\
\text{$/ /$ each $c_{i}$ is blen bits,}\\
\text{ // except possibly $c_\ell$}\\\\
\text{$j:=$ blen $-\mid c_{\ell}$}\\
\text{if $j \neq 0$}\\
\quad\text{swap $c_{\ell-1}$ and $c_{\ell}$}\\
\quad x:=\text { last } j \text { bits of } F^{-1}\left(k, c_{\ell}\right) \\
\quad c_{\ell-1}:=c_{\ell-1} \| x\\
\text{for}\ i=1\ \text{to}\ \ell:\\
\quad m_{i}:=F^{-1}\left(k, c_{i}\right) \oplus c_{i-1}\\
\text{remove final $j$ bits of $m_{\ell}$}\\
\text{ return $m_{1}\|\cdots\| m_{\ell}$}
\end{array}\\\hline
\end{array}
$$
The marked lines correspond to plain CBC mode.

### Exercises
8.1. Prove that a block cipher in ECB mode does not provide CPA security. Describe a distinguisher and compute its advantage.

8.2. Describe OFB decryption mode.

8.3. Describe CTR decryption mode.

8.4. CBC mode:
(a) In CBC-mode encryption, if a single bit of the plaintext is changed, which ciphertext blocks are affected (assume the same IV is used)?
(b) In CBC-mode decryption, if a single bit of the ciphertext is changed, which plaintext blocks are affected?

8.5. Prove that CPA\$ security for variable-length plaintexts implies CPA security for variablelength plaintexts. Where in the proof do you use the fact that $\left|m_{L}\right|=\left|m_{R}\right| ?$

8.6. Suppose that instead of applying CBC mode to a block cipher, we apply it to one-time pad. In other words, we replace every occurrence of $F(k, \star)$ with $k \oplus \star$ in the code for $\mathrm{CBC}$ encryption. Show that the result does not have CPA security. Describe a distinguisher and compute its advantage.

8.7. Prove that there is an attacker that runs in time $O\left(2^{\lambda / 2}\right)$ and that can break CPA security of CBC mode encryption with constant probability.

8.8. Below are several block cipher modes for encryption, applied to a PRP $F$ with blocklength $blen$ $=\lambda$. For each of the modes:
- Describe the corresponding decryption procedure.
- Show that the mode does not have CPA-security. That means describe a distinguisher and compute its advantage.

$$
\def\arraystretch{1.5}
\text{(a):\quad}
\begin{array}{|l|}\hline
\underline{\text{Enc}(k,m_1\|\cdots \|m_{\ell)}:}\\
\quad r_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c_0:=r_0\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r_i:=F(k,m_i)\\
\qquad c_i :=r_i\oplus r_{i-1}\\
\quad\text{return}\ c_0 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(b):\quad}
\begin{array}{|l|}\hline
\underline{\text{Enc}(k,m_1\|\cdots \|m_{\ell)}:}\\
\quad c_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad c_i :=F(k,m_i)\oplus c_{i-1}\\
\quad\text{return}\ c_0 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(c):\quad}
\begin{array}{|l|}\hline
\underline{\text{Enc}(k,m_1\|\cdots \|m_{\ell)}:}\\
\quad c_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad m_0:=c_0\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad c_i :=F(k,m_i)\oplus m_{i-1}\\
\quad\text{return}\ c_0 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\text{(d):\quad}
\begin{array}{|l|}\hline
\underline{\text{Enc}(k,m_1\|\cdots \|m_{\ell)}:}\\
\quad c_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad r_0:=c_0\\
\quad \text{for}\ i=1\ \text{to}\ \ell:\\
\qquad r_i:=r_{i-1}\oplus m_i\\
\qquad c_i :=F(k,r_i)\\
\quad\text{return}\ c_0 \| \cdots \| c_{\ell}\\\hline
\end{array}
$$

Mode (a) is similar to $\mathrm{CBC}$, except the xor happens after, rather than before, the block cipher application. Mode (c) is essentially the same as CBC decryption.

8.9. Suppose you observe a CBC ciphertext and two of its blocks happen to be identical. What can you deduce about the plaintext? State some non-trivial property of the plaintext that *doesn't depend on the encryption key*.

8.10. The CPA$\varPhi$-security proof for CBC encryption has a slight complication compared to the proof of OFB encryption. Recall that an important part of the proof is arguing that all inputs to the PRF are distinct.

In OFB, outputs of the PRF were fed directly into the PRF as inputs. The adversary had no influence over this process, so it wasn't so bad to argue that all PRF inputs were distinct (with probability negligibly close to 1 ).

By contrast, CBC mode takes an output block from the PRF, xoR's it with a plaintext block (which is after all *chosen by the adversary*), and uses the result as input to the next PRF call. This means we have to be a little more careful when arguing that $\mathrm{CBC}$ mode gives distinct inputs to all PRF calls (with probability negligibly close to 1).

(a) Prove that the following two libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{left}}\\\hline
\underline{\text{SAMP}(m\in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad\text{return}\ r\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \qquad\mathcal{L}_{\text{right}}\\\hline
R;=\emptyset\\\\
\underline{\text{SAMP}(m\in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda):}\\
\quad r\leftarrow \{r'\in\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\mid r'\oplus m\notin\ R\}\\
\quad R:=R\cup\{r\oplus m\}\\
\quad\text{return}\ r\\\hline
\end{array}
$$
>Hint: Use Lemma 4.12.

(b) Using part (a), and the security of the underlying PRF, prove the CPA$-security of CBC
mode.
> Hint:  In $\mathcal{L}_{\text{right}}$, let $R$ correspond to the set of all inputs sent to the PRF. Letm correspond to the next plaintext block. Instead of sampling r (the output of the PRF) uniformly as in $\mathcal{L}_{\text{left}}$, we sample $r$ so that $r \oplus m$ has never been used as a PRF-input before. This guarantees that the next PRF call will be on a “fresh” input.

Note: Appreciate how important it is that the adversary chooses plaintext block $m$ before “seeing” the output $r$ from the PRF (which is included in the ciphertext).

$\star 8.11$. Prove that CTR mode achieves CPA\$ security.
>Hint: Use Lemma 4.12 to show that there is only negligible probability of chosing the IV so that the block cipher gets called on the same value twice.

8.12. Let $F$ be a secure PRF with out $=i n=\lambda$ and let $F^{(2)}$ denote the function $F^{(2)}(k, r)=$ $F(k, F(k, r))$
(a) Prove that $F^{(2)}$ is also a secure PRF.
(b) What if $F$ is a secure PRP with blocklength blen? Is $F^{(2)}$ also a secure PRP?

8.13. This question refers to the nonce-based notion of CPA security.
(a) Show a definition for CPA\$ security that incorporates both the nonce-based syntax of Section 7.1 and the variable-length plaintexts of Section 8.2 .
(b) Show that $\mathrm{CBC}$ mode not secure as a nonce-based scheme (where the IV is used as a nonce).
(c ) Show that CTR mode is not secure as a nonce-based scheme (where the IV is used as a nonce). Note that if we restrict (randomized) CTR mode to a single plaintext block, we get the CPA-secure scheme of Construction $7.4,$ which is is secure as a nonce-based scheme. The attack must therefore use the fact that plaintexts can be longer than one block. (Does the attack in part (b) work with single-block plaintexts?)

8.14. One way to convert a randomized-IV-based construction into a nonce-based construction is called the synthetic IV approach.
(a) The synthetic-IV (SIV) approach applied to CBC mode is shown below. Prove that it is CPA/CPA$ secure as a nonce-based scheme (refer to the security denitions from the previous problem):
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{SIV-CBC.Enc}\Big((k_1,k_2),v,m_1\|\cdots\|m_\ell\Big):}\\
c_0:=\colorbox{yellow}{F(k,v)}\\
\text{for}\ i=1\ \text{to}\ \ell:\\
\quad c_i:=F(\colorbox{yellow}{k}_2,m_i\oplus c_{i-1})\\
\text{return}\ c_0\|c_1\|\cdots\|c_\ell\\\hline
\end{array}
$$
Instead of chosing a random IV $c_0$, it is generated deterministically from the nonce $v$ using the block cipher $F$ . In your proof, you can use the fact that randomized CBC mode has CPA$\varPhi$ security, and that $F$ is also a secure PRF.

(b) It is important that the SIV construction uses two keys for different purposes. Suppose that we instead used the same key throughout:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{BadSIV-CBC.Enc}\Big((k_1,k_2),v,m_1\|\cdots\|m_\ell\Big):}\\
c_0:=F(\colorbox{yellow}{k},v)\\
\text{for}\ i=1\ \text{to}\ \ell:\\
\quad c_i:=F(\colorbox{yellow}{k},m_i\oplus c_{i-1})\\
\text{return}\ c_0\|c_1\|\cdots\|c_\ell\\\hline
\end{array}
$$
Show that the resulting scheme does not have CPA$\varPhi$ security (in the nonce-based sense). Ignore the complication of padding, and only consider plaintexts that are a multiple of the block length. Describe a successful distinguisher and compute its advantage.

(c ) For randomized encryption, it is necessary to include the IV in the ciphertext; otherwise the receiver cannot decrypt. In the nonce-based setting we assume that the receiver knows the correct nonce (e.g., from some out-of-band communication). With that in mind, we could modify the scheme from part (b) to remove $c_{0}$, since the receiver could reconstruct it anyway from $v$. Show that even with this modification, the scheme still fails to be CPA-secure under the nonce-based definition.

8.15. Implementers are sometimes cautious about IVs in block cipher modes and may attempt to "protect" them. One idea for protecting an IV is to prevent it from directly appearing in the ciphertext. The modified CBC encryption below sends the IV through the block cipher before including it in the ciphertext:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{Enc}(k,m_1\|\cdots\|m_\ell):}\\
c_0\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\colorbox{yellow}{c}_0':=F(k,c_0)\\
\text{for}\ i=1\ \text{to}\ \ell:\\
\quad c_i:=F(k,m_i\oplus c_{i-1})\\
\text{return}\ \colorbox{yellow}{c}'_0\|c_1\|\cdots\|c_\ell\\\hline
\end{array}
$$

This ciphertext can be decrypted by first computing $c_{0}:=F^{-1}\left(k, c_{0}^{\prime}\right)$ and then doing usual CBC decryption on $c_{0}\|\cdots\| c_{\ell}$.

Show that this new scheme is **not** CPA-secure (under the traditional definitions for randomized encryption).

8.16. Suppose a bad implementation leads to two ciphertexts being encrypted with the same IV, rather than a random IV each time.
(a) Characterize as thoroughly as you can what information is leaked about the plaintexts when CBC mode was used and an IV is repeated.
(b) Characterize as thoroughly as you can what information is leaked about the plaintexts when CTR mode was used and an IV is repeated.

8.17. Describe how to extend CTR and OFB modes to deal with plaintexts of arbitrary length (without using padding). Why is it so much simpler than CBC ciphertext stealing?

8.18. The following technique for ciphertext stealing in CBC was proposed in the 1980 s and was even adopted into commercial products. Unfortunately, it's insecure. Suppose the final plaintext block $m_{\ell}$ is $blen$ $-j$ bits long. Rather than padding the final block with zeroes, it is padded with the last $j$ bits of ciphertext block $c_{\ell-1}$. Then the padded block $m_{\ell}$ is sent through the PRP to produce the final ciphertext block $c_{\ell}$. Since the final $j$ bits of $c_{\ell-1}$ are recoverable from $c_{\ell}$, they can be discarded.

If the final block of plaintext is already $blen$ bits long, then standard CBC mode is used.

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

Show that the scheme does not satisfy CPA$\varPhi$ security. Describe a distinguisher and compute its advantage.
>Hint: Ask for several encryptions of plaintexts whose last block is $blen - 1$ bits long.
>
8.19. Prove that any CPA-secure encryption remains CPA-secure when augmented by padding
the input.

8.20. Prove that CBC with ciphertext stealing has CPA$\varPhi$ security. You may use the fact that CBC mode has CPA$\varPhi$ security when restricted to plaintexts whose length is an exact multiple of the blocklength (i.e., CBC mode without padding or ciphertext stealing).
>Hint: Let CBC denote standard CBC mode restricted to plaintext space $\mathcal{M}=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen})^*$ and let CBC-CTS denote CBC mode with ciphertext stealing (so $\mathcal{M}=(\{\textcolor{brown}{0},\textcolor{brown}{1}\})^*$). Observe that it is easy to implement a call to $\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^{\text{CBC-CTS}}$ by a related call to$\mathcal{L}_{\text{cpa}\varPhi-\text{real}}^{\text{CBC}}$ plus a small amount of additional processing.

8.21. Propagating CBC (PCBC) mode refers to the following variant of CBC mode:

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

(a) Describe PCBC decryption.
(b) Assuming that standard CBC mode has CPA$\varPhi$-security (for plaintexts that are exact
multiple of the block length), prove that PCBC mode also has CPA$\varPhi$-security (for the
same plaintext space).
>Hint: Write PCBC encryption using plain CBC encryption as a subroutine.

(c ) Consider the problem of adapting CBC ciphertext stealing to PCBC mode. Suppose
the nal plaintext block $m_\ell$ has $blen- j$ bits, and we pad it with the final $j$ bits of the
previous plaintext block $m_{\ell-1}$. Show that discarding the last j bits of $c_{\ell-1}$ still allows
for correct decryption and results in CPA$\varPhi$ security.

>Hint: See Exercise 8.20.

(d) Suppose the final plaintext block is padded using the final $j$ bits of the previous ciphertext block $c_{\ell-1}$. Although correct decryption is still possible, the construction is no longer secure. Show an attack violating the CPA$\varphi$-security of this construction. Why doesn’t the proof approach from part (c) work?



