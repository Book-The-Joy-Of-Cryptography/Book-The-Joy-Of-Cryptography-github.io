


# 9 Chosen Ciphertext Attacks

In this chapter we discuss the limitations of the CPA security definition. In short, the CPA security definition considers only the information leaked to the adversary by *honestly generated* ciphertexts. It does not, however, consider what happens when an adversary is allowed to inject its own *maliciously* *crafted* ciphertexts into an honest system. If that happens, then even a CPA-secure encryption scheme can fail in spectacular ways. We begin by seeing such an example of spectacular and surprising failure, called a padding oracle attack:

## 9.1 Padding Oracle Attacks
Imagine a webserver that receives CBC-encrypted ciphertexts for processing. When receiving a ciphertext, the webserver decrypts it under the appropriate key and then checks whether the plaintext has valid X.923 padding (Section 8.4).

Importantly, suppose that the *observable behavior of the webserver changes depending on whether the padding* is valid. You can imagine that the webserver gives a special error message in the case of invalid padding. Or, even more cleverly (but still realistic), the *difference in response time* when processing a ciphertext with invalid padding is enough to allow the attack to work. The *mechanism* for learning padding validity is not important — what is important is simply the fact that an attacker has some way to determine whether a ciphertext encodes a plaintext with valid padding. No matter how the attacker comes by this information, we say that the attacker has access to a **padding oracle**, which gives the same information as the following subroutine:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\text{PADDINGORACLE}(c):\\
\quad m:=\text{Deck}(k,c)\\
\quad \text{return VALIDPAD}(m)\\\hline
\end{array}
$$

We call this a padding *oracle* because it answers only one specific kind of question about the input. In this case, the answer that it gives is always a single boolean value. It does not seem like a padding oracle is leaking useful information, and that there is no cause for concern. Surprisingly, we can show that an attacker who doesn’t know the encryption key $k$ can use a padding oracle alone to *decrypt **any** ciphertext of its choice*! This is true no matter what else the webserver does. As long as it leaks this one bit of information on ciphertexts that the attacker can choose, it might as well be leaking everything.

### Malleability of CBC Encryption

Recall the definition of CBC decryption. If the ciphertext is $c=c_{0} \cdots c_{\ell}$ then the $i$th plaintext block is computed as:
$$
m_{i}:=F^{-1}\left(k, c_{i}\right) \oplus c_{i-1}
$$
From this we can deduce two important facts:
- Two consecutive blocks $\left(c_{i-1}, c_{i}\right)$ taken in isolation are a valid encryption of $m_{i}$. Looking ahead, this fact allows the attacker to focus on decrypting a single block at a time.
- XORing a ciphertext block with a known value (say, $x$ ) has the effect of xoring the corresponding plaintext block by the same value. In other words, for all $x,$ the ciphertext $\left(c_{i-1} \oplus x, c_{i}\right)$ decrypts to $m_{i} \oplus x:$
$$
\operatorname{Dec}\left(k,\left(c_{i-1} \oplus x, c_{i}\right)\right)=F^{-1}\left(k, c_{i}\right) \oplus\left(c_{i-1} \oplus x\right)=\left(F^{-1}\left(k, c_{i}\right) \oplus c_{i-1}\right) \oplus x=m_{i} \oplus x
$$
If we send such a ciphertext $\left(c_{i-1} \oplus x, c_{i}\right)$ to the padding oracle, we would therefore learn whether $m_{i} \oplus x$ is a (single block) with valid padding. Instead of thinking in terms of padding, it might be best to think of the oracle as telling you whether $m_{i} \oplus x$ ends in one of the suffixes $\colorbox{silver}{|01|},\colorbox{silver}{|00|02|},\colorbox{silver}{|00|00|03|},$ etc.

By carefully choosing different values $x$ and asking questions of this form to the padding oracle, we will show how it is possible to learn all of $m_{i}$. We summarize the capability so far with the following subroutine:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\text{// suppose $c$ encrypts an (unknown) plaintextm $m_1\|\cdots\|m_\ell$}\\
\text{// does $m_i \oplus x$ end in one of the valid pading strings?}\\\\
\underline{\text{CHECKXOR}(c,i,x):}\\
\quad \text{return paddingoracle $(c_{i-1}\oplus x,c_i)$}\\\hline
\end{array}
$$

Given a ciphertext $c$ that encrypts an unknown message $m$, we can see that an adversary can generate another ciphertext whose contents are related tom in a *predictable* way. This property of an encryption scheme is called **malleability**.

### Learning the Last Byte of a Block

We now show how to use the CHECKXOR subroutine to determine the last byte of a plaintext block $m$. There are two cases to consider, depending on the contents of $m .$ The attacker does not initially know which case holds:

For the first (and easier) of the two cases, suppose the second-to-last byte of $m$ is nonzero. We will try every possible byte $b$ and ask whether $m \oplus b$ has valid padding. Since $m$ is a block and $b$ is a single byte, when we write $m \oplus b$ we mean that $b$ is extended on the left with zeroes. Since the second-to-last byte of $m$ (and hence $m \oplus b$ ) is nonzero, only one of these possibilities will have valid padding $-$ the one in which $m \oplus b$ ends in byte $\colorbox{silver}{|O1|}$. Therefore, if $b$ is the candidate byte that succeeds (i.e., $m \oplus b$ has valid padding) then the last byte of $m$ must be $b \oplus \colorbox{silver}{|O1|}$.

**Example**
Using LEARNLASTBYTE to learn the last byte of a plaintext block:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\quad \ \text{$ \cdots \colorbox{silver}{| a0 | 42 | ?? |}\quad  m =$ unknown plaintext block}\\
\underline{\oplus\  \cdots \colorbox{silver}{| a0 | 42 |\  b\   |}}\quad  b = \text{byte that causes oracle to return true}\\
=\cdots \colorbox{silver}{| a0 | 42 | \textcolor{green}{ 01 |}}\quad \text{valid padding}\  \Leftrightarrow \colorbox{silver}{| b |}\ \oplus\ \colorbox{silver}{| ?? |}\ =\ \colorbox{silver}{| 01 |}\\
\hspace{2.25in}\Leftrightarrow \colorbox{silver}{| ??|}\ \oplus\ \colorbox{silver}{| 01 |}\ \oplus\ \colorbox{silver}{|\  b\   |}\\\hline
\end{array}
$$
For the other case, suppose the second-to-last byte ofm is zero. Then $m\oplus b$ will have valid padding for several candidate values of $b$:

**Example**
Using LEARNLASTBYTE to learn the last byte of a plaintext block:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\quad \ \text{$ \cdots \colorbox{silver}{| a0 | 00 | ?? |}\quad  \quad \ \text{$ \cdots \colorbox{silver}{| a0 | 00 | ?? |}\quad  $ }m =$ unknown plaintext}\\
\underline{\oplus\  \cdots \colorbox{silver}{| 00 | 00 |\  $b_1$   |}}\quad  \underline{\oplus\  \cdots \colorbox{silver}{| 00 | 00 |\  $b_2$   |}}\quad  b_1 = \text{candidate bytes}\\
=\cdots \colorbox{silver}{| a0 | 00 | \textcolor{green}{ 01 |}}\quad =\cdots \colorbox{silver}{| a0 | 00 | \textcolor{green}{ 01 |}}\quad \text{two candidates cause oracle to return true} \\
\qquad \quad\downarrow \qquad \qquad \qquad \qquad \qquad\downarrow\\
\quad \ \text{$ \cdots \colorbox{silver}{| a0 | 00 | ?? |}\quad  \quad \ \text{$ \cdots \colorbox{silver}{| a0 | 00 | ?? |}\quad  $ }$ }\\
\underline{\oplus\  \cdots \colorbox{silver}{| 00 | 01 |\  $b_1$   |}}\quad  \underline{\oplus\  \cdots \colorbox{silver}{| 00 | 01 |\  $b_2$   |}}\quad   \text{same $b_1,b_2$, but change next-to-last byte}\\
=\cdots \colorbox{silver}{| a0 | 01 | \textcolor{green}{ 01 |}}\quad =\cdots \colorbox{silver}{| a0 | \textcolor{brown}{ 01} | \textcolor{brown}{ 02 |}}\quad \text{only one causes oracle to return true} \\
\hspace{2.8in}\Rightarrow \colorbox{silver}{??}=\colorbox{silver}{$b_1$}\oplus\colorbox{silver}{$01$}\\\hline
\end{array}
$$

Whenever more than one candidate $b$ value yields valid padding, we know that the second-to-last byte of $m$ is zero (in fact, by counting the number of successful candidates, we can know exactly how many zeroes precede the last byte of $m$ ).

If the second-to-last byte of $m$ is zero, then the second-to-last byte of $m \oplus \colorbox{silver}{|01|b|} b$ is nonzero. The only way for both strings $m \oplus\colorbox{silver}{|01|b|} b$ and $m \oplus b$ to have valid padding is when $m \oplus b$ ends in byte $\colorbox{silver}{|01|b|}$ . We can re-try all of the successful candidate $b$ values again, this time with an extra nonzero byte in front. There will be a unique candidate $b$ that is successful in both rounds, and this will tell us that the last byte of $m$ is $b \oplus \colorbox{silver}{|01|b|}$.

The overall approach for learning the last byte of a plaintext block is summarized in the LEARNLASTBYTE subroutine in Figure $9.1 .$ The set $B$ contains the successful candidate bytes from the first round. There are at most 16 elements in $B$ after the first round, since there are only 16 valid possibilities for the last byte of a properly padded block. In the worst case, LEARNLASTBYTE makes $256+16=272$ calls to the padding oracle (via CHECKXOR).

### Learning Other Bytes of a Block

Once we have learned one of the trailing bytes of a plaintext block, it is slightly easier to learn additional ones. Suppose we know the last 3 bytes of a plaintext block, as in the example below. We would like to use the padding oracle to discover the 4th-to-last byte.

**Example**
Using LEARNPREVBYTE to learn the 4th-to-last byte when the last 3 bytes of the block are already known.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\quad \ \text{$ \cdots \colorbox{silver}{| ?? | a0 | 42 | 3c|}\quad  m =$ unknown plaintext block}\\
\oplus\  \cdots \colorbox{silver}{| 00 | 00 | 00 |04 |}\quad  p = \text{string ending in}\ \ \colorbox{silver}{|04|} \\
\oplus\  \cdots \colorbox{silver}{| 00 | a0 | 42 |3c |}\quad  s = \text{known bytes of $m$}\\
\underline{\oplus\  \cdots \colorbox{silver}{| b  | 00 | 00 | 00 |}}\quad  y = \text{candidate byte $b$ shifted into place}\\
=\  \cdots \colorbox{silver}{| \textcolor{green}{00} | \textcolor{green}{00} | \textcolor{green}{00} |\textcolor{green}{00} |}\quad  \text{valid padding $\Rightarrow \colorbox{silver}{??}=\colorbox{silver}{b}$}\\\hline
\end{array}
$$

Since we know the last 3 bytes of $m$, we can calculate a string $x$ such that $m \oplus x$ ends in $\colorbox{silver}{|00|00|04|}$ . Now we can try xor'ing the 4 th-to-last byte of $m \oplus x$ with different candidate bytes $b$, and asking the padding oracle whether the result has valid padding. Valid padding only occurs when the result has $\colorbox{silver}{|00|}$ in its 4 th-to-last byte, and this happens exactly when the 4 th-to-last byte of $m$ exactly matches our candidate byte $b$.

The process is summarized in the LEARNPREVBYTE subroutine in Figure $9.1 .$ In the worst case, this subroutine makes 256 queries to the padding oracle.

**Putting it all together.** We now have all the tools required to decrypt any ciphertext using only the padding oracle. The process is summarized below in the LEARNALL. subroutine.

In the worst case, 256 queries to the padding oracle are required to learn each byte of the plaintext. $^{2}$ However, in practice the number can be much lower. The example in this section was inspired by a real-life padding oracle attack ${ }^{3}$ which includes optimizations that allow an attacker to recover each plaintext byte with only 14 oracle queries on average.

## 9.2 What Went Wrong?

CBC encryption provides CPA security, so why didn't it save us from padding oracle attacks? How was an attacker able to completely obliterate the privacy of encryption?
1. First, CBC encryption (in fact, every encryption scheme we've seen so far) has a property called malleability. Given an encryption $c$ of an unknown plaintext $m$, it is possible to generate another ciphertext $c^{\prime}$ whose contents are related to $m$ in a predictable way. In the case of CBC encryption, if ciphertext $c_{0}\|\cdots\| c_{\ell}$ encrypts a plaintext $m_{1}\|\cdots\| m_{\ell}$, then ciphertext $\left(c_{i-1} \oplus x, c_{i}\right)$ encrypts the related plaintext $m_{i} \oplus x$
In short, if an encryption scheme is malleable, then it allows information contained in one ciphertext to be "transferred" to another ciphertext.

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

2. Second, you may have noticed that the CPA security definition makes no mention of the Dec algorithm. The Dec algorithm shows up in our definition for correctness, but it is nowhere to be found in the $\mathcal{L}_{\text {cpa- } \star}$ libraries. Decryption has no impact on CPA security!

But the padding oracle setting involved the Dec algorithm - in particular, the adversary was allowed to see some information about the result of Dec applied to adversarially-chosen ciphertexts. Because of that, the CPA security definition does not capture the padding oracle attack scenario.

The bottom line is: give an attacker a malleable encryption scheme and access to any partial information related to decryption, and he/she can get information to leak out in surprising ways. As the padding-oracle attack demonstrates, even if only a single bit of information (i.e., the answer to a yes/no question about a plaintext) is leaked about the result of decryption, this is frequently enough to extract the entire plaintext.

If we want security even under the padding-oracle scenario, we need a better security definition and encryption schemes that achieve it. That's what the rest of this chapter is about.

### Discussion
- **Is this a realistic concern?** You may wonder whether this whole situation is somewhat contrived just to give cryptographers harder problems to solve. That was probably a common attitude towards the security definitions introduced in this chapter. However, in 1998, Daniel Bleichenbacher demonstrated a devastating attack against early versions of the SSL protocol. By presenting millions of carefully crafted ciphertexts to a webserver, an attacker could eventually recover arbitrary SSL session keys.
In practice, it is hard to make the external behavior of a server not depend on the result of decryption. This makes CPA security rather fragile in the real world. In the case of padding oracle attacks, mistakes in implementation can lead to different error messages for invalid padding. In other cases, even an otherwise careful implementation can provide a padding oracle through a timing side-channel (if the server's response time is different for valid/invalid padded plaintexts).
As we will see, it is in fact possible to provide security in these kinds of settings, and with low additional overhead. These days there is rarely a good excuse for using encryption which is only CPA-secure.
- Padding is in the name of the attack. But padding is not the culprit. The culprit is using a (merely) CPA-secure encryption scheme while allowing some information to leak about the result of decryption. The exercises expand on this idea further.
- **If padding is added to only the last block of the plaintext, how can this attack recover the entire plaintext?** This common confusion is another reason to not place so much blame on the padding scheme. A padding oracle has the following behavior: "give me an encryption of $m_{1}\|\cdots\| m_{\ell}$ and I'll tell you some information about $m_{\ell}$ (whether it ends with a certain suffix)." Indeed, the padding oracle checks only the last block. However, CBC mode has the property that if you have an encryption of $m_{1}\|\cdots\| m_{\ell},$ then you can easily construct a different ciphertext that encrypts $m_{1}\|\cdots\| m_{\ell-1} .$ If you send this ciphertext to the padding oracle, you will get information about $m_{\ell-1} .$ By modifying the ciphertext (via the malleability of $\mathrm{CBC}$ ), you give different plaintext blocks the chance to be the "last block" that the padding oracle looks at.
- The attack seems superficially like brute force, but it is not: The attack makes 256 queries per byte of plaintext, so it costs about $256 \ell$ queries for a plaintext of $\ell$ bytes. Brute-forcing the entire plaintext would cost $256^{\ell}$ since that's how many $\ell$ -byte plaintexts there are. So the attack is exponentially better than brute force. The lesson is: brute-forcing small pieces at a time is much better then brute-forcing the entire thing.

## 9.3 Defining CCA Security
Our goal now is to develop a new security definition $-$ one that considers an adversary that can construct malicious ciphertexts and observe the effects caused by their decryption. We will start with the basic approach of CPA security, with left and right libraries that differ only in which of two plaintexts they encrypt.

In a typical system, an adversary might be able to learn only some specific partial *information* about the Dec process. In the padding oracle attack, the adversary was able to learn only whether the result of decryption had valid padding.

However, we are trying to come up with a security definition that is useful no matter how the encryption scheme is deployed. How can we possibly anticipate every kind of partial information that might make its way to the adversary in every possible usage of the encryption scheme? The safest choice is to be as pessimistic as possible, as long as we end up with a security notion that we can actually achieve in the end. **So let's just allow the adversary to totally decrypt arbitrary ciphertexts of its choice**. In other words, if we can guarantee security when the adversary has full information about decrypted ciphertexts, then we certainly have security when the adversary learns only partial information about decrypted ciphertexts (as in a typical real-world system).

But this presents a significant problem. An adversary can do $c^{*}:=$ EAVESDROP $\left(m_{L}, m_{R}\right)$ to obtain a challenge ciphertext, and then immediately ask for that ciphertext $c^{*}$ to be decrypted. This will obviously reveal to the adversary whether it is linked to the left or right library.

So, simply providing unrestricted Dec access to the adversary cannot lead to a reasonable security definition (it is a security definition that can never be satisfied). The simplest way to patch this obvious problem with the definition is to allow the adversary to ask for the decryption of **any ciphertext, except those produced in response to EAVESDROP** queries. In doing so, we arrive at the final security definition: security against chosenciphertext attacks, or CCA-security:

**Definition 9.1 (CCA security)**
Let $\Sigma$ be an encryption scheme. We say that $\Sigma$ has **security against chosen-ciphertext attacks (CCA security)** if $\mathcal{L}_{\text {cca-L }}^{\Sigma} \approx \mathcal{L}_{\text {cca-R }}^{\Sigma},$ where


$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text {cca-L }}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
S:=\emptyset\\\\
\underline{\text{EAVESDROP}(m_L,m_R\in \Sigma.\mathcal{M}):}\\
\quad\text{if} |m_L|\neq |m_R|\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad c:=\Sigma.\text{Enc}(k,m_L)\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return}\ \Sigma.\text{Dec}(k,c)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text {cca-R }}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
S:=\emptyset\\\\
\underline{\text{EAVESDROP}(m_L,m_R\in \Sigma.\mathcal{M}):}\\
\quad\text{if} |m_L|\neq |m_R|\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad c:=\Sigma.\text{Enc}(k,m_R)\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return}\ \Sigma.\text{Dec}(k,c)\\\hline
\end{array}
$$

In this denition, the set $S$ keeps track of the ciphertexts that have been generated by the eavesdrop subroutine. The decrypt subroutine refuses to decrypt these ciphertexts, but will gladly decrypt any other ciphertext of the adversary’s choice.

### An Example
The padding oracle attack already demonstrates that CBC mode does not provide security in the presence of chosen ciphertext attacks. But that attack was quite complicated since the adversary was restricted to learn just 1 bit of information at a time about a decrypted ciphertext. An attack against full CCA security can be much more direct, since the adversary has full access to decrypted ciphertexts.

**Example**
Consider the adversary below attacking the CCA security of CBC mode (with block length blen)
$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \mathcal{A}\\\hline
c=c_0\|c_1\|c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{2blen},\textcolor{brown}{1}^{2blen})\\
m:=\text{DECRYPT}(c_0\|c_1)\\
\text{return}\ m\stackrel{?}{=}\textcolor{brown}{0}^{blen}\\\hline
\end{array}
$$

It can easily be verified that this adversary achieves advantage 1 distinguishing $\mathcal{L}_{\text {cca-L }}$ from $\mathcal{L}_{\text {cca-R. }}$ The attack uses the fact (also used in the padding oracle attack) that if $c_{0}\left\|c_{1}\right\| c_{2}$ encrypts $m_{1} \| m_{2},$ then $c_{0} \| c_{1}$ encrypts $m_{1} .$ To us, it is obvious that ciphertext $c_{0} \| c_{1}$ is related to $c_{0}\left\|c_{1}\right\| c_{2} .$ Unfortunately for $C B C$ mode, the security definition is not very clever $-$ since $c_{0} \| c_{1}$ is simply different than $c_{0}\left\|c_{1}\right\| c_{2},$ the DECRYPT subroutine happily decrypts it.

**Example**
Perhaps unsurprisingly, there are many very simple ways to catastrophically attack the CCA security of CBC-mode encryption. Here are some more (where $\bar{x}$ denotes the result of flipping every bit in $x$ ):

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \mathcal{A'}\\\hline
c_0\|c_1\|c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{2blen},\textcolor{brown}{1}^{2blen})\\
m:=\text{DECRYPT}(c_0\|c_1\|\overline{c_2})\\
\text{if $m$ begins with $\textcolor{brown}{0}^{blen}$ return 1 else return 0}\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \mathcal{A''}\\\hline
c_0\|c_1\|c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{2blen},\textcolor{brown}{1}^{2blen})\\
m:=\text{DECRYPT}(\overline{c_0}\|c_1\|c_2)\\
\text{return}\ m\stackrel{?}{=}\textcolor{brown}{0}^{blen}\\\hline
\end{array}
$$

It can easily be verified that this adversary achieves advantage 1 distinguishing $\mathcal{L}_{\text {cca-L }}$ from $\mathcal{L}_{\text {cca-R. }}$ The attack uses the fact (also used in the padding oracle attack) that if $c_{0}\left\|c_{1}\right\| c_{2}$ encrypts $m_{1} \| m_{2},$ then $c_{0} \| c_{1}$ encrypts $m_{1} .$ To us, it is obvious that ciphertext $c_{0} \| c_{1}$ is related to $c_{0}\left\|c_{1}\right\| c_{2} .$ Unfortunately for $C B C$ mode, the security definition is not very clever $-$ since $c_{0} \| c_{1}$ is simply different than $c_{0}\left\|c_{1}\right\| c_{2},$ the DECRYPT subroutine happily decrypts it.

**Example**
Perhaps unsurprisingly, there are many very simple ways to catastrophically attack the CCA security of $\mathrm{CBC}$ - mode encryption. Here are some more (where $\bar{x}$ denotes the result of flipping every bit in $x$ ):

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \mathcal{A'}\\\hline
c_0\|c_1\|c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{2blen},\textcolor{brown}{1}^{2blen})\\
m:=\text{DECRYPT}(c_0\|c_1\|\overline{c_2})\\
\text{if $m$ begins with $\textcolor{brown}{0}^{blen}$ return 1 else return 0}\\\hline
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \qquad \qquad \mathcal{A''}\\\hline
c_0\|c_1\|c_2:=\text{EAVESDROP}(\textcolor{brown}{0}^{2blen},\textcolor{brown}{1}^{2blen})\\
m:=\text{DECRYPT}(\overline{c_0}\|c_1\|c_2)\\
\text{return}\ m\stackrel{?}{=}\textcolor{brown}{1}^{blen}\|\textcolor{brown}{0}^{blen}\\\hline
\end{array}
$$

The first attack uses the fact that modifying $c_2$ has no effect on the first plaintext block. The second attack uses the fact that flipping every bit in the IV flips every bit inm1.

Again, in all of these cases, the decrypt subroutine is being called on a different (but related) ciphertext than the one returned by eavesdrop.

### Discussion

**So if I use a CCA-secure encryption scheme, I should never decrypt a ciphertext that I encrypted myself?**

Remember: when we define the Enc and Dec algorithms of an encryption scheme, we are describing things from the normal user's perspective. As a user of an encryption scheme, you can encrypt and decrypt whatever you like. It would indeed be strange if you encrypted something knowing that it should never be decrypted. What's the point?

The security definition describes things from the attacker's perspective. The $\mathcal{L}_{\mathrm{cca}-\star}$ libraries tell us *what are the circumstances under which the encryption scheme provides security?* They say (roughly):

>an attacker can't tell what's inside a ciphertext $c^{*}$, even if she has some partial information about that plaintext, even if she had some partial influence over the choice of that plaintext, and even if she is allowed to decrypt any other ciphertext she wants.

Of course, if a real-world system allows an attacker to learn the result of decrypting $c^{*}$, then by definition the attacker learns what's inside that ciphertext.

CCA security is deeply connected with the concept of **malleability**. Malleability means that, given a ciphertext that encrypts an unknown plaintext $m,$ it is possible to generate a different ciphertext that encrypts a plaintext that is *related* to $m$ in a predictable way. For example:
- If $c_{0}\left\|c_{1}\right\| c_{2}$ is a CBC encryption of $m_{1} \| m_{2}$, then $c_{0} \| c_{1}$ is a CBC encryption of $m_{1}$.
- If $c_{0}\left\|c_{1}\right\| c_{2}$ is a CBC encryption of $m_{1} \| m_{2}$, then $c_{0}\left\|c_{1}\right\| c_{2} \| \textcolor{brown}{0}^{\text {blen }}$ is a CBC encryption of some plaintext that begins with $m_{1} \| m_{2}$.
- If $c_{0} \| c_{1}$ is a CBC encryption of $m_{1}$, then $\left(c_{0} \oplus x\right) \| c_{1}$ is a CBC encryption of $m_{1} \oplus x$.

Note from the second example thatwe don’t need to knowexactly the relationship between the old and new ciphertexts.

If an encryption scheme is malleable, then a typical attack against its CCA security would work as follows:

 1. Request an encryption c of some plaintext.
 2. Applying the malleability of the scheme, modify $c$ to some other ciphertext $c'$.
 3. Ask for $c'$ to be decrypted.

Since $c' \neq c$, the security library allows $c'$ to be decrypted. The malleability of the scheme
says that the contents of $c'$ should be related to the contents of $c$. In other words, seeing the contents of $c'$ should allow the attacker to determine what was initially encrypted in $c$.

### Pseudorandom Ciphertexts
We can also modify the pseudorandom-ciphertexts security definition (CPA$ security) in a similar way:

**Definition 9.2 (CCA$\varPhi$ security)**

Let $\Sigma$ be an encryption scheme. We say that $\Sigma$ has **pseudorandom ciphertexts in the presence of chosen-ciphertext attacks (CCA$ security)** if $\mathcal{L}_{\text{cca}\varPhi\text{-real}}\approx\mathcal{L}_{\text{cca}\varPhi\text{-real}}$, where:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text {cca}\varPhi-\text{real }}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
S:=\emptyset\\\\
\underline{\text{CTXT}(m\in \Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{c:=}\Sigma.\text{Enc}(k,m)\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return}\ \Sigma.\text{Dec}(k,c)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \mathcal{L}_{\text {cca}\varPhi-\text{rand }}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
S:=\emptyset\\\\
\underline{\text{CTXT}(m\in \Sigma.\mathcal{M}):}\\
\quad \colorbox{yellow}{c:=}\Sigma.\text{Enc}(k,m)\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return}\ \Sigma.\text{Dec}(k,c)\\\hline
\end{array}
$$

Just like for CPA security, if a scheme has CCA$\varPhi$ security, then it also has CCA security, but not vice-versa. See the exercises.

## $\star\quad$ 9.4 A Simple CCA-Secure Scheme
Recall the definition of a strong pseudorandom permutation (PRP) (Definition 6.13). A strong PRP is one that is indistinguishable from a randomly chosen permutation, even to an adversary that can make both forward (i.e., to $F$ ) and reverse (i.e., to $F^{-1}$ ) queries.

This concept has some similarity to the definition of CCA security, in which the adversary can make queries to both Enc and its inverse Dec. Indeed, a strong PRP can be used to construct a CCA-secure encryption scheme in a natural way:

**Construction 9.3**
Let $F$ be a pseudorandom permutation with block length blen $=n+\lambda .$ Define the following encryption scheme with message space $\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}(k,m):} &  \underline{\text{Dec}(k,c):}\\
\quad k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & v:=F^{-1}(k,c)\\
\quad \text{return}\ k & \quad \text{return}\ F(k,m\|r) & \quad \text{return first $n$ bits of $v$}\\\hline
\end{array}
$$

In this scheme, $m$ is encrypted by appending a random value $r$ to it, then applying a PRP. While this scheme is conceptually quite simple, it is generally not used in practice since it requires a block cipher with a fairly large block size, and these are rarely encountered.

 We can informally reason about the security of this scheme as follows:
 
- Imagine an adversary linked to one of the CCA libraries. As long as the random value $r$ does not repeat, all inputs to the PRP are distinct. The guarantee of a pseudorandom function/permutation is that its outputs (which are the *ciphertexts* in this scheme) will therefore all look independently uniform.

- The CCA library prevents the adversary from asking for $c$ to be decrypted, if $c$ was itself generated by the library. For any other value $c^{\prime}$ that the adversary asks to be decrypted, the guarantee of a strong PRP is that the result will look independently random. In particular, the result will not depend on the choice of plaintexts used to generate challenge ciphertexts. Since this choice of plaintexts is the only difference between the two CCA libraries, these decryption queries (intuitively) do not help the adversary.

We now prove the CCA security of Construction 9.3 formally:

**Claim 9.4**
If $F$ is a strong PRP (Definition 6.13) then Construction 9.3 has CCA$\varPhi$ security (and therefore CCA security).

**Proof**
As usual, we prove the claim in a sequence of hybrids.

$$
\def\arraystretch{1.5}
\mathcal{L}_{\text {cca}\varPhi-\text{real }}^{\Sigma}:\ 
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text {cca}\varPhi-\text{real }}^{\Sigma}\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
S:=\emptyset\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad c:=F(k,m\|r)\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return first $n$ bits of}\ F^{-1}(k,c)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{The starting point is $\mathcal{L}_{\text {cca}\varPhi-\text{real }}^{\Sigma}$ as expected, where}\\
\text{$\Sigma$ refers to Construction 9.3.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{if $T [m\| r] $ undefined:}\\
\qquad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T.\text{values}\\
\qquad T[m\|r]:=c;T_{inv}[c]:=m\|r\\
\quad c:=T[m\|r]\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T_{inv}.\text{values}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have applied the strong PRP security (Definition 6.13)}\\
\text{of $F$ , skipping some standard intermediate steps.}\\
\text{We factored out all invocations of $F$ and $F^{-1}$ in terms}\\
\text{of the $\mathcal{L}_{\text{sprp-real}}$ library, replaced that library with}\\
\text{$\mathcal{L}_{\text{sprp-rand}}$, and finally inlined it.}
\end{array}
$$

This proof has some subtleties, so it's a good time to stop and think about what needs to be done. To prove CCA\$-security, we must reach a hybrid in which the responses of $\mathrm{CTXT}$ are uniform. In the current hybrid there are two properties in the way of this goal:

- The ciphertext values $c$ are sampled from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }} \backslash T$.values, rather than $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$.
- When the if-condition in crxt is false, the return value of crxt is not a fresh random value but an old, repeated one. This happens when $T[m \| r]$ is already defined. Note that both crxt and DECRYPT assign to $T,$ so either one of these subroutines may be the cause of a pre-existing $T[m \| r]$ value.

Perhaps the most subtle fact about our current hybrid is that arguments of crxt can affect responses from DECRYPT! In crxt, the library assigns $m \| r$ to a value $T_{\text {inv }}[c]$. Later calls to DECRYPT will not read this value directly; these values of $c$ are off-limits due to the guard condition in the first line of $\mathrm{DECRYPT}$. However, DECRYPT samples a value from $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }} \backslash T_{\text {inv. }}$ values, which indeed uses the values $T_{\text {inv }}[c]$. To show CCA$\varPhi$ security, we must remove this dependence of DECRYPT on previous values given to CTXT.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset; \quad \mathcal{R}:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{if $T [m\| r] $ undefined:}\\
\qquad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T.\text{values}\\
\qquad T[m\|r]:=c;T_{inv}[c]:=m\|r\\
\quad c:=T[m\|r]\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash T_{inv}.\text{values}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have added some book-keeping that is not used}\\
\text{anywhere. Every time an assignment of the form}\\
\text{$T[m\|r]$ happens, we add $r$ to the set $\mathcal{R}$. Looking}\\
\text{ahead, we eventually want to ensure that $r$ is chosen}\\
\text{so that the if-statement in ctxt is always taken, and}\\
\text{the return value of CTXT is always a *fresh* random value.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset; \quad \mathcal{R}:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash \mathcal{R}\\
\quad \text{if $T [m\| r] $ undefined:}\\
\qquad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash \\
\qquad T[m\|r]:=c;T_{inv}[c]:=m\|r\\
\quad \quad \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad c:=T[m\|r]\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
$$

We have applied Lemma 4.12 three separate times. The standard intermediate steps (factor out, swap library, inline) have been skipped, and this shows only the final result.

In CTXT, we’ve added a restriction to how $r$ is sampled. Looking ahead, sampling $r$ in this way means that the if-statement in CTXT is always taken.

In CTXT, we’ve removed the restriction in how $c$ is sampled. Since $c$ is the final return value of CTXT, this gets us closer to our goal of this return value being uniformly random.

In decrypt, we have removed the restriction in how $m\|r$ is sampled. As described above, this is
because $T_{inv}$:values contains previous arguments of CTXT, and we don’t want these arguments to affect the result of decrypt in any way.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset; \quad \mathcal{R}:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash \mathcal{R}\\
\quad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\quad T[m\|r]:=c;T_{inv}[c]:=m\|r\\
\quad  \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{In the previous hybrid, the if-statement in CTXT is}\\
\text{always taken. This is because if $T[m\|r]$ is already}\\
\text{defined, then $r$ would already be in $\mathcal{R}$, but we are}\\
\text{sampling $r$ to avoid everything in $\mathcal{R}$. We can therefore}\\
\text{simply execute the body of the if-statement without}\\
\text{actually checking the condition.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset; \quad \mathcal{R}:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash \mathcal{R}\\
\quad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\quad \colorbox{yellow}{//}T[m\|r]:=c;T_{inv}[c]:=m\|r\\
\quad  \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{In the previous hybrid, no line of code ever reads}\\
\text{from $T$ ; they only write to $T$ . It has no effect to remove}\\
\text{a line that assigns to $T$ , so we do so in CTXT.}\\\\
\text{CTXT also writes to $T[m\|r]$, but for a value $c\in S$.}\\
\text{The only line that reads from $T_{inv}$ is in decrypt,}\\
\text{but the first line of decrypt prevents it from being}\\
\text{reached for such a $c\in S$. It therefore has no effect}\\
\text{to remove this assignment to $T_{inv}$.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset; \quad \colorbox{yellow}{//}\mathcal{R}:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad \colorbox{yellow}{//}r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\backslash \mathcal{R}\\
\quad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\quad  \colorbox{yellow}{//}\mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\qquad \colorbox{yellow}{//}\mathcal{R}:=\mathcal{R}\cup\{r\}\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{Consider all the ways that $\mathcal{R}$ is used in the previous}\\
\text{hybrid. The first line of CTXT uses $\mathcal{R}$ to sample $r$ , but}\\
\text{then $r$ is subsequently used only to further update}\\
\text{$\mathcal{R}$ and nowhere else. Both subroutines use $\mathcal{R}$ only}\\
\text{to update the value of $\mathcal{R}$. It has no effect to simply}\\
\text{remove all lines that refer to variable $\mathcal{R}$.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
S:=\emptyset\\
\text{$T,T_{inv}$ := empty assoc. arrays}\\\\
\underline{\text{CTXT}(m):}\\
\quad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{if $T_{inv} [c] $ undefined:}\\
\qquad m\|r \leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\backslash \colorbox{yellow}{T}_{inv.}\text{values}\\
\qquad T_{inv}[c]:=m\|r;T[m\|r]:=c\\
\quad \text{return first $n$ bits of}\ T_{inv}[c]\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have applied Lemma 4.12 to the sampling step}\\
\text{in DECRYPT. The standard intermediate steps have}\\
\text{been skipped. Now the second if-statement in}\\
\text{decrypt exactly matches $\mathcal{L}_{\text{sprp-rand}}$.}
\end{array}
$$

$$
\def\arraystretch{1.5}
\mathcal{L}_{\text{cca}\varPhi-\text{rand}}^\Sigma:\ 
\begin{array}{|l|}\hline
\qquad \qquad\ \mathcal{L}_{\text{cca}\varPhi-\text{rand}}^\Sigma\\\hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}\\
S:=\emptyset\\\\
\underline{\text{CTXT}(m):}\\
\quad c\leftarrow  \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{blen}\\
\quad S:=S\cup\{c\}\\
\quad\text{return}\ c\\\\
\underline{\text{DECRYPT}}(c\in \Sigma.C):\\
\quad \text{if}\ c\in S\ \text{return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return first $n$ bits of}\ \colorbox{yellow}{F}^{-1}(k,c)\\\hline
\end{array}
\quad
\begin{array}{l}
\text{We have applied the strong PRP security of $F$ to}\\
\text{replace $\mathcal{L}_{\text{sprp-rand}}$ with $\mathcal{L}_{\text{sprp-real}}$. The standard intermediate}\\
\text{steps have been skipped. The result is $\mathcal{L}_{\text{cca}\varPhi-\text{rand}}$.}\\
\end{array}
$$

We showed that $\mathcal{L}_{\text {ccas-real }}^{\Sigma} \approx \mathcal{L}_{\text {ccas-rand }}^{\Sigma}$, so the scheme has CCA\$ security.

### Exercises
9.1. There is nothing particularly bad about padding schemes. They are only a target because padding is a commonly used structure in plaintexts that is verified at the time of decryption.

A null character is simply the byte $\colorbox{silver}{00}$. We say that a string is properly null terminated if its last character is null, but no other characters are null. Suppose you have access to the following oracle:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{NULLTERMORACLE}(c):}\\
\quad m := \text{Dec}(k,c)\\
\quad \text{if $m$ is properly null terminated:}\\
\qquad \text{return true}\\
\quad \text{else return false}\\\hline
\end{array}
$$

Suppose you are given a CTR-mode encryption of an unknown (but properly null terminated) plaintext $m^*$ under unknown key $k$. Suppose that plaintexts of arbitrary length are supported by truncating the CTR-stream to the appropriate length before xoring with the plaintext.

Show how to completely recover $m^*$ in the presence of this null-termination oracle.

9.2. Show how to completely recover the plaintext of an arbitrary CBC-mode ciphertext in the
presence of the following oracle:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{NULLORACLE}(c):}\\
\quad m := \text{Dec}(k,c)\\
\quad \text{if $m$ contains a null character:}\\
\qquad \text{return true}\\
\quad \text{else return false}\\\hline
\end{array}
$$

Assume that the victim ciphertext encodes a plaintext that does not use any padding (its plaintext is an exact multiple of the block length).

9.3. Show how to perform a padding oracle attack, to decrypt arbitrary messages that use
PKCS#7 padding (where all padded strings end with $\colorbox{silver}{|01|,|02|02|, |03|03|03|}$ , etc.).

9.4. Sometimes encryption is as good as decryption, to an adversary.
(a) Suppose you have access to the following encryption oracle, where s is a secret that is consistent across all calls:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{ECBORACLE}(m):}\\
\quad //k,s\ \text{are secret}\\
\quad \text{return ECB:Enc}(k,m\|s)
\\\hline
\end{array}
$$

Yes, this question is referring to the awful **ECB** encryption mode (Construction 8.1). Describe an attack that efficiently recovers all of s using access to ecboracle. Assume that if the length of $m\|s$ is not a multiple of the blocklength, then ECB mode will pad it with null bytes.
>Hint: By varying the length ofm, you can control where the block-division boundaries are in $s$.

(b) Now suppose you have access to a CBC encryption oracle, where you can control the
IV that is used:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{CBCORACLE}(m):}\\
\quad //k,s\ \text{are secret}\\
\quad \text{return CBC:Enc}(k,iv, m\|s)
\\\hline
\end{array}
$$

Describe an attack that efficiently recovers all of $s$ using access to CBCORACLE. As above, assume that $m \| s$ is padded to a multiple of the blocklength in some way. It is possible to carry out the attack no matter what the padding method is, as long as the padding method is known to the adversary.

$\star$ 9.5. Show how a padding oracle (for CBC-mode encryption with X.923 padding) can be used to **generate a valid encryption** of any chosen plaintext, under the same (secret) key that the padding oracle uses. In this problem, you are not given access to an encryption subroutine, or any valid ciphertexts - only the padding oracle subroutine.

9.6. Prove formally that CCA$\varPhi$ security implies CCA security.

9.7. Let $\Sigma$ be an encryption scheme with message space $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{n}$ and define $\Sigma^{2}$ to be the following encryption scheme with message space $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{2 n}$

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}(k,m):} &  \underline{\text{Dec}(k,(c_1,c_2)):}\\
\quad k\leftarrow \Sigma.\text{KeyGen} & \quad c_1:=\Sigma.\text{Enc}(k,m_{\text{left}})& \quad m_1:=\Sigma.\text{Dec}(k,c_1)\\
\quad \text{return}\ k & \quad c_2:=\Sigma.\text{Enc}(k,m_{\text{right}}) & \quad m_2:=\Sigma.\text{Dec}(k,c_2)\\
& \quad \text{return}\ (c_1,c_2) &\quad \text{if}\ \textcolor{brown}{\texttt{err}} \in \{m_1,m_2\}:\\
& &  \quad \text{return}\ \textcolor{brown}{\texttt{err}}\\
& & \quad \text{else return}\ m_1\|m_2\\\hline
\end{array}
$$

(a) Prove that if $\Sigma$ has CPA security, then so does $\Sigma^{2}$.
(b) Show that even if $\Sigma$ has CCA security, $\Sigma^{2}$ does not. Describe a successful distinguisher and compute its distinguishing advantage.

9.8. Show that the following block cipher modes do not have CCA security. For each one, describe a successful distinguisher and compute its distinguishing advantage.
(a) OFB mode
(b) CBC mode
(c ) CTR mode

9.9. Show that none of the schemes in Exercise 7.7 have CCA security. For each one, describe a successful distinguisher and compute its distinguishing advantage.

9.10. Let F be a secure block cipher with blocklength  $\lambda$. Below is an encryption scheme for plaintexts $\mathcal{M} =\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda$. Formally describe its decryption algorithm and show that it does not have CCA security.

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}(k,m):} \\
\quad k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ k & \quad c_1:=F(k,r)\\
& \quad c_2:=r\oplus F(k,m)\\
&\quad \text{return}(c_1,c_2)\\\hline
\end{array}
$$

9.11. Let $F$ be a secure block cipher with blocklength  $\lambda$. Below is an encryption scheme for plaintexts $\mathcal{M} =\{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda$. Formally describe its decryption algorithm and show that it does not have CCA security.

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}((k_1,k_2),m):} \\
\quad k_1\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda & \quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
 \quad k_2\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda  & \quad c_1:=F(k_1,r)\\
\quad \text{return}(k_1,k_2)& \quad c_2:=F(k_1,r\oplus m\oplus k_2)\\
&\quad \text{return}(c_1,c_2)\\\hline
\end{array}
$$

9.12. Alice has the following idea for a CCA-secure encryption. To encrypt a single plaintext block $m,$ do normal $\mathrm{CBC}$ encryption of $\textcolor{brown}{0}^{blen } \| m .$ To decrypt, do normal CBC decryption but give an error if the first plaintext block is not all zeroes. Her reasoning is:
- The ciphertext has 3 blocks (including the IV). If an adversary tampers with the IV or the middle block of a ciphertext, then the first plaintext block will no longer be all zeroes and the ciphertext is rejected.

If an adversary tampers with the last block of a ciphertext, then the CBC decryption results in $\textcolor{brown}{0}^{blen } \| m^{\prime}$ where $m^{\prime}$ is unpredictable from the adversary's point of view. Hence the result of decryption $\left(m^{\prime}\right)$ will leak no information about the original $m .$

More formally, let CBC denote the encryption scheme obtained by using a secure PRF in CBC mode. Below we define an encryption scheme $\Sigma^{\prime}$ with message space $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\text {blen }}$ and ciphertext space $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{3 \text { blen }}$ :

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\Sigma'.\text{KeyGen}:} &  \underline{\Sigma'.\text{Dec}(k,c):} \\
\quad k\leftarrow \text{CBC.KeyGen} & \quad m_1\|m_2:=\text{CBC.Dec(k,c)}\\
\quad \text{return}\ k &\quad \text{if}\ m_1=\textcolor{brown}{0}^{blen};\\
& \qquad \text{return}\ m_2\\
\underline{\Sigma'.\text{Enc}(k,m):} & \text{else return}\ \textcolor{brown}{\texttt{err}}\\
\quad \text{return CBC.Enc}(k,\textcolor{brown}{0}^{blen}\|m)\\\hline
\end{array}
$$

Show that $\Sigma'$ does not have CCA security. Describe a distinguisher and compute its distinguishing advantage. What part of Alice’s reasoning was not quite right?
> Hint: Obtain a ciphertext $c=c_0\|c_1\|c_2$ and another ciphertext $c=c'_0\|c'_1\|c'_2$, both with known plaintexts. Ask the library to decrypt $c_0\|c_1\|c'_2$

9.13. CBC and OFB modes are malleable in very different ways. For that reason, Mallory claims that encrypting a plaintext (independently) with both modes results in CCA security, when the Dec algorithm rejects ciphertexts whose OFB and CBC plaintexts don’t match. The reasoning is that it will be hard to tamper with both ciphertexts in a way that achieves the same effect on the plaintext.

Let CBC denote the encryption scheme obtained by using a secure PRF in CBC mode. Let
OFB denote the encryption scheme obtained by using a secure PRF in OFB mode. Below
we define an encryption scheme $\Sigma'$:

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\Sigma'.\text{KeyGen}:} &  \\
\quad k_{\text{cbc}} \leftarrow \text{CBC.KeyGen} &\\
\quad k_{\text{ofb}} \leftarrow \text{OFB.KeyGen} & \underline{\Sigma'.\text{Dec}(k_{\text{cbc}},k_{\text{ofb}},(c,c')):}\\
\quad\text{return}\ (k_{\text{cbc}},k_{\text{ofb}}) & \quad m:=\text{CBC.Dec}(k_{\text{cbc}},c)\\
& \quad m':=\text{CBC.Dec}(k_{\text{ofb}},c')\\
&\quad \text{if}\ m=m':\\
\underline{\Sigma'.\text{Enc}(k_{\text{cbc}},k_{\text{ofb}},m):} & \quad\text{return}\ m\\
\quad c:=\text{CBC.Enc}(k_{\text{cbc},m}) & \text{else return \textcolor{brown}{\texttt{err}}}\\
\quad c':=\text{OFB.Enc}(k_{\text{ofb},m})\\
\quad \text{return}\ (c,c')\\\hline
\end{array}
$$

Show that $\Sigma^{\prime}$ does not have CCA security. Describe a distinguisher and compute its distinguishing advantage.

9.14. This problem is a generalization of the previous one. Let $\Sigma_{1}$ and $\Sigma_{2}$ be two (possibly different) encryption schemes with the same message space $\mathcal{M}$. Below we define an encryption scheme $\Sigma^{\prime}$

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\Sigma'.\text{KeyGen}:} &  \underline{\Sigma'.\text{Enc}((k_1,k_2),m):} &  \underline{\Sigma'.\text{Dec}((k_1,k_2),(c_1,c_2)):}\\
\quad k_1\leftarrow \Sigma_1.\text{KeyGen} & \quad c_1:=\Sigma_1.\text{Enc}(k,m)& \quad m_1:=\Sigma_1.\text{Dec}(k_1,c_1)\\
\quad k_2\leftarrow \Sigma_2.\text{KeyGen} & \quad c_2:=\Sigma_2.\text{Enc}(k_2,m) & \quad m_2:=\Sigma_2.\text{Dec}(k_2,c_2)\\
\quad \text{return}\ (k_1,k_2)& \quad \text{return}\ (c_1,c_2) &\quad \text{if}\ m_1=m_2:\\
& &  \quad \text{return}\ m_1\\
& & \quad \text{else return}\ \textcolor{brown}{\texttt{err}}\\\hline
\end{array}
$$

Show that $\Sigma^{\prime}$ does not have CCA security, even if both $\Sigma_{1}$ and $\Sigma_{2}$ have $\mathrm{CCA}$ (yes, CCA) security. Describe a distinguisher and compute its distinguishing advantage.

9.15. Consider any padding scheme consisting of subroutines PAD (which adds valid padding to its argument) and valitpead (which checks its argument for valid padding and returns true/false). Assume that VALIDPAD(PAD($x$))=true for all strings $x$.

Show that if an encryption scheme $\Sigma$ has CCA security, then the following two libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{pad}-L}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
\underline{\text{EAVESDROP}(m_L,m_R\in\Sigma.\mathcal{M})}:\\
\quad \text{if $|m_L|\neq |m_R|$ return \textcolor{brown}{\texttt{err}}}\\
\quad \text{return $\Sigma$.Enc}(k,\text{PAD}(m_L))\\\\
\underline{\text{PADDINGORACLE}(c\in\Sigma.C)}:\\
\text{return VALIDPAD}(\Sigma.\text{Dec}(k,c))\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{pad}-R}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
\underline{\text{EAVESDROP}(m_L,m_R\in\Sigma.\mathcal{M})}:\\
\quad \text{if $|m_L|\neq |m_R|$ return \textcolor{brown}{\texttt{err}}}\\
\quad \text{return $\Sigma$.Enc}(k,\text{PAD}(m_L))\\\\
\underline{\text{PADDINGORACLE}(c\in\Sigma.C)}:\\
\text{return VALIDPAD}(\Sigma.\text{Dec}(k,c))\\\hline
\end{array}
$$

That is, a CCA-secure encryption scheme hides underlying plaintexts in the presence of padding-oracle attacks.

Note: The distinguisher can even send a ciphertext $c$ obtained from EAVESDROP as an argument to PADDINGORACLE. Your proof should somehow account for this when reducing to the CCA security of $\Sigma$.

9.16. Show that an encryption scheme $\Sigma$ has CCA$\varPhi$ security if and only if the following two libraries are indistinguishable:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{left}}^{\Sigma}\\\hline
k\leftarrow \Sigma.\text{KeyGen}\\
\underline{\text{EAVESDROP}(m\in\Sigma.\mathcal{M})}:\\
\quad \text{return $\Sigma$.Enc}(k,m)\\\\
\underline{\text{DECRYPT}(c\in\Sigma.C)}:\\
\quad\text{return}(\Sigma.\text{Dec}(k,c))\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{right}}^{\Sigma}\\\hline
D:=\text{empty assoc. array}\\\\
\underline{\text{EAVESDROP}(m\in\Sigma.\mathcal{M})}:\\
\quad c\leftarrow\Sigma.C(|m|)\\
\quad D[c]:=m\\
\quad \text{return}\ c\\\\
\underline{\text{DECRYPT}(c\in\Sigma.C)}:\\
\quad\text{if $D[c]$ exists: return $D[c]$}\\
\quad \text{else: return}(\Sigma.\text{Dec}(k,c))\\\hline
\end{array}
$$

Note: In $\mathcal{L}_{\text {left }}$, the adversary can obtain the decryption of any ciphertext via DECRYPT. In $\mathcal{L}_{\text {right }}$, the DECRYPT subroutine is "patched" (via $D$ ) to give reasonable answers to ciphertexts generated in EAVESDROP.

# 10. Message Authentication Codes

The challenge of CCA-secure encryption is dealing with ciphertexts that were generated by an adversary. Imagine there was a way to “certify” that a ciphertext was not adversarially generated — *i.e.,* it was generated by someone who knows the secret key. We could include such a certification in the ciphertext, and the Dec algorithm could raise an error if it asked to decrypt something with invalid certification.

What we are asking for is not to **hide** the ciphertext but to **authenticate** it: to ensure that it was generated by someone who knows the secret key. The tool for the job is called a **message authentication code**. One of the most important applications of a message authentication code is to transform a CPA-secure encryption scheme into a CCA-secure one.

As you read this chapter, keep in mind that privacy and authentication are indeed different properties. It is possible to have one or the other or indeed both simultaneously. But one does not imply the other, and it is crucial to think about them separately.

## 10.1 Definition

AMAC is like a signature that can be added to a piece of data, which certifies that someone who knows the secret key attests to this particular data. In cryptography, the term “signature” means something specific, and slightly different than a MAC. Instead of calling the output of a MAC algorithm a signature, we call it a “tag” (or, confusingly, just “a MAC”).

Our security requirement for a MAC scheme is that only someone with the secret key can generate a valid tag. To check whether a tag is valid, you just recompute the tag for a given message and see whether it matches the claimed tag. This implies that both generating and verifying a MAC tag requires the secret key.

**Definition 10.1 (MAC scheme)**

*A **message authentication code (MAC) scheme** for message space $\mathcal{M}$ consists of the following algorithms:*

 - KeyGen: *samples a key.*
 - MAC: *takes a key k and message $m \in \mathcal{M}$ as input, and outputs a **tag** t . The MAC algorithm is deterministic.*


### How to Think About Authenticity Properties

Every security definition we’ve seen so far is about hiding information, so how do we make a formal definition about authenticity?

Before we see the security definition for MACs, let’s start with a much simpler (potentially obvious?) statement: “an adversary should not be able to guess a uniformly chosen $\lambda$-bit value.” We can formalize this idea with the following two libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad\mathcal{L}_{\text{left}} \\ \hline
r \leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda} \\
\underline{\text{GUESS}(g):} \\
\quad \text{return } g \overset{?}{=} r \\ \hline
\end{array}
\qquad
\begin{array}{|l|} \hline
\qquad\mathcal{L}_{\text{right}} \\ \hline
\underline{\text{GUESS}(g):} \\
\quad \text{return } \texttt{fasle} \\ \hline
\end{array}
$$

The left library allows the calling program to attempt to guess a uniformly chosen “target” string. The right library doesn’t even bother to verify the calling program’s guess — in fact it doesn’t even bother to sample a random target string!

The GUESS subroutines of these libraries give the same output on nearly all inputs. There is only one input $r$ on which they disagree. If a calling program can manage to find the value $r$, then it can easily distinguish the libraries. Therefore, by saying that these libraries are indistinguishable, we are really saying that **it’s hard for an adversary to find/generate this special value!** That’s the kind of property we want to express.

Indeed, in this case, an adversary who makes $q$ queries to the guess subroutine achieves an advantage of at most $q/2^{\lambda}$. For polynomial-time adversaries, this is a negligible advantage (since $q$ is a polynomial function of $\lambda$).

More generally, suppose we have two libraries, and a subroutine in one library checks some condition (and could return either $\texttt{true}$ or $\texttt{false}$), while in the other library this subroutine always returns $\texttt{false}$. If the two libraries are indistinguishable, the calling program can’t tell whether the library is actually checking the condition or always saying $\texttt{false}$. This means it must be very hard to find an input for which the “correct” answer is $\texttt{true}$.

### The MAC Security Definition

We want to say that only someone who knows the secret key can come up with valid MAC tags. In other words, the adversary cannot come up with valid MAC tags.

Actually, that property is not quite enough to be useful. A more useful property is: *even if the adversary knows valid MAC tags* corresponding to various messages, she cannot produce a valid MAC tag for a *different* message. We call it a **forgery** if the adversary can produce a “new” valid MAC tag.

To translate this security property to a formal definition, we define two libraries that allow the adversary to request MAC tags on chosen messages. The libraries also provide a mechanism to let the adversary *check* whether it has successfully found a forgery (since there is no way of checking this property without the secret key). One library will actually perform the check, and the other library will simply assume that forgeries are impossible.
The two libraries are different only in how they behave when the adversary calls this verification subroutine on a forgery. By demanding that the two libraries be indistinguishable, we are actually demanding that it is difficult for the calling program to generate a forgery.

**Definition 10.2 (MAC security)**

*Let $\Sigma$ be a MAC scheme. We say that $\Sigma$ is a* **secure MAC** *if $\mathcal{L}^{\Sigma}_{\text{mac-real}} \approx \mathcal{L}^{\Sigma}_{\text{mac-fake}}$, where:*

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad\qquad\mathcal{L}^{\Sigma}_{\text{mac-real}} \\ \hline
k \leftarrow \Sigma.\text{KeyGen} \\
\underline{\text{GETTAG}(m \in \Sigma.\mathcal{M}):} \\
\quad \text{return } \Sigma.\text{MAC}(k,m) \\ 
\underline{\text{CHECKTAG}(m \in \Sigma.\mathcal{M},t):} \\
\quad \text{return } t \overset{?}{=} \Sigma.\text{MAC}(k,m) \\ \hline
\end{array}
\qquad
\begin{array}{|l|} \hline
\qquad\qquad\mathcal{L}^{\Sigma}_{\text{mac-fake}} \\ \hline
k \leftarrow \Sigma.\text{KeyGen} \\
\mathcal{T} := \empty \\
\underline{\text{GETTAG}(m \in \Sigma.\mathcal{M}):} \\
\quad t := \Sigma.\text{MAC}(k,m) \\ 
\quad \mathcal{T} := \mathcal{T} \cup \{(m,t)\}\\
\quad \text{return } t \\
\underline{\text{CHECKTAG}(m \in \Sigma.\mathcal{M},t):} \\
\quad \text{return } (m,t) \overset{?}{\in} \mathcal{T} \\ \hline
\end{array}
$$

Discussion:

 - The adversary can see valid tags of chosen messages, from the GETTAG subroutine. However, these tags shouldn’t count as a successful forgery. The way this is enforced is in the CHECKTAG subroutine of $\mathcal{L}_{\text{mac-fake}}$ — instead of always responding $\texttt{false}$, it gives the correct answer ($\texttt{true}$) for any tags generated by GETTAG.
 - In order for the two libraries to behave differently, the adversary must call CHECKTAG on input $(m, t)$ such that $m$ was never used as an argument to GETTAG (so that $\mathcal{L}_{\text{mac-fake}}$ responds $\texttt{false}$) but where the tag is actually correct (so that $\mathcal{L}_{\text{mac-real}}$ responds $\texttt{true}$).
 - The adversary can successfully distinguish if it finds *any* forgery — a valid MAC tag of *any* “fresh” message. The definition doesn’t care whether it’s the tag of any particular *meaningful* message.


### MAC Applications
Although MACs are less embedded in public awareness than encryption, they are extremely useful. A frequent application of MACs is to store some information in an untrusted place, where we don’t intend to *hide* the data, only ensure that the data is not changed.

 - A **browser cookie** is a small piece of data that a webserver stores in a user’s web browser. The browser presents the cookie data to the server upon each request.
Imagine a webserver that stores a cookie when a user logs in, containing that user’s account name. What stops an attacker from modifying their cookie to contain a different user’s account name? Adding a MAC tag of the cookie data (using a key known only to the server) ensures that such an attack will not succeed. The server can trust any cookie data whose MAC tag is correct.
 - When Alice initiates a network connection to Bob, they must perform a **TCP handshake:**


 1. Alice sends a special SYN packet containing her initial sequence number A. In TCP, all packets from Alice to Bob include a sequence number, which helps the parties detect when packets are missing or out of order. It is important that the initial sequence number be random, to prevent other parties from injecting false packets.
2. Bob sends a special SYN+ACK packet containing $A+1$ (to acknowledge Alice’s $A$ value) and the initial sequence number $B$ for his packets.
3. Alice sends a special ACK packet containing $B + 1$, and then the connection is established.

When Bob is waiting for step 3, the connection is considered “half-open.” While waiting, Bob must remember $B$ so that he can compare to the $B + 1$ that Alice is supposed to send in her final ACK. Typically the operating system allocates only a very limited amount of resources for these half-open connections.

In the past, it was possible to perform a denial of service attack by starting a huge number of TCP connections with a server, but never sending the final ACK packet. The server’s queue for half-open connections fills up, which prevents other legitimate connections from starting.

A clever backwards-compatible solution to this problem is called **SYN cookies**. The idea is to let Bob choose his initial sequence number $B$ to be a MAC of the client’s IP address, port number, and some other values. Now there is nothing to store for half-open connections. When Alice sends the final ACK of the handshake, Bob can recompute the initial sequence number from his MAC key.

These are all cases where the person who *generates* the MAC is the same person who later *verifies* the MAC. You can think of this person as choosing not to store some information, but rather leaving the information with someone else as a “note to self.”

There are other useful settings where one party generates a MAC while the other verifies.

 - In **two-factor authentication**, a user logs into a service using *something they know (e.g.,* a password) and *something they have (e.g.,* a mobile phone). The most common two-factor authentication mechanism is called *timed one-time passwords (TOTP).* When you (as a user) enable two-factor authentication, you generate a secret key $k$ and store it both on your phone and with the service provider. When you wish to log in, you open a simple app on your phone which computes $p =$ MAC$(k,T)$, where $T$ is the current date $+$ time (usually rounded to the nearest 30 seconds). The value $p$ is the “timed one-time password.” You then log into the service using your usual (long-term) password and the one-time password $p$. The service provider has $k$ and also knows the current time, so can verify the MAC $p$.

From the service provider’s point of view, the only other place $k$ exists is in the phone of this particular user. Intuitively, the only way to generate a valid one-time password at time $T$ is to be in posession of this phone at time $T$ . Even if an attacker sees both your long-term and one-time password over your shoulder, this does not help him gain access to your account in the future (well, not after 30 seconds in the future).


## $\star$ 10.2 A PRF is a MAC

The definition of a PRF says (more or less) that even if you’ve seen the output of the PRF on several chosen inputs, all other outputs look independently & uniformly random. Furthermore, uniformly chosen values are hard to guess, as long as they are sufficiently long (e.g., $\lambda$ bits).

In other words, after seeing some outputs of a PRF, any other PRF output will be hard to guess. This is exactly the intuitive property we require from a MAC. And indeed, we will prove in this section that a PRF is a secure MAC. While the claim makes intuitive sense, proving it formally is a little tedious. This is due to the fact that that in the MAC security game, the adversary can make many verification queries CHECKTAG$(m, t)$ *before* asking to see the correct MAC of $m$. Dealing with this event is the source of all the technical
difficulty in the proof.

We start with a technical claim that captures the idea that “if you can blindly guess at uniformly chosen values and can also ask to see the values, then it is hard to guess a random value before you have seen it.”

**Claim 10.3**
*The following two libraries are indistinguishable:*

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad\qquad\qquad\mathcal{L}_{\text{guess-L}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{in}, g \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} ):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return } g \overset{?}{=} T[m] \\
\underline{\text{REVEAL}(m \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{in}):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return }  T[m] \\ \hline
\end{array}
\qquad
\begin{array}{|l|} \hline
\qquad\qquad\qquad\mathcal{L}_{\text{guess-R}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{in}, g \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} ):} \\
//\ returns\ false if\ T[m]\ undefined \\ \\
\quad \text{return } g \overset{?}{=} T[m] \\
\underline{\text{REVEAL}(m \in \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{in}):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return }  T[m] \\ \hline
\end{array}
$$

Both libraries maintain an associative array $T$ whose values are sampled uniformly the first time they are needed. Calling programs can try to guess these values via the GUESS subroutine, or simply learn them via reveal. Note that the calling program can call GUESS$(m, \cdot)$ both *before and after* calling REVEAL$(m)$.

Intuitively, since the values in $T$ are $\lambda$ bits long, it should be hard to guess $T[m]$ before calling REVEAL$(m)$. That is exactly what we formalize in $\mathcal{L}_{\text{guess-R}}$. In fact, this library doesn’t bother to even choose $T[m]$ until REVEAL$(m)$ is called. All calls to GUESS$(m, \cdot)$ made before the first call to REVEAL$(m)$ will return $\texttt{false}$.

**Proof** 
Let $q$ be the number of queries that the calling program makes to GUESS. We will show that the libraries are indistinguishable with a hybrid sequence of the form:

$$
\mathcal{L}_{\text {guess-L}} \equiv \mathcal{L}_{\text {hyb-} 0} \approx \mathcal{L}_{\text {hyb-} 1} \approx \cdots \approx \mathcal{L}_{\text {hyb-} q} \equiv \mathcal{L}_{\text {guess-R}}
$$

The $h$th hybrid library in the sequence is defined as:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad\qquad\qquad\mathcal{L}_{\text{hyp-}h} \\ \hline
count := 0 \\
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m , g):} \\
\quad count := count + 1 \\
\quad \text{if } T[m] \text{ undefined and } count > h : \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return } g \overset{?}{=} T[m] \\
\quad //\ returns\ false\ if\ T[m]\ undefined \\
\underline{\text{REVEAL}(m):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return }  T[m] \\ \hline
\end{array}
$$

This hybrid library behaves like $\mathcal{L}_{\text {guess-R }}$ for the first $h$ queries to GUESS, in the sense that it will always just return false when $T[m]$ is undefined. After $h$ queries, it will behave like $\mathcal{L}_{\text {guess-L }}$ by actually sampling $T[m]$ in these cases.

In $\mathcal{L}_{\text {hyb-} 0}$, the clause "$count >0$ " is always true so this clause can be removed from the if-condition. This modification results in $\mathcal{L}_{\text {guess-L }},$ so we have $\mathcal{L}_{\text {guess-L}} \equiv \mathcal{L}_{\text {hyb-} 0}$.

In $\mathcal{L}_{\text {hyb-} q}$, the clause "$count >q$ "in the if-statement is always false since the calling program makes only $q$ queries. Removing the unreachable if-statement it results in $\mathcal{L}_{\text {guess-R }},$ so we have $\mathcal{L}_{\text {guess-R}} \equiv \mathcal{L}_{\text {hyb- } q}$ 

It remains to show that $\mathcal{L}_{\text {hyb- } h} \approx \mathcal{L}_{\text {hyb- }(h+1)}$ for all $h$. We can do so by rewriting these two libraries as follows:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad\qquad\qquad\mathcal{L}_{\text{hyp-}h} \\ \hline
count := 0 \\
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m , g):} \\
\quad count := count + 1 \\
\quad \text{if } T[m] \text{ undefined and } count > h : \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\qquad  \text{if } g = T[m] \text{ and } count = h + 1: \\
\qquad\quad \text{bad} := 1 \\
\quad \text{return } g \overset{?}{=} T[m] \\
\quad //\ returns\ false\ if\ T[m]\ undefined \\
\underline{\text{REVEAL}(m):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return }  T[m] \\ \hline
\end{array}
\qquad
\begin{array}{|l|} \hline
\qquad\qquad\qquad\mathcal{L}_{\text{hyp-}(h+1)} \\ \hline
count := 0 \\
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m , g):} \\
\quad count := count + 1 \\
\quad \text{if } T[m] \text{ undefined and } count > h : \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\qquad  \text{if } g = T[m] \text{ and } count = h + 1: \\
\qquad\quad \text{bad} := 1; \text{ return } \texttt{false} \\
\quad \text{return } g \overset{?}{=} T[m] \\
\quad //\ returns\ false\ if\ T[m]\ undefined \\
\underline{\text{REVEAL}(m):} \\
\quad \text{if } T[m] \text{ undefined:} \\ 
\qquad T[m] \leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} \\
\quad \text{return }  T[m] \\ \hline
\end{array}
$$

The library on the left is equivalent to $\mathcal{L}_{\text{hyb}-h}$ since the only change is the highlighted lines, which don’t actually affect anything. In the library on the right, if $T[m]$ is undefined during the first $h + 1$ calls to GUESS, the subroutine will return false (either by avoiding the if-statement altogether or by triggering the highlighted lines). This matches the behavior of $\mathcal{L}_{\text{hyb-}(h + 1)}$, except that the library shown above samples the value $T[m]$ which in $\mathcal{L}_{\text{hyb-}(h + 1)}$ would not be sampled until the next call of the form GUESS$(m, \cdot)$ or REVEAL$(m)$. But the method of sampling is the same, only the timing is different. This difference has no effect on the calling program.

So the two libraries above are indeed equivalent to $\mathcal{L}_{\text{hyb-}h}$ and $\mathcal{L}_{\text{hyb-}(h + 1)}$. They differ only in code that is reachable when bad $= 1$. From Lemma 4.8, we know that these two libraries are indistinguishable if Pr[bad $= 1]$ is negligible. In these libraries there is only one chance to set bad $= 1$, and that is by guessing/predicting uniform $T[m]$ on the $(h+1)$th call to guess. This happens with probability $1/2^{\lambda}$, which is indeed negligible.

This shows that $\mathcal{L}_{\text{hyb-}h} \approx \mathcal{L}_{\text{hyb-}(h + 1)}$, and completes the proof.

We now return to the problem of proving that a PRF is a MAC.

**Claim 10.4** 
*Let $F$ be a secure PRF with input length in and output length out $= \lambda$. Then the scheme MAC$(k,m) = F (k,m)$ is a secure MAC for message space $\{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{in}$.*

**Proof**
We show that $\mathcal{L}_{\text {mac-real }}^{F} \approx \mathcal{L}_{\text {mac-fake }}^{F},$ using a standard sequence of hybrids.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{mac-real}} \\ \hline
k \leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda} \\
\underline{\text{GETTAG}(m):} \\
\quad \text{return } F(k,m) \\ 
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return } t \overset{?}{=} F(k,m) \\ \hline
\end{array}
$$

The starting point is the $\mathcal{L}_{\text{mac-real}}$ library, with the details of this MAC scheme filled in.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{GETTAG}(m):} \\
\quad \text{return LOOKUP} (m) \\ 
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return } t \overset{?}{=} \text{LOOKUP}(m) \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{prf-real}} \\ \hline
k \leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{\lambda} \\
\underline{\text{LOOKUP}(x):} \\
\quad \text{return } F(k,x) \\ \hline
\end{array}
$$

We have factored out the PRF operations in terms of the library $\mathcal{L}_{\text{prf-real}}$ from the PRF security definition.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{GETTAG}(m):} \\
\quad \text{return LOOKUP} (m) \\ 
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return } t \overset{?}{=} \text{LOOKUP}(m) \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{prf-rand}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{LOOKUP}(x):} \\
\quad \text{if } T[x] \text{ undefined:} \\
\qquad T[x]\leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^{out} \\
\quad \text{return } T(x) \\ \hline
\end{array}
$$

We have applied the PRF security of $F$ and replaced $\mathcal{L}_{\text{prf-real}}$ with $\mathcal{L}_{\text{prf-rand}}$.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{GETTAG}(m):} \\
\quad \text{return REVEAL} (m) \\ 
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  \text{GUESS}(m,t) \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{guess-L}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m,g):} \\
\quad \text{if } T[m] \text{ undefined:} \\
\qquad T[m]\leftarrow \{\textcolor{brown}{0}, \textcolor{brown}{1}\}^\lambda \\
\quad \text{return } g\stackrel{?}{=}T[m]\\ 
\underline{\text{REVEAL}(m):}\\
\quad \text{if}\ T[m]\ undefined:\\
\qquad T[m]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ T[m]\\\hline
\end{array}
$$

We can express the previous hybrid in terms of the $\mathcal{L}^{F}_{\text{guess-L}}$ library from Claim 10.3. The change has no effect on the calling program.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{GETTAG}(m):} \\
\quad \text{return REVEAL} (m) \\ 
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  \text{GUESS}(m,t) \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{guess-R}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m,g):} \\
\quad \text{return } g\stackrel{?}{=}T[m]\\ 
\underline{\text{REVEAL}(m):}\\
\quad \text{if}\ T[m]\ undefined:\\
\qquad T[m]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ T[m]\\\hline
\end{array}
$$

We have applied Claim 10.3 to replace $\mathcal{L}^{F}_{\text{guess-L}}$ with $\mathcal{L}^{F}_{\text{guess-R}}$. This involves simply removing the if-statement from guess. As a result, GUESS $(m,g)$ will return false if $T[m]$ is undefined.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\mathcal{T}:=\emptyset\\
\underline{\text{GETTAG}(m):} \\
\quad t:=\text{REVEAL} (m) \\ 
\quad \mathcal{T}:=\mathcal{T}\cup \{(m,t)\}\\
\quad \text{return}\ t\\
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  \text{GUESS}(m,t) \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{guess-R}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m,g):} \\
\quad \text{return } g\stackrel{?}{=}T[m]\\ 
\underline{\text{REVEAL}(m):}\\
\quad \text{if}\ T[m]\ undefined:\\
\qquad T[m]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ T[m]\\\hline
\end{array}
$$

Extra bookkeeping information is added, but not used anywhere. There is no effect on the calling program.

Consider the hybrid experiment above, and suppose the calling program makes a call to CHECKTAG $(m, t)$. There are two cases:
- Case 1 : there was a previous call to GETTAG $(m)$. In this case, the value $T[m]$ is defined in $\mathcal{L}_{\text {guess-R }}$ and $(m, T[m])$ already exists in $\mathcal{T}$. In this case, the result of $\operatorname{GUESS}(m, t)$ (and hence, of $\operatorname{cHECKTAG}(m, t))$ will be $t \stackrel{?}{=} T[m]$.

- Case 2: there was no previous call to GETTAG $(m)$. Then there is no value of the form $(m,\star)$ in $\mathcal{T}$.  Furthermore, $T[m]$ is undefined in $\mathcal{L}^{F}_{\text{guess-R}}$. The call to guess $(m,t)$ will return false, and so will the call to CHECKTAG $(m,t)$ that we consider.
- 
In both cases, the result of CHECKTAG $(m,t)$ is true if and only if $(m,t)\in\mathcal{T}$.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\mathcal{T}:=\emptyset\\
\underline{\text{GETTAG}(m):} \\
\quad t:=\text{REVEAL} (m) \\ 
\quad \mathcal{T}:=\mathcal{T}\cup \{(m,t)\}\\
\quad \text{return}\ t\\
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  (m,t)\stackrel{?}{\in}\mathcal{T} \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{guess-R}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{GUESS}(m,g):} \\
\quad \text{return } g\stackrel{?}{=}T[m]\\ 
\underline{\text{REVEAL}(m):}\\
\quad \text{if}\ T[m]\ undefined:\\
\qquad T[m]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\quad \text{return}\ T[m]\\\hline
\end{array}
$$

We have modified checktag according to the discussion above.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\mathcal{T}:=\emptyset\\
\underline{\text{GETTAG}(m):} \\
\quad t:=\text{LOOKUP} (m) \\ 
\quad \mathcal{T}:=\mathcal{T}\cup \{(m,t)\}\\
\quad \text{return}\ t\\
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  (m,t)\stackrel{?}{\in}\mathcal{T} \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{prf-rand}} \\ \hline
T := \text{empty assoc. array} \\
\underline{\text{LOOKUP}(x):} \\
\quad \text{if}\ T[m]\ undefined:\\
\qquad T[m]\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{out}\\
\quad \text{return}\ T[x]\\\hline
\end{array}
$$

In the previous hybrid, the guess subroutine is never called. Removing that unused subroutine and renaming reveal to lookup results in the $\mathcal{L}^{F}_{\text{prf-ideal}}$ library from the PRF security definition.

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\mathcal{T}:=\emptyset\\
\underline{\text{GETTAG}(m):} \\
\quad t:=\text{LOOKUP} (m) \\ 
\quad \mathcal{T}:=\mathcal{T}\cup \{(m,t)\}\\
\quad \text{return}\ t\\
\underline{\text{CHECKTAG}(m,t):} \\
\quad \text{return }  (m,t)\stackrel{?}{\in}\mathcal{T} \\ \hline
\end{array}
\diamond
\begin{array}{|l|} \hline
\quad\qquad\mathcal{L}^{F}_{\text{prf-real}} \\ \hline
k\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^\lambda\\
\underline{\text{LOOKUP}(x):} \\
\quad \text{return}\ F(k,x)\\\hline
\end{array}
$$

We have applied the PRF security of $F$ again, replacing $\mathcal{L}^{F}_{\text{prf-ideal}}$ with  $\mathcal{L}^{F}_{\text{prf-real}}$.

Inlining $\mathcal{L}_{\text {prf-real }}$ in the final hybrid, we see that the result is exactly $\mathcal{L}_{\text {mac-fake }}^{F} .$ Hence, we have shown that $\mathcal{L}_{\text {mac-real }}^{F} \approx \mathcal{L}_{\text {mac-fake }}^{F}$, which completes the proof.

### Discussion
**If PRFs are MACs, why do we even need a definition for MACs?** The simplest answer to this question is that the concepts of PRF and MAC are indeed different:
- Not every PRF is a MAC. Only sufficiently long random values are hard to guess, so only PRFs with long outputs (out $\geqslant \lambda)$ are MACs. It is perfectly reasonable to consider a PRF with short outputs.
- Not every MAC is a PRF. Just like not every encryption scheme has pseudorandom ciphertexts, not every MAC scheme has pseudorandom tags. Imagine taking a secure MAC scheme and modifying it as $\operatorname{MAC}^{\prime}(k, m)=\operatorname{MAC}(k, m) \| \theta^{\lambda}$. Adding Os to every tag prevents the tags from looking pseudorandom, but does not make the tags any easier to guess. Something doesn't have to be uniformly random in order to be hard to guess.

It is true that in the vast majority of cases we will encounter MAC schemes with random tags, and PRFs with long outputs (out $\geqslant \lambda)$. But it is good practice to know whether you really need something that is pseudorandom or hard to guess.

## 10.3 MACs for Long Messages
Using a PRF as a MAC is useful only for short, fixed-length messages, since most PRFs that exist in practice are limited to such inputs. Can we somehow extend a PRF to construct a MAC scheme for long messages, similar to how we used block cipher modes to construct encryption for long messages?
### How NOT to do it
To understand the challenges of constructing a MAC for long messages, we first explore some approaches that don't work. The things that can go wrong in an insecure MAC are quite different in character to the things that can go wrong in a block cipher mode, so pay attention closely!

Let $F$ be a PRF with *in* = *out* = $\lambda$. Below is a MAC approach for messages of length $2\lambda$. It is inspired by ECB mode, so you know it’s going to be a disaster:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{ECBMAC}(k,m_1\|m_2):} \\
\quad t_1:=F(k,m_1) \\ 
\quad t_2:=F(k,m_2) \\ 
\quad \text{return}\ t_1\|t_2\\\hline
\end{array}
$$

One problem with this approach is that, although the PRF authenticates each block $m_1,m_2$ individually, it does nothing to authenticate that $m_1$ is the first block but $m_2$ is the second one. Translating this observation into an attack, an adversary can ask for the MAC tag of $m_1\|m_2$ and then predict/forge the tag for $m_1\|m_2:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\qquad \qquad \qquad \quad\mathcal{A}:\\\hline
t_1\|t_2:=\text{GETTAG}(\textcolor{brown}{0}^\lambda\|\textcolor{brown}{1}^\lambda)\\
\text{return CHECKTAG}(\textcolor{brown}{0}^\lambda\|\textcolor{brown}{1}^\lambda,t_2\|t_1)\\\hline
\end{array}
$$

When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{mac-real}}$, it always return true, since we can tell that $t_2\|t_1$ is indeed the valid tag for $\textcolor{brown}{1}^\lambda\|\textcolor{brown}{0}^\lambda$. When $\mathcal{A}$ is linked to $\mathcal{L}_{\text{mac-fake}}$, it always return false, since the calling program never called GETTAG with input $\textcolor{brown}{1}^\lambda\|\textcolor{brown}{0}^\lambda$. Hence, $\mathcal{A}$ distinguishes the libraries with advantage 1.

This silly MAC construction treats both $m_1$ and $m_2$ identically, and an obvious way to try to fix the problem is to treat the different blocks differently somehow:

**Example**
Let $F$ be a PRF with in = $\lambda + 1$ and out = $\lambda$. Below is another MAC approach for messages of length $2\lambda$:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\underline{\text{ECB++MAC}(k,m_1\|m_2):}\\
\quad t_1:=F(k,\textcolor{brown}{0}\|m_1)\\
\quad t_2:=F(k,\textcolor{brown}{1}\|m_2)\\
\quad \text{return}\ t_1\|t_2\\\hline
\end{array}
$$

This MAC construction does better, as it treats the two message blocks $m_1$ and $m_2$ differently. Certainly the previous attack of swapping the order of $m_1$ and $m_2$ doesn’t work anymore. (Can you see why?)

The construction authenticates (in some sense) the fact that $m_1$ is the first message block, and $m_2$ is the second block. However, this construction doesn’t authenticate **the fact that this particular $m_1$ and $m_2$ belong together**. More concretely, we can “mix and match” blocks of the tag corresponding to different messages:

$$
\def\arraystretch{1.5}
\begin{array}{|l|} \hline
\mathcal{A}:\\\hline
\quad t_1\|t_2:=\text{GETTAG}(\textcolor{brown}{0}^{2\lambda})\\
\quad t'_1\|t'_2:=\text{GETTAG}(\textcolor{brown}{1}^{2\lambda})\\
\quad \text{return CHECKTAG}(\textcolor{brown}{0}^{\lambda}\|\textcolor{brown}{1}^{\lambda},t_1\|t'_2)\\\hline
\end{array}
$$
In this attack, we combine the $t_1$ block from the First tag and the $t_2$ block from the second tag.

We are starting to see the challenges involved in constructing a MAC scheme for long messages. A secure MAC should authenticate each message block, the order of the message blocks, and the fact that these *particular message* blocks are appearing in a single message. In short, it must authenticate the entirety of the message.

Think about how authentication is significantly different than privacy/hiding in this respect. At least for CPA security, we can hide an entire plaintext by hiding each individual piece of the plaintext separately (encrypting it with a CPA-secure encryption). Authentication is fundamentally different.

### How to do it: CBC-MAC
We have seen some insecure ways to construct a MAC for longer messages. Now let's see a secure way. A common approach to constructing a MAC for long messages involves the CBC block cipher mode.

**Construction 10.5 (CBC-MAC)**
Let $F$ be a PRF with *in* $=$ *out* $=\lambda .$ CBC-MAC refers to the following MAC scheme:

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

Unlike CBC encryption, CBC-MAC uses no initialization vector (or, you can think of it as using the all-zeroes IV), and it outputs only the last block.

**Theorem 10.6**

If $F$ is a secure PRF with in $=$ out $=\lambda,$ then for any fixed $\ell, C B C-M A C$ is a secure MAC when used with message space $\mathcal{M}=\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda \ell}$

Pay close attention to the security statement. It says that if you only ever authenticate 4-block messages, CBC-MAC is secure. If you only ever authenticate 24 -block messages, CBC-MAC is secure. However, if you want to authenticate both 4 -block and 24 -block messages (i.e., under the same key), then CBC-MAC is not secure. In particular, seeing the CBC-MAC of several 4-block messages allows an attacker to generate a forgery of a 24-block message. The exercises explore this property.

### More Robust CBC-MAC
If $\mathrm{CBC}-\mathrm{MAC}$ is so fragile, is there a way to extend it to work for messages of mixed lengths? One approach is called $\mathrm{ECBC}-\mathrm{MAC},$ and is shown below. It works by treating the last block differently - specifically, it uses an independent PRF key for the last block in the CBC chain.

**Construction 10.7 (ECBC-MAC)**
Let $F$ be a PRF with in $=$ out $=\lambda .$ ECBC-MAC refers to the following scheme:

$$
\textcolor{red}{{\text{Image screenshot here}}}
$$

**Theorem 10.8**
If $F$ is a secure PRF with *in* = *out* = $\lambda$, then ECBC-MAC is a secure MAC for message space $\mathcal{M}=(\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda})^*$.

In other words, ECBC-MAC is safe to use with messages of any length (that is a multiple of the block length).

To extend ECBC-MAC to messages of any length (not necessarily a multiple of the block length), one can use a padding scheme as in the case of encryption.

## 10.4 Encrypt-Then-MAC
Our motivation for studying MACs is that they seem useful in constructing a CCA-secure encryption scheme. The idea is to add a MAC to a CPA-secure encryption scheme. The decryption algorithm can raise an error if the MAC is invalid, thereby ensuring that adversarially-generated (or adversarially-modified) ciphertexts are not accepted. There are several natural ways to combine a MAC and encryption scheme, but not all are secure! (See the exercises.) The safest way is known as encrypt-then-MAC:

**Construction 10.9 (Enc-then-MAC)**
Let $E$ denote an encryption scheme, and $M$ denote a MAC scheme where $E . C \subseteq M . \mathcal{M}$ (i.e., the MAC scheme is capable of generating MACs of ciphertexts in the E scheme). Then let EtM denote the **encrypt-then-MAC** construction given below:

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
&\underline{\text{Enc}((k_e,k_m),m):}\\
\mathcal{K}=E.\mathcal{K}\times M.\mathcal{K} & \quad c:=\text{E.Enc}(k_e,m)\\
\mathcal{M}=E.\mathcal{M} & \quad t:=M.\text{MAC}(k_m,c)\\
C=E.C\times M.\mathcal{T} & \quad \text{return}\ (c,t)\\
\underline{\text{KeyGen:}} &\underline{\text{Dec}((k_e,k_m),(c,t)):}\\
k_e\leftarrow \text{E.KeyGen} & \quad \text{if}\ t\neq M.\text{MAC}(k_m,c):\\
k_m\leftarrow M.\text{KeyGen} & \qquad \text{return \textcolor{brown}{\texttt{err}}}\\
\text{return}\ (k_e,k_m) & \quad \text{return}\ E.\text{Dec}(k_e,c)\\\hline
\end{array}
$$

Importantly, the scheme computes a MAC of the CPA ciphertext, and not of the plaintext! The result is a CCA-secure encryption scheme:

**Claim 10.10**
If E has CPA security and M is a secure MAC, then EtM (Construction 10.9) has CCA security.

**Proof**
As usual, we prove the claim with a sequence of hybrid libraries:

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{cca-L}}^{EtM}\\\hline
k_e\leftarrow E.\text{KeyGen}\\
k_m\leftarrow M.\text{KeyGen}\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=E.\text{Enc}(k_e,m_L)\\
\quad t\leftarrow M.\text{MAC}(k_m,c)\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\ \text{return null}\\
\quad \text{if}\ t\neq M.\text{MAC}(k_m,c):\\
\qquad \text{return \textcolor{brown}{err}}\\
\quad \text{return E.Dec}(k_e,c)\\\hline
\end{array}
$$

The starting point is $\mathcal{L}_{\text{cca-L}}^{EtM}$, shown here with the details of the encrypt-then-MAC construction highlighted. Our goal is to eventually swap $m_L$ with $m_R$. But the CPA security of $E$ should allow us to do just that, so what’s the catch?

To apply the CPA-security of $E$, we must factor out the relevant call to $E.$Enc in terms of the CPA library $\mathcal{L}_{\text{cpa-L}}^{E}$. This means that ke becomes private to the $\mathcal{L}_{\text{cpa-L}}^{E}$ library. But ke is also used in the last line of the library as E.Dec$(k_e,c)$. The CPA security library for E provides no way to carry out such E:Dec statements!

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k_e\leftarrow E.\text{KeyGen}\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=E.\text{Enc}(k_e,m_L)\\
\quad t:=\text{GETTAG}(c)\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\\
\qquad \text{return null}\\
\quad \text{if}\ t\text{not CHECKTAG}(c,t)\\
\qquad \text{return \textcolor{brown}{err}}\\
\quad \text{return E.Dec}(k_e,c)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{mac-real}}^M\\\hline
k_m\leftarrow E.\text{KeyGen}\\
\underline{\text{GETTAG}(c):}\\
\quad\text{return M.MAC}(k_m,c)\\
\underline{\text{CHECKTAG}(c,t):}\\
\quad \text{return}\ t\stackrel{?}{=}M.MAC(k_m,c)\\\hline
\end{array}
$$

The operations of the MAC scheme have been factored out in terms of $\mathcal{L}_{\text{mac-real}}^M$. Notably, in the DEC subroutine the condition “$t\neq M.MAC(k_M,c)$” has been replaced with “not CHECKTAG$(c,t)$”

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k_e\leftarrow E.\text{KeyGen}\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=E.\text{Enc}(k_e,m_L)\\
\quad t:=\text{GETTAG}(c)\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\\
\qquad \text{return null}\\
\quad \text{if}\ t\text{not CHECKTAG}(c,t)\\
\qquad \text{return \textcolor{brown}{err}}\\
\quad \text{return E.Dec}(k_e,c)\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad\mathcal{L}_{\text{mac-real}}^M\\\hline
k_m\leftarrow M.\text{KeyGen}\\
\mathcal{T}=\emptyset\\
\underline{\text{GETTAG}(c):}\\
\quad t:=M>MAC(k_m,c)\\
\quad \mathcal{T}:=\mathcal{T}\cup\{(c,t)\}\\
\quad\text{return}\ t\\
\underline{\text{CHECKTAG}(c,t):}\\
\quad \text{return}\ (c,t)\stackrel{?}{\in}\mathcal{T}\\\hline
\end{array}
$$

We have applied the security of the MAC scheme, and replaced $\mathcal{L}_{\text{mac-real}}$ with $\mathcal{L}_{\text{mac-fake}}$

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k_e\leftarrow E.\text{KeyGen}\\
k_m\leftarrow M.\text{KeyGen}\\
\mathcal{T}:=\emptyset\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=E.\text{Enc}(k_e,m_L)\\
\quad t:=M.MAC(k_m,c)\\
\quad\mathcal{T}:=\mathcal{T}\cup\{(c,t)\}\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\\
\qquad \text{return null}\\
\quad \text{if}\ (c,t)\notin \mathcal{T}:\\
\qquad \text{return \textcolor{brown}{err}}\\
\quad \text{return E.Dec}(k_e,c)\\\hline
\end{array}
$$

We have inlined the $\mathcal{L}_{\text {mac-fake }}$ library. This library keeps track of a set $\mathcal{S}$ of values for the purpose of the CCA interface, but also a set $\mathcal{T}$ of values for the purposes of the MAC. However, it is clear from the code of this library that $\mathcal{S}$ and $\mathcal{T}$ always have the same contents.

Therefore, the two conditions " $(c, t) \in \mathcal{S}$ " and " $(c, t) \notin \mathcal{T}$ " in the DEC subroutine are *exhaustive*! The final line of $\mathrm{DEC}$ is unreachable. This hybrid highlights the intuitive idea that an adversary can either query DEC with a ciphertext generated by EAVESDROP (the $(c, t) \in \mathcal{S}$ case $)-$ in which case the response is null $-$ or with a different ciphertext $-$ in which case the response will be brr since the MAC will not verify.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k_e\leftarrow E.\text{KeyGen}\\
k_m\leftarrow M.\text{KeyGen}\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=E.\text{Enc}(k_e,m_L)\\
\quad\mathcal{T}:=\mathcal{T}\cup\{(c,t)\}\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\\
\qquad \text{return null}\\
\quad \text{if}\ (c,t)\notin \mathcal{S}:\\
\qquad \text{return \textcolor{brown}{err}}\\
\quad \text{// unreachable}\\\hline
\end{array}
$$

The unreachable statement has been removed and the redundant variables $S$ and $\mathcal{T}$ have been unied. Note that this hybrid library never uses E.Dec, making it possible to express its use of the $E$encryption scheme in terms of $\mathcal{L}_{\text{cpa-L}}$.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
k_m\leftarrow M.\text{KeyGen}\\
S:=\emptyset\\
\underline{\text{EAVESDROP}(m_L,m_R):}\\
\quad \text{if}\ |m_L|\neq |m_R|\\
\qquad\text{return null}\\
\quad c:=\text{CPA.EAVESDROP}(m_L,m_R)\\
\quad t:=M.MAC(k_m,c)\\
\quad S:=S\cup\{(c,t)\}\\
\quad \text{return}\ (c,t)\\
\underline{\text{Dec}(c,t):}\\
\quad \text{if}\ (c,t)\in S\\
\qquad \text{return null}\\
\quad \text{if}\ (c,t)\notin \mathcal{S}:\\
\qquad \text{return \textcolor{brown}{err}}\\\hline
\end{array}
\quad
\begin{array}{|l|}\hline
\qquad \qquad \quad\mathcal{L}_{\text{cpa-L}}^E\\\hline
k_e\leftarrow E.\text{KeyGen}\\
\underline{\text{CPA.EAVESDROP}(m_L,m_R):}\\
\quad c:=E.\text{Enc}(k_e,m_L)
\quad \text{return}\ c\\\hline
\end{array}
$$

The statements involving the encryption scheme $E$ have been factored out in terms $\mathcal{L}_{\text{cpa-L}}$.

We have now reached the half-way point of the proof. The proof proceeds by replacing $\mathcal{L}_{\text {cpa-L }}$ with $\mathcal{L}_{\text {cpa-R }}$ (so that $m_{R}$ rather than $m_{L}$ is encrypted), applying the same modifications as before (but in reverse order), to finally arrive at $\mathcal{L}_{\text {cca-R. }}$ The repetitive details have been omitted, but we mention that when listing the same steps in reverse, the changes appear very bizarre indeed. For instance, we add an unreachable statement to the DEC subroutine; we create a redundant variable $\mathcal{T}$ whose contents are the same as $\mathcal{S}$; we mysteriously change one instance of $\mathcal{S}$ (the condition of the second if-statement in DEC) to refer to the other variable $\mathcal{T}$. Of course, all of this is so that we can factor out the statements referring to the MAC scheme (along with $\mathcal{T}$ ) in terms of $\mathcal{L}_{\text {mac-fake }}$ and finally  replace  $\mathcal{L}_{\text {mac-fake }}$ with $\mathcal{L}_{\text {mac-real }}$.

###  Exercises 
10.1. Consider the following MAC scheme, where F is a secure PRF with *in* = *out* = $\lambda$:

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\text{KeyGen:}} & \underline{\text{MAC}(k,m_1\|\cdots\|m_\ell):}//\text{each $m_i$ is $\lambda$ bits}\\
\quad k\leftarrow \{\textcolor{brown}{0}.\textcolor{brown}{1}\}^\lambda & \quad m^*:=\textcolor{brown}{0}^\lambda\\
\quad \text{return}\ k & \quad \text{for}\ i=1\ \text{to}\ \ell:\\
& \qquad m^*:=m^*\oplus m_i\\
& \quad \text{return}\ G(k,m^*)\\\hline
\end{array}
$$

Show that the scheme is not a secure MAC. Describe a distinguisher and compute its advantage.

10.2. Consider the following MAC scheme, where $F $is a secure PRF with *in* = *out* = $\lambda$:

$$
\def\arraystretch{1.5}
\begin{array}{|ll|}\hline
\underline{\text{KeyGen:}} & \underline{\text{MAC}(k,m_1\|\cdots\|m_\ell):}//\text{each $m_i$ is $\lambda$ bits}\\
\quad k\leftarrow \{\textcolor{brown}{0}.\textcolor{brown}{1}\}^\lambda & \quad t:=\textcolor{brown}{0}^\lambda\\
\quad \text{return}\ k & \quad \text{for}\ i=1\ \text{to}\ \ell:\\
& \qquad t:=t\oplus F(k,m_i)\\
& \quad \text{return}\ t\\\hline
\end{array}
$$

Show that the scheme is not a secure MAC. Describe a distinguisher and compute its advantage.
 
10.3. Suppose $\mathrm{MAC}$ is a secure $\mathrm{MAC}$ algorithm. Define a new algorithm $\mathrm{MAC}^{\prime}(k, m)=$ $\operatorname{MAC}(k, m) \| \operatorname{MAC}(k, m)$. Prove that $\mathrm{MAC}^{\prime}$ is also a secure MAC algorithm.

Note: MAC' cannot be a secure PRF. This shows that MAC security is different than PRF security.

10.4. Suppose $\mathrm{MAC}$ is a secure MAC scheme, whose outputs are $\ell$ bits long. Show that there is an efficient adversary that breaks MAC security (i.e., distinguishes the relevant libraries) with advantage $\Theta\left(1 / 2^{\ell}\right)$. This implies that MAC tags must be reasonably long in order to be secure.


10.5. Suppose we use $\mathrm{CBC}$ -MAC with message space $\mathcal{M}=\left(\{\textcolor{brown}{0}.\textcolor{brown}{1}\}^{\lambda}\right)^{*}$. In other words, a single MAC key will be used on messages of any length that is an exact multiple of the block length. Show that the result is not a secure MAC. Construct a distinguisher and compute its advantage.

>Hint: Request a MAC on two single-block messages, then use the result to forge the MAC of a two-block message.

$\star$ 10.6. Here is a different way to extend CBC-MAC for mixed-length messages, when the length
of each message is known in advance. Assume that $F$ is a secure PRF with *in* = *out* = $\lambda$.

$$
\def\arraystretch{1.5}
\begin{array}{|l|}\hline
\underline{\text{NEWMAC}^F(k,m_1\|\cdots\|m_\ell}\\
\quad k^*:=F(k,\ell)\\
\text{return CBCMAC}^F(k^*,m_1\|\cdots \|m_\ell\\\hline
\end{array}
$$

Prove that this scheme is a secure MAC for message space $\mathcal{M}=(\{\textcolor{brown}{0},\textcolor{brown}{1}^\lambda)^*$. You can use the fact that CBC-MAC is secure for messages of fixed-length.

10.7. Let E be a CPA-secure encryption scheme and $M$ be a secure MAC. Show that the following
encryption scheme (called encrypt & MAC) is not CCA-secure:

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\Sigma'.\text{KeyGen}:} &  \underline{\Sigma'.\text{Enc}((k_e,k_m),m):} &  \underline{\Sigma'.\text{Dec}((k_e,k_m),(c,c')):}\\
\quad k_e\leftarrow E.\text{KeyGen} & \quad c:=E.\text{Enc}(k_e,m)& \quad m:=E.\text{Dec}(k_e,c)\\
\quad k_m\leftarrow M.\text{KeyGen} & \quad t:=M.\text{MAC}(k_m,m) & \quad t:=E.\text{Dec}(k_e,c')\\
\quad \text{return}\ (k_e,k_m)& \quad c'\leftarrow E.\text{Enc}(k_e,t) &\quad \text{if}\ t\neq M.\text{MAC}(k_m,m):\\
&\quad \text{return}\  (c,c') &  \quad \text{return \textcolor{brown}{\texttt{err}}}\\
& & \quad \text{return}\ m\\\hline
\end{array}
$$

Describe a distinguisher and compute its advantage.

10.8. Let E be a CPA-secure encryption scheme and M be a secure MAC. Show that the following
encryption scheme $\Sigma$ (which I call encrypt-and-encrypted-MAC) is not CCA-secure:

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\Sigma'.\text{KeyGen}:} &  \underline{\Sigma'.\text{Enc}((k_e,k_m),m):} &  \underline{\Sigma'.\text{Dec}((k_e,k_m),(c,c')):}\\
\quad k_e\leftarrow E.\text{KeyGen} & \quad c:=E.\text{Enc}(k_e,m)& \quad m:=E.\text{Dec}(k_e,c)\\
\quad k_m\leftarrow M.\text{KeyGen} & \quad t:=M.\text{MAC}(k_m,m) & \quad t:=E.\text{Dec}(k_e,c')\\
\quad \text{return}\ (k_e,k_m)& \quad c'\leftarrow E.\text{Enc}(k_e,t) &\quad \text{if}\ t\neq M.\text{MAC}(k_m,m):\\
&\quad \text{return}\  (c,c') &  \quad \text{return \textcolor{brown}{\texttt{err}}}\\
& & \quad \text{return}\ m\\\hline
\end{array}
$$
Describe a distinguisher and compute its advantage.

$\star 10.9 .$ In Construction $7.4,$ we encrypt one plaintext block into two ciphertext blocks. Imagine applying the Encrypt-then-MAC paradigm to this encryption scheme, but (erroneously) computing a MAC of only the second ciphertext block.

In other words, let $F$ be a PRF with $i n=$ out $=\lambda$, and let $M$ be a MAC scheme for message space $\{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda} .$ Define the following encryption scheme:

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}((k_e,k_m),m):} &  \underline{\text{Dec}((k_e,k_m),(r,x,t)):}\\
\quad k_e\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  & \quad r\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}& \quad \text{if}\ t\neq M.MAC(k_m,x):\\
\quad k_m\leftarrow M.\text{KeyGen} & \quad x:=F(k_e,r)\oplus m& \quad \text{return \textcolor{brown}{\texttt{err}}}\\
\quad \text{return}\ (k_e,k_m)& \quad t:=M.MAC(k_m,x) &\quad \text{else return}\ F(k_e,r)\oplus x\\
&\quad \text{return}\  (r,x,t) &  \\\hline
\end{array}
$$

Show that the scheme does not have CCA security. Describe a successful attack and compute its advantage.

10.10. When we combine different cryptographic ingredients (e.g., combining a CPA-secure encryption scheme with a MAC to obtain a CCA-secure scheme) we generally require the two ingredients to use separate, independent keys. It would be more convenient if the entire scheme just used a single $\lambda$ -bit key.
(a) Suppose we are using Encrypt-then-MAC, where both the encryption scheme and MAC have keys that are $\lambda$ bits long. Refer to the proof of security of Claim 12.5 and describe where it breaks down whenwe modify Encrypt-then-MAC to use the same key for both the encryption & MAC components:

$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}(k,m),:} &  \underline{\text{Dec}(k,(c,t))):}\\
\quad k_e\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  & \quad c:=E.\text{Enc}(k,m)& \quad \text{if}\ t\neq M.MAC(k,c):\\
\quad \text{return}\ k & \quad t:=M.MAC(k_m,x)& \quad \text{return \textcolor{brown}{\texttt{err}}}\\
& \quad \text{return}\  (c,t) &\quad \text{return}\ E\text{Dec}(k,c)\\\hline
\end{array}
$$

(b) While Encrypt-then-MAC requires independent keys $k_e$ and $k_m$ for the two components, show that they can both be derived from a single key using a PRF. In more detail, let $F$ be a PRF with *in* = 1 and out = $\lambda$. Prove that the following modified Encrypt-then-MAC construction is CCA-secure:
$$
\def\arraystretch{1.5}
\begin{array}{|lll|}\hline
\underline{\text{KeyGen}:} &  \underline{\text{Enc}(k^*,m),:} &  \underline{\text{Dec}(k^*,(c,t))):}\\
\quad k_e\leftarrow \{\textcolor{brown}{0},\textcolor{brown}{1}\}^{\lambda}  & \quad k_e:=F(k^*,\textcolor{brown}{0})&\quad k_e:=F(k^*,\textcolor{brown}{0})\\
\quad \text{return}\ k^* &\quad  k_m:=F(k^*,\textcolor{brown}{1})& \quad  k_m:=F(k^*,\textcolor{brown}{1})\\
& \quad c:=E.\text{Enc}(k_e,m)&\quad \text{if}\ t\neq M.MAC(k_m,c):\\
&\quad t:=M.MAC(k_m,c) &\qquad \text{return \textcolor{brown}{\texttt{err}}}\\
&\quad \text{return}\ (c,t) &\quad \text{return}\ E.\text{Dec}(k_e,c)\\\hline
\end{array}
$$

You should not have to re-prove all the tedious steps of the Encrypt-then-MAC security proof. Rather, you should apply the security of the PRF in order to reach the original Encrypt-then-MAC construction, whose securitywe already proved (so you don’t have to repeat).



